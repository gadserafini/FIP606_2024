[
  {
    "objectID": "index.html",
    "href": "index.html",
    "title": "FIP606 - Análise e visualização de dados em Fitopatologia",
    "section": "",
    "text": "Esta página foi criada em Quarto Markdown, com o intuito de organiza o material das aulas em tópicos que sejam intuitivos a qualquer pessoa. Convido você a explorar o site e aprender sobre o fascinante mundo da análise de dados.\n\n\nGabriel A. D. Serafini é graduado em Agronomia pelo Instituto Federal de Educação, Ciência e Tecnologia do Espírito Santo - Campus Santa Teresa (2017). Atualmente doutorando em Fitotecnia (2023), com ênfase em Agricultura Digital pelo Departamento de Fitotecnia da Universidade Federal de Viçosa - UFV, onde também obteve o título de Mestre em Fitotecnia (2020), tendo como foco de seus estudos o Melhoramento de Plantas. Além disso, realizou especialização em Inteligência Artificial e Computacional (2022) pelo Departamento de Engenharia Elétrica da mesma instituição.\n\n  \n \n \n  \n   \n  \n    \n     Lattes\n  \n  \n    \n     ORCID\n  \n  \n    \n     Email\n  \n\n\n\n\n\n\nA disciplina de FIP606 - Análise e visualização de dados em Fitopatologia do Programa de Pós-graduação em Fitopatologia da UFV, foi ministrada pelo Professor Emerson Del Ponte no primeiro semestre letivo do ano de 2024.\nEmbora direcionada a pós-graduandos em Fitopatologia, os princípios e métodos abordados são aplicáveis a outras áreas do conhecimento que lidam com dados e problemas similares. A disciplina capacita os estudantes a conduzir todas as etapas da pesquisa científica, desde o planejamento e coleta de dados até a análise e comunicação dos resultados, utilizando o ambiente computacional.\nA disciplina é ensinada na linguagem de programação atualmente mais utilizada pela comunidade científica, a linguagem R . Para isso, utiliza do ambiente de desenvolvimento integrado (IDE) RStudio, seguindo a filosofia do tidyverse e gerando propts reproduzíveis em Quarto Markdown.\n\n\n\nNesta disciplina foi utilizada a apostila da disciplina, disponibilizada pelo Porf. Emerson Del Ponte como literatura principal. Esta apostila, foi produzida em R Markdown e utilizando o pacote bookdown para geração no formato gitbook, é uma ferramenta completa, intuitiva e de fácil compreensão, combinando textos e códigos em R, com a programação ensinada no IDE RStudio seguindo a filosofia do tidyverse. Esta apostila é ideal para iniciantes, oferecendo uma abordagem clara e acessível para quem deseja aprender análise de dados usando R.\nRecomendo também o livro “R para Data Science” de Hadley Wickham e Garrett Grolemund, caso deseje aprofundar os conhecimentos em ciência de dados com R. Este livro é robusto e detalhado, abrangendo desde a importação e limpeza de dados até a visualização e modelagem, utilizando também os pacotes do tidyverse. Com uma abordagem prática e acessível, ele é ideal tanto para iniciantes quanto para aqueles com alguma experiência.\nOutra recomendação é o livro “Estatística Prática para Cientistas de Dados” de Peter Bruce e Andrew Bruce, um livro consiso mas de leitura essencial para quem busca compreender e aplicar conceitos estatísticos no campo da ciência de dados. Este livro oferece uma abordagem prática e acessível utilizando o R como forma de ensino, tornando a estatística intuitiva e fácil de entender para profissionais de todas as áreas. Ele cobre tópicos fundamentais como distribuição de dados, inferência estatística, testes de hipóteses, regressão e análise de variância, com exemplos claros e exercícios práticos no R."
  },
  {
    "objectID": "index.html#sobre-o-autor",
    "href": "index.html#sobre-o-autor",
    "title": "FIP606 - Análise e visualização de dados em Fitopatologia",
    "section": "",
    "text": "Gabriel A. D. Serafini é graduado em Agronomia pelo Instituto Federal de Educação, Ciência e Tecnologia do Espírito Santo - Campus Santa Teresa (2017). Atualmente doutorando em Fitotecnia (2023), com ênfase em Agricultura Digital pelo Departamento de Fitotecnia da Universidade Federal de Viçosa - UFV, onde também obteve o título de Mestre em Fitotecnia (2020), tendo como foco de seus estudos o Melhoramento de Plantas. Além disso, realizou especialização em Inteligência Artificial e Computacional (2022) pelo Departamento de Engenharia Elétrica da mesma instituição.\n\n  \n \n \n  \n   \n  \n    \n     Lattes\n  \n  \n    \n     ORCID\n  \n  \n    \n     Email"
  },
  {
    "objectID": "index.html#sobre-a-disciplina",
    "href": "index.html#sobre-a-disciplina",
    "title": "FIP606 - Análise e visualização de dados em Fitopatologia",
    "section": "",
    "text": "A disciplina de FIP606 - Análise e visualização de dados em Fitopatologia do Programa de Pós-graduação em Fitopatologia da UFV, foi ministrada pelo Professor Emerson Del Ponte no primeiro semestre letivo do ano de 2024.\nEmbora direcionada a pós-graduandos em Fitopatologia, os princípios e métodos abordados são aplicáveis a outras áreas do conhecimento que lidam com dados e problemas similares. A disciplina capacita os estudantes a conduzir todas as etapas da pesquisa científica, desde o planejamento e coleta de dados até a análise e comunicação dos resultados, utilizando o ambiente computacional.\nA disciplina é ensinada na linguagem de programação atualmente mais utilizada pela comunidade científica, a linguagem R . Para isso, utiliza do ambiente de desenvolvimento integrado (IDE) RStudio, seguindo a filosofia do tidyverse e gerando propts reproduzíveis em Quarto Markdown."
  },
  {
    "objectID": "index.html#literaturas-de-apoio",
    "href": "index.html#literaturas-de-apoio",
    "title": "FIP606 - Análise e visualização de dados em Fitopatologia",
    "section": "",
    "text": "Nesta disciplina foi utilizada a apostila da disciplina, disponibilizada pelo Porf. Emerson Del Ponte como literatura principal. Esta apostila, foi produzida em R Markdown e utilizando o pacote bookdown para geração no formato gitbook, é uma ferramenta completa, intuitiva e de fácil compreensão, combinando textos e códigos em R, com a programação ensinada no IDE RStudio seguindo a filosofia do tidyverse. Esta apostila é ideal para iniciantes, oferecendo uma abordagem clara e acessível para quem deseja aprender análise de dados usando R.\nRecomendo também o livro “R para Data Science” de Hadley Wickham e Garrett Grolemund, caso deseje aprofundar os conhecimentos em ciência de dados com R. Este livro é robusto e detalhado, abrangendo desde a importação e limpeza de dados até a visualização e modelagem, utilizando também os pacotes do tidyverse. Com uma abordagem prática e acessível, ele é ideal tanto para iniciantes quanto para aqueles com alguma experiência.\nOutra recomendação é o livro “Estatística Prática para Cientistas de Dados” de Peter Bruce e Andrew Bruce, um livro consiso mas de leitura essencial para quem busca compreender e aplicar conceitos estatísticos no campo da ciência de dados. Este livro oferece uma abordagem prática e acessível utilizando o R como forma de ensino, tornando a estatística intuitiva e fácil de entender para profissionais de todas as áreas. Ele cobre tópicos fundamentais como distribuição de dados, inferência estatística, testes de hipóteses, regressão e análise de variância, com exemplos claros e exercícios práticos no R."
  },
  {
    "objectID": "aula_10.html",
    "href": "aula_10.html",
    "title": "Aula 10",
    "section": "",
    "text": "Correlação é uma associação entre duas variáveis. Um incremento de uma variável modifica a outra.\nO r é sempre menor doque o R². O r é menor porque é a raiz de r. r é a força de associação entre x e y.\n\nlibrary(tidyverse)\n\n── Attaching core tidyverse packages ──────────────────────── tidyverse 2.0.0 ──\n✔ dplyr     1.1.4     ✔ readr     2.1.5\n✔ forcats   1.0.0     ✔ stringr   1.5.1\n✔ ggplot2   3.5.1     ✔ tibble    3.2.1\n✔ lubridate 1.9.3     ✔ tidyr     1.3.1\n✔ purrr     1.0.2     \n── Conflicts ────────────────────────────────────────── tidyverse_conflicts() ──\n✖ dplyr::filter() masks stats::filter()\n✖ dplyr::lag()    masks stats::lag()\nℹ Use the conflicted package (&lt;http://conflicted.r-lib.org/&gt;) to force all conflicts to become errors\n\ntheme_set(theme_bw())\n\n\nlibrary(gsheet)\nimgs &lt;- gsheet2tbl(\"https://docs.google.com/spreadsheets/d/1bq2N19DcZdtax2fQW9OHSGMR0X2__Z9T/edit#gid=373270992\")\n\n\nimgs |&gt; \n  pivot_longer(3:5, names_to = \"method\",\n               values_to = \"value\") |&gt; \n  ggplot(aes(method, value))+\n  geom_boxplot()\n\n\n\n\n\n\n\nimgs |&gt; \n  ggplot(aes(Assess, LeafDoctor))+\n  geom_point()+\n  geom_smooth(method = \"lm\")\n\n`geom_smooth()` using formula = 'y ~ x'\n\n\n\n\n\n\n\n\n\nCriando a matriz de correlação\n\nimgs2 &lt;- imgs[, c(\"Assess\", \"LeafDoctor\", \"ImageJ\")]\n\nlibrary(AgroR)\n\nWarning: pacote 'AgroR' foi compilado no R versão 4.4.1\n\n\n\nAnexando pacote: 'AgroR'\n\n\nO seguinte objeto é mascarado por 'package:dplyr':\n\n    desc\n\ncorgraph(imgs2) \n\n        Var1       Var2       cor            p\n2 LeafDoctor     Assess 0.9666367 5.972544e-42\n3     ImageJ     Assess 0.9776918 8.143613e-48\n6     ImageJ LeafDoctor 0.9797478 3.144091e-49\n\n\n\n\n\n\n\n\ncor.test(imgs$Assess, imgs$LeafDoctor)\n\n\n    Pearson's product-moment correlation\n\ndata:  imgs$Assess and imgs$LeafDoctor\nt = 31.119, df = 68, p-value &lt; 2.2e-16\nalternative hypothesis: true correlation is not equal to 0\n95 percent confidence interval:\n 0.9466882 0.9792005\nsample estimates:\n      cor \n0.9666367 \n\ncor(imgs$Assess, imgs$LeafDoctor)\n\n[1] 0.9666367\n\n\n\nlibrary(corrplot)\n\nWarning: pacote 'corrplot' foi compilado no R versão 4.4.1\n\n\ncorrplot 0.92 loaded\n\ncor_imgs2 &lt;- cor(imgs2)\ncorrplot(cor_imgs2, method = \"number\", type = \"lower\")\n\n\n\n\n\n\n\n\n\nlibrary(corrplot)\ncor_imgs2 &lt;- cor(imgs2)\ncorrplot(cor_imgs2, method = \"circle\", type = \"lower\") #Pode ser square tabém, e escolher o type, esse pacote é muito mais customizável. diag False tira a diagonal\n\n\n\n\n\n\n\n\nOutro conjunto de dados\n\nlibrary(AgroR)\ncampo &lt;- gsheet2tbl(\"https://docs.google.com/spreadsheets/d/1bq2N19DcZdtax2fQW9OHSGMR0X2__Z9T/edit#gid=866852711\")\n\ncampo2 &lt;- campo |&gt; \n  dplyr::select(DFC, FER, PROD)\n\ncorgraph(campo2)\n\n  Var1 Var2        cor            p\n2  FER  DFC  0.9316978 9.864101e-15\n3 PROD  DFC -0.6928161 1.110652e-05\n6 PROD  FER -0.6258321 1.277444e-04\n\n\n\n\n\n\n\n\n\n\nestande &lt;- gsheet2tbl(\"https://docs.google.com/spreadsheets/d/1bq2N19DcZdtax2fQW9OHSGMR0X2__Z9T/edit#gid=401662555\")\n\nestande |&gt; \n  ggplot(aes(trat, nplants))+\n  geom_jitter(width = 0.1, alpha = 0.5)+\n  facet_wrap(~ exp)+\n  stat_summary(fun.data = \"mean_cl_boot\", size =0.5, color = \"blue\")+\n geom_smooth(method = \"lm\", se = F)\n\n`geom_smooth()` using formula = 'y ~ x'\n\n\n\n\n\n\n\n\n\nFoi pego os dados “estande”\n\nexp2 &lt;- estande |&gt; \n  filter(exp == 2)\n\nexp2 |&gt; \n  ggplot(aes(trat, nplants))+\n  geom_point()+\n  ylim(0,100)+\n  geom_smooth(method= \"lm\", \n              se=FALSE, \n              formula = y ~poly(x,2), color=\"black\")+\n  geom_smooth(method = \"lm\",\n              se = FALSE)\n\n`geom_smooth()` using formula = 'y ~ x'\n\n\n\n\n\n\n\n\n\n\n# modelo linear\n\nexp2$trat2 &lt;- exp2$trat^2 \n  \n# primeira ordem\nlm2 &lt;- lm(nplants ~ trat, \n          data = exp2)\n# segunda ordem ou quadrático\nlm3 &lt;- lm(nplants ~ trat + trat2 , \n          data = exp2)\n\nsummary(lm2)\n\n\nCall:\nlm(formula = nplants ~ trat, data = exp2)\n\nResiduals:\n     Min       1Q   Median       3Q      Max \n-25.7816  -7.7150   0.5653   8.1929  19.2184 \n\nCoefficients:\n            Estimate Std. Error t value Pr(&gt;|t|)    \n(Intercept)  60.9857     3.6304  16.798 4.93e-14 ***\ntrat         -0.7007     0.1605  -4.365 0.000247 ***\n---\nSignif. codes:  0 '***' 0.001 '**' 0.01 '*' 0.05 '.' 0.1 ' ' 1\n\nResidual standard error: 12.95 on 22 degrees of freedom\nMultiple R-squared:  0.4641,    Adjusted R-squared:  0.4398 \nF-statistic: 19.05 on 1 and 22 DF,  p-value: 0.0002473\n\nsummary(lm3)\n\n\nCall:\nlm(formula = nplants ~ trat + trat2, data = exp2)\n\nResiduals:\n    Min      1Q  Median      3Q     Max \n-25.439  -6.019   1.789   8.016  19.561 \n\nCoefficients:\n            Estimate Std. Error t value Pr(&gt;|t|)    \n(Intercept) 66.30156    4.42097  14.997 1.08e-12 ***\ntrat        -1.77720    0.58467  -3.040  0.00623 ** \ntrat2        0.02223    0.01166   1.906  0.07036 .  \n---\nSignif. codes:  0 '***' 0.001 '**' 0.01 '*' 0.05 '.' 0.1 ' ' 1\n\nResidual standard error: 12.24 on 21 degrees of freedom\nMultiple R-squared:  0.5432,    Adjusted R-squared:  0.4997 \nF-statistic: 12.49 on 2 and 21 DF,  p-value: 0.0002675\n\nAIC(lm2)\n\n[1] 194.9597\n\nAIC(lm3)\n\n[1] 193.1284\n\n\nQuando ajusta o modelo ele já dá as\nElevou ao quadrado para dar um coeficiente a mais, quanto mais coeficiente mais não linear ele fica.\nDois modelos, de primera ordem e de segunda ordem ou quadrado.\nSe explica melhor com a quadrada (0,4997) do que com a linear(0,4398) (Verificar os dados)\n\nlibrary(AgroR)\nwith(exp2, polynomial(trat,nplants, grau = 2))\n\n\n----------------------------------------------------\nRegression Models\n----------------------------------------------------\n               Estimate Std. Error   t value     Pr(&gt;|t|)\n(Intercept) 66.30156250 4.42096799 14.997069 1.079972e-12\ntrat        -1.77719814 0.58467380 -3.039640 6.230050e-03\nI(trat^2)    0.02222876 0.01165948  1.906496 7.036247e-02\n\n----------------------------------------------------\nDeviations from regression\n----------------------------------------------------\n          Df       SSq       MSQ         F      p-value\nLinear     1 3196.2031 3196.2031 21.823293 0.0001899378\nQuadratic  1  544.5029  544.5029  3.717801 0.0697619482\nDeviation  3  509.6690  169.8897  1.159986 0.3523240106\nResidual  18 2636.2500  146.4583                       \n\n\n[[1]]\n\n\n\n\n\n\n\n\ndata(\"phao\")\nwith(phao, polynomial(dose,comp, grau = 2))\n\n\n----------------------------------------------------\nRegression Models\n----------------------------------------------------\n              Estimate Std. Error   t value     Pr(&gt;|t|)\n(Intercept) 10.2097143 0.68981140 14.800733 6.427099e-13\ntrat         2.8822857 0.40856781  7.054608 4.456995e-07\nI(trat^2)   -0.3042857 0.04897332 -6.213296 2.971498e-06\n\n----------------------------------------------------\nDeviations from regression\n----------------------------------------------------\n          Df        SSq         MSQ          F      p-value\nLinear     1  40.140800  40.1408000 14.0529338 1.265122e-03\nQuadratic  1 103.700571 103.7005714 36.3046392 6.852202e-06\nDeviation  2   1.968229   0.9841143  0.3445296 7.126767e-01\nResidual  20  57.128000   2.8564000                        \n\n\n[[1]]\n\n\n\n\n\n\n\n\n\nSensibilidade de fungicida (sensibiidade_fungicidas)\n\nlibrary(gsheet)\npyra &lt;- gsheet2tbl(\"https://docs.google.com/spreadsheets/d/1bq2N19DcZdtax2fQW9OHSGMR0X2__Z9T/edit#gid=465348652\")\n\n\npyra2 &lt;- pyra |&gt; \n  group_by(code, state, dose) |&gt; \n  summarise(mean_germination = mean(germination))\n\n`summarise()` has grouped output by 'code', 'state'. You can override using the\n`.groups` argument.\n\npyra2 |&gt; \n  ggplot(aes(dose, mean_germination))+\n  geom_point()+\n  geom_smooth(span = 3, se = FALSE)+\n  facet_wrap(~code)\n\n`geom_smooth()` using method = 'loess' and formula = 'y ~ x'\n\n\n\n\n\n\n\n\n\nDose bem pequena já cai drásticamente a germinação\n\nlibrary(drc)\n\nWarning: pacote 'drc' foi compilado no R versão 4.4.1\n\n\nCarregando pacotes exigidos: MASS\n\n\nWarning: pacote 'MASS' foi compilado no R versão 4.4.1\n\n\n\nAnexando pacote: 'MASS'\n\n\nO seguinte objeto é mascarado por 'package:dplyr':\n\n    select\n\n\n\n'drc' has been loaded.\n\n\nPlease cite R and 'drc' if used for a publication,\n\n\nfor references type 'citation()' and 'citation('drc')'.\n\n\n\nAnexando pacote: 'drc'\n\n\nO seguinte objeto é mascarado por 'package:AgroR':\n\n    logistic\n\n\nOs seguintes objetos são mascarados por 'package:stats':\n\n    gaussian, getInitial\n\nisolado165 &lt;- pyra2 |&gt; \n  filter(code == \"165\")\n\ndrc1 &lt;- drm(mean_germination ~ dose, data = isolado165, fct = LL.3()) #pacote drc tem a função dmr\n\nAIC(drc1)\n\n[1] 31.55522\n\nplot(drc1)\n\n\n\n\n\n\n\n#esse pacote já tem uma função que cálcula a dose letal a 50 a função ED também dá um intervalo se colocar interval = \"delta\"\n\nPacote ec50estimator trabalha com todos os dados, ele faz de todos ao invés de fazer um por um.\n\nlibrary(ec50estimator)\n\nWarning: pacote 'ec50estimator' foi compilado no R versão 4.4.1\n\ndf_ec50 &lt;- estimate_EC50(mean_germination ~ dose, data = pyra2, isolate_col = \"code\", interval = \"delta\", fct = drc::LL.3())\n\ndf_ec50\n\n      ID strata   Estimate  Std..Error        Lower     Upper\n1    152        0.44435629 0.077789240  0.196796213 0.6919164\n2    153        0.20379664 0.042373512  0.068945217 0.3386481\n3    164        0.50775844 0.047248266  0.357393370 0.6581235\n4    165        0.55839613 0.114195113  0.194976315 0.9218159\n5    169        0.14722311 0.009555688  0.116812646 0.1776336\n6    170        0.37503889 0.043207328  0.237533889 0.5125439\n7    186        0.57975744 0.013332268  0.537328208 0.6221867\n8    187        0.21563338 0.036639446  0.099030315 0.3322365\n9    188        0.15297172 0.004284691  0.139335920 0.1666075\n10   189        0.53106193 0.023130936  0.457448972 0.6046749\n11 FGT05        0.04483862 0.019290890 -0.016553601 0.1062308\n12 FGT06        0.54497946 0.034834602  0.434120211 0.6558387\n13 FGT07        0.88770053 0.079917704  0.633366725 1.1420343\n14 FGT28        0.22608141 0.033600742  0.119148854 0.3330140\n15 FGT29        0.23601652 0.034933881  0.124841318 0.3471917\n16 FGT33        0.10481627 0.013065221  0.063236910 0.1463956\n17 FGT34        0.14773114 0.047003373 -0.001854568 0.2973169\n18 FGT35        0.20315392 0.038984604  0.079087515 0.3272203\n19 FGT42        0.45000559 0.059685890  0.260058448 0.6399527\n20 FGT43        0.49589549 0.060850771  0.302241178 0.6895498\n\n\n\ndf_ec50 |&gt; \n  ggplot(aes(reorder(ID, Estimate), Estimate))+\n  geom_point()+\n  geom_errorbar(aes(ymin = Lower, ymax = Upper))+\n  coord_flip()"
  },
  {
    "objectID": "aula_10.html#análise-de-correlação",
    "href": "aula_10.html#análise-de-correlação",
    "title": "Aula 10",
    "section": "",
    "text": "Correlação é uma associação entre duas variáveis. Um incremento de uma variável modifica a outra.\nO r é sempre menor doque o R². O r é menor porque é a raiz de r. r é a força de associação entre x e y.\n\nlibrary(tidyverse)\n\n── Attaching core tidyverse packages ──────────────────────── tidyverse 2.0.0 ──\n✔ dplyr     1.1.4     ✔ readr     2.1.5\n✔ forcats   1.0.0     ✔ stringr   1.5.1\n✔ ggplot2   3.5.1     ✔ tibble    3.2.1\n✔ lubridate 1.9.3     ✔ tidyr     1.3.1\n✔ purrr     1.0.2     \n── Conflicts ────────────────────────────────────────── tidyverse_conflicts() ──\n✖ dplyr::filter() masks stats::filter()\n✖ dplyr::lag()    masks stats::lag()\nℹ Use the conflicted package (&lt;http://conflicted.r-lib.org/&gt;) to force all conflicts to become errors\n\ntheme_set(theme_bw())\n\n\nlibrary(gsheet)\nimgs &lt;- gsheet2tbl(\"https://docs.google.com/spreadsheets/d/1bq2N19DcZdtax2fQW9OHSGMR0X2__Z9T/edit#gid=373270992\")\n\n\nimgs |&gt; \n  pivot_longer(3:5, names_to = \"method\",\n               values_to = \"value\") |&gt; \n  ggplot(aes(method, value))+\n  geom_boxplot()\n\n\n\n\n\n\n\nimgs |&gt; \n  ggplot(aes(Assess, LeafDoctor))+\n  geom_point()+\n  geom_smooth(method = \"lm\")\n\n`geom_smooth()` using formula = 'y ~ x'\n\n\n\n\n\n\n\n\n\nCriando a matriz de correlação\n\nimgs2 &lt;- imgs[, c(\"Assess\", \"LeafDoctor\", \"ImageJ\")]\n\nlibrary(AgroR)\n\nWarning: pacote 'AgroR' foi compilado no R versão 4.4.1\n\n\n\nAnexando pacote: 'AgroR'\n\n\nO seguinte objeto é mascarado por 'package:dplyr':\n\n    desc\n\ncorgraph(imgs2) \n\n        Var1       Var2       cor            p\n2 LeafDoctor     Assess 0.9666367 5.972544e-42\n3     ImageJ     Assess 0.9776918 8.143613e-48\n6     ImageJ LeafDoctor 0.9797478 3.144091e-49\n\n\n\n\n\n\n\n\ncor.test(imgs$Assess, imgs$LeafDoctor)\n\n\n    Pearson's product-moment correlation\n\ndata:  imgs$Assess and imgs$LeafDoctor\nt = 31.119, df = 68, p-value &lt; 2.2e-16\nalternative hypothesis: true correlation is not equal to 0\n95 percent confidence interval:\n 0.9466882 0.9792005\nsample estimates:\n      cor \n0.9666367 \n\ncor(imgs$Assess, imgs$LeafDoctor)\n\n[1] 0.9666367\n\n\n\nlibrary(corrplot)\n\nWarning: pacote 'corrplot' foi compilado no R versão 4.4.1\n\n\ncorrplot 0.92 loaded\n\ncor_imgs2 &lt;- cor(imgs2)\ncorrplot(cor_imgs2, method = \"number\", type = \"lower\")\n\n\n\n\n\n\n\n\n\nlibrary(corrplot)\ncor_imgs2 &lt;- cor(imgs2)\ncorrplot(cor_imgs2, method = \"circle\", type = \"lower\") #Pode ser square tabém, e escolher o type, esse pacote é muito mais customizável. diag False tira a diagonal\n\n\n\n\n\n\n\n\nOutro conjunto de dados\n\nlibrary(AgroR)\ncampo &lt;- gsheet2tbl(\"https://docs.google.com/spreadsheets/d/1bq2N19DcZdtax2fQW9OHSGMR0X2__Z9T/edit#gid=866852711\")\n\ncampo2 &lt;- campo |&gt; \n  dplyr::select(DFC, FER, PROD)\n\ncorgraph(campo2)\n\n  Var1 Var2        cor            p\n2  FER  DFC  0.9316978 9.864101e-15\n3 PROD  DFC -0.6928161 1.110652e-05\n6 PROD  FER -0.6258321 1.277444e-04\n\n\n\n\n\n\n\n\n\n\nestande &lt;- gsheet2tbl(\"https://docs.google.com/spreadsheets/d/1bq2N19DcZdtax2fQW9OHSGMR0X2__Z9T/edit#gid=401662555\")\n\nestande |&gt; \n  ggplot(aes(trat, nplants))+\n  geom_jitter(width = 0.1, alpha = 0.5)+\n  facet_wrap(~ exp)+\n  stat_summary(fun.data = \"mean_cl_boot\", size =0.5, color = \"blue\")+\n geom_smooth(method = \"lm\", se = F)\n\n`geom_smooth()` using formula = 'y ~ x'\n\n\n\n\n\n\n\n\n\nFoi pego os dados “estande”\n\nexp2 &lt;- estande |&gt; \n  filter(exp == 2)\n\nexp2 |&gt; \n  ggplot(aes(trat, nplants))+\n  geom_point()+\n  ylim(0,100)+\n  geom_smooth(method= \"lm\", \n              se=FALSE, \n              formula = y ~poly(x,2), color=\"black\")+\n  geom_smooth(method = \"lm\",\n              se = FALSE)\n\n`geom_smooth()` using formula = 'y ~ x'\n\n\n\n\n\n\n\n\n\n\n# modelo linear\n\nexp2$trat2 &lt;- exp2$trat^2 \n  \n# primeira ordem\nlm2 &lt;- lm(nplants ~ trat, \n          data = exp2)\n# segunda ordem ou quadrático\nlm3 &lt;- lm(nplants ~ trat + trat2 , \n          data = exp2)\n\nsummary(lm2)\n\n\nCall:\nlm(formula = nplants ~ trat, data = exp2)\n\nResiduals:\n     Min       1Q   Median       3Q      Max \n-25.7816  -7.7150   0.5653   8.1929  19.2184 \n\nCoefficients:\n            Estimate Std. Error t value Pr(&gt;|t|)    \n(Intercept)  60.9857     3.6304  16.798 4.93e-14 ***\ntrat         -0.7007     0.1605  -4.365 0.000247 ***\n---\nSignif. codes:  0 '***' 0.001 '**' 0.01 '*' 0.05 '.' 0.1 ' ' 1\n\nResidual standard error: 12.95 on 22 degrees of freedom\nMultiple R-squared:  0.4641,    Adjusted R-squared:  0.4398 \nF-statistic: 19.05 on 1 and 22 DF,  p-value: 0.0002473\n\nsummary(lm3)\n\n\nCall:\nlm(formula = nplants ~ trat + trat2, data = exp2)\n\nResiduals:\n    Min      1Q  Median      3Q     Max \n-25.439  -6.019   1.789   8.016  19.561 \n\nCoefficients:\n            Estimate Std. Error t value Pr(&gt;|t|)    \n(Intercept) 66.30156    4.42097  14.997 1.08e-12 ***\ntrat        -1.77720    0.58467  -3.040  0.00623 ** \ntrat2        0.02223    0.01166   1.906  0.07036 .  \n---\nSignif. codes:  0 '***' 0.001 '**' 0.01 '*' 0.05 '.' 0.1 ' ' 1\n\nResidual standard error: 12.24 on 21 degrees of freedom\nMultiple R-squared:  0.5432,    Adjusted R-squared:  0.4997 \nF-statistic: 12.49 on 2 and 21 DF,  p-value: 0.0002675\n\nAIC(lm2)\n\n[1] 194.9597\n\nAIC(lm3)\n\n[1] 193.1284\n\n\nQuando ajusta o modelo ele já dá as\nElevou ao quadrado para dar um coeficiente a mais, quanto mais coeficiente mais não linear ele fica.\nDois modelos, de primera ordem e de segunda ordem ou quadrado.\nSe explica melhor com a quadrada (0,4997) do que com a linear(0,4398) (Verificar os dados)\n\nlibrary(AgroR)\nwith(exp2, polynomial(trat,nplants, grau = 2))\n\n\n----------------------------------------------------\nRegression Models\n----------------------------------------------------\n               Estimate Std. Error   t value     Pr(&gt;|t|)\n(Intercept) 66.30156250 4.42096799 14.997069 1.079972e-12\ntrat        -1.77719814 0.58467380 -3.039640 6.230050e-03\nI(trat^2)    0.02222876 0.01165948  1.906496 7.036247e-02\n\n----------------------------------------------------\nDeviations from regression\n----------------------------------------------------\n          Df       SSq       MSQ         F      p-value\nLinear     1 3196.2031 3196.2031 21.823293 0.0001899378\nQuadratic  1  544.5029  544.5029  3.717801 0.0697619482\nDeviation  3  509.6690  169.8897  1.159986 0.3523240106\nResidual  18 2636.2500  146.4583                       \n\n\n[[1]]\n\n\n\n\n\n\n\n\ndata(\"phao\")\nwith(phao, polynomial(dose,comp, grau = 2))\n\n\n----------------------------------------------------\nRegression Models\n----------------------------------------------------\n              Estimate Std. Error   t value     Pr(&gt;|t|)\n(Intercept) 10.2097143 0.68981140 14.800733 6.427099e-13\ntrat         2.8822857 0.40856781  7.054608 4.456995e-07\nI(trat^2)   -0.3042857 0.04897332 -6.213296 2.971498e-06\n\n----------------------------------------------------\nDeviations from regression\n----------------------------------------------------\n          Df        SSq         MSQ          F      p-value\nLinear     1  40.140800  40.1408000 14.0529338 1.265122e-03\nQuadratic  1 103.700571 103.7005714 36.3046392 6.852202e-06\nDeviation  2   1.968229   0.9841143  0.3445296 7.126767e-01\nResidual  20  57.128000   2.8564000                        \n\n\n[[1]]\n\n\n\n\n\n\n\n\n\nSensibilidade de fungicida (sensibiidade_fungicidas)\n\nlibrary(gsheet)\npyra &lt;- gsheet2tbl(\"https://docs.google.com/spreadsheets/d/1bq2N19DcZdtax2fQW9OHSGMR0X2__Z9T/edit#gid=465348652\")\n\n\npyra2 &lt;- pyra |&gt; \n  group_by(code, state, dose) |&gt; \n  summarise(mean_germination = mean(germination))\n\n`summarise()` has grouped output by 'code', 'state'. You can override using the\n`.groups` argument.\n\npyra2 |&gt; \n  ggplot(aes(dose, mean_germination))+\n  geom_point()+\n  geom_smooth(span = 3, se = FALSE)+\n  facet_wrap(~code)\n\n`geom_smooth()` using method = 'loess' and formula = 'y ~ x'\n\n\n\n\n\n\n\n\n\nDose bem pequena já cai drásticamente a germinação\n\nlibrary(drc)\n\nWarning: pacote 'drc' foi compilado no R versão 4.4.1\n\n\nCarregando pacotes exigidos: MASS\n\n\nWarning: pacote 'MASS' foi compilado no R versão 4.4.1\n\n\n\nAnexando pacote: 'MASS'\n\n\nO seguinte objeto é mascarado por 'package:dplyr':\n\n    select\n\n\n\n'drc' has been loaded.\n\n\nPlease cite R and 'drc' if used for a publication,\n\n\nfor references type 'citation()' and 'citation('drc')'.\n\n\n\nAnexando pacote: 'drc'\n\n\nO seguinte objeto é mascarado por 'package:AgroR':\n\n    logistic\n\n\nOs seguintes objetos são mascarados por 'package:stats':\n\n    gaussian, getInitial\n\nisolado165 &lt;- pyra2 |&gt; \n  filter(code == \"165\")\n\ndrc1 &lt;- drm(mean_germination ~ dose, data = isolado165, fct = LL.3()) #pacote drc tem a função dmr\n\nAIC(drc1)\n\n[1] 31.55522\n\nplot(drc1)\n\n\n\n\n\n\n\n#esse pacote já tem uma função que cálcula a dose letal a 50 a função ED também dá um intervalo se colocar interval = \"delta\"\n\nPacote ec50estimator trabalha com todos os dados, ele faz de todos ao invés de fazer um por um.\n\nlibrary(ec50estimator)\n\nWarning: pacote 'ec50estimator' foi compilado no R versão 4.4.1\n\ndf_ec50 &lt;- estimate_EC50(mean_germination ~ dose, data = pyra2, isolate_col = \"code\", interval = \"delta\", fct = drc::LL.3())\n\ndf_ec50\n\n      ID strata   Estimate  Std..Error        Lower     Upper\n1    152        0.44435629 0.077789240  0.196796213 0.6919164\n2    153        0.20379664 0.042373512  0.068945217 0.3386481\n3    164        0.50775844 0.047248266  0.357393370 0.6581235\n4    165        0.55839613 0.114195113  0.194976315 0.9218159\n5    169        0.14722311 0.009555688  0.116812646 0.1776336\n6    170        0.37503889 0.043207328  0.237533889 0.5125439\n7    186        0.57975744 0.013332268  0.537328208 0.6221867\n8    187        0.21563338 0.036639446  0.099030315 0.3322365\n9    188        0.15297172 0.004284691  0.139335920 0.1666075\n10   189        0.53106193 0.023130936  0.457448972 0.6046749\n11 FGT05        0.04483862 0.019290890 -0.016553601 0.1062308\n12 FGT06        0.54497946 0.034834602  0.434120211 0.6558387\n13 FGT07        0.88770053 0.079917704  0.633366725 1.1420343\n14 FGT28        0.22608141 0.033600742  0.119148854 0.3330140\n15 FGT29        0.23601652 0.034933881  0.124841318 0.3471917\n16 FGT33        0.10481627 0.013065221  0.063236910 0.1463956\n17 FGT34        0.14773114 0.047003373 -0.001854568 0.2973169\n18 FGT35        0.20315392 0.038984604  0.079087515 0.3272203\n19 FGT42        0.45000559 0.059685890  0.260058448 0.6399527\n20 FGT43        0.49589549 0.060850771  0.302241178 0.6895498\n\n\n\ndf_ec50 |&gt; \n  ggplot(aes(reorder(ID, Estimate), Estimate))+\n  geom_point()+\n  geom_errorbar(aes(ymin = Lower, ymax = Upper))+\n  coord_flip()"
  },
  {
    "objectID": "aula_08.html",
    "href": "aula_08.html",
    "title": "Análise Estatística: Estatística inferencial - Parte 3",
    "section": "",
    "text": "Hoje iremos trabalhar com Delineamento Blocos Casualisados (DBC)\nPara trabalhar com blocos casualizados vamos tratar os Tratamentos e os Blocos como fatores.\n\nlibrary(tidyverse)\n\n── Attaching core tidyverse packages ──────────────────────── tidyverse 2.0.0 ──\n✔ dplyr     1.1.4     ✔ readr     2.1.5\n✔ forcats   1.0.0     ✔ stringr   1.5.1\n✔ ggplot2   3.5.1     ✔ tibble    3.2.1\n✔ lubridate 1.9.3     ✔ tidyr     1.3.1\n✔ purrr     1.0.2     \n── Conflicts ────────────────────────────────────────── tidyverse_conflicts() ──\n✖ dplyr::filter() masks stats::filter()\n✖ dplyr::lag()    masks stats::lag()\nℹ Use the conflicted package (&lt;http://conflicted.r-lib.org/&gt;) to force all conflicts to become errors\n\nlibrary(gsheet)\nsoja &lt;- gsheet2tbl(\"https://docs.google.com/spreadsheets/d/1bq2N19DcZdtax2fQW9OHSGMR0X2__Z9T/edit#gid=866852711\")\nsoja &lt;- soja |&gt; \n  mutate(TRAT = as.factor(TRAT),\n         BLOCO = as.factor(BLOCO))\n\n\ntheme_set(theme_bw())\n\nVamos plotar as os gráficos para observar se há diferença entre os tratamentos. Colocamos a média e o intervalo de confiança, o bootstrap aprende a média e o intervalo de confiança. #FALTOU PLOTAR OS DEMAIS#\n\ndfc &lt;- soja |&gt; \n  ggplot(aes(TRAT, DFC ))+\n  geom_jitter(width = 0.05, color = \"gray70\")+\n  stat_summary(fun.data = \"mean_cl_boot\", size =0.5, color = \"black\", alpha = 0.5)\ndfc\n\n\n\n\n\n\n\nfer &lt;- soja |&gt; \n  ggplot(aes(TRAT, FER ))+\n  geom_jitter(width = 0.05, color = \"gray70\")+\n  stat_summary(fun.data = \"mean_cl_boot\", size =0.5, color = \"black\", alpha = 0.5)\nfer\n\n\n\n\n\n\n\nprod &lt;- soja |&gt; \n  ggplot(aes(TRAT, PROD ))+\n  geom_jitter(width = 0.05, color = \"gray70\")+\n  stat_summary(fun.data = \"mean_cl_boot\", size =0.5, color = \"black\", alpha = 0.5)\nprod\n\n\n\n\n\n\n\n#library(r4pde)\nlibrary(patchwork)\n(dfc | fer | prod)\n\n\n\n\n\n\n\n\nAnova DBC\nMesmo não tendo efeito de bloco, deixa-se pois o experimento foi delineado em Blocos Casualisados.\n\naov_dfc &lt;- lm(DFC ~ TRAT + BLOCO,\n              data = soja)\nanova(aov_dfc)\n\nAnalysis of Variance Table\n\nResponse: DFC\n          Df  Sum Sq Mean Sq F value    Pr(&gt;F)    \nTRAT       7 149.299 21.3284 51.5490 8.218e-12 ***\nBLOCO      3   0.461  0.1537  0.3716    0.7743    \nResiduals 21   8.689  0.4138                      \n---\nSignif. codes:  0 '***' 0.001 '**' 0.01 '*' 0.05 '.' 0.1 ' ' 1\n\n\n\nlibrary(performance)\n\nWarning: pacote 'performance' foi compilado no R versão 4.4.1\n\ncheck_heteroscedasticity(aov_dfc)\n\nOK: Error variance appears to be homoscedastic (p = 0.532).\n\ncheck_normality(aov_dfc)\n\nOK: residuals appear as normally distributed (p = 0.978).\n\nlibrary(emmeans)\n\nWarning: pacote 'emmeans' foi compilado no R versão 4.4.1\n\n\nWelcome to emmeans.\nCaution: You lose important information if you filter this package's results.\nSee '? untidy'\n\nmedias_dfc &lt;- emmeans(aov_dfc, ~TRAT)\nmedias_dfc\n\n TRAT emmean    SE df lower.CL upper.CL\n 1     10.88 0.322 21    10.21    11.54\n 2      6.42 0.322 21     5.76     7.09\n 3      6.05 0.322 21     5.38     6.72\n 4      4.75 0.322 21     4.08     5.42\n 5      4.20 0.322 21     3.53     4.87\n 6      4.00 0.322 21     3.33     4.67\n 7      4.08 0.322 21     3.41     4.74\n 8      4.58 0.322 21     3.91     5.24\n\nResults are averaged over the levels of: BLOCO \nConfidence level used: 0.95 \n\npwpm(medias_dfc)\n\n        1       2       3       4       5       6       7       8\n1 [10.87]  &lt;.0001  &lt;.0001  &lt;.0001  &lt;.0001  &lt;.0001  &lt;.0001  &lt;.0001\n2   4.450 [ 6.42]  0.9896  0.0249  0.0017  0.0006  0.0009  0.0107\n3   4.825   0.375 [ 6.05]  0.1329  0.0107  0.0040  0.0058  0.0628\n4   6.125   1.675   1.300 [ 4.75]  0.9202  0.7173  0.8072  0.9999\n5   6.675   2.225   1.850   0.550 [ 4.20]  0.9998  1.0000  0.9896\n6   6.875   2.425   2.050   0.750   0.200 [ 4.00]  1.0000  0.9020\n7   6.800   2.350   1.975   0.675   0.125  -0.075 [ 4.07]  0.9499\n8   6.300   1.850   1.475   0.175  -0.375  -0.575  -0.500 [ 4.57]\n\nRow and column labels: TRAT\nUpper triangle: P values   adjust = \"tukey\"\nDiagonal: [Estimates] (emmean) \nLower triangle: Comparisons (estimate)   earlier vs. later\n\nlibrary(multcomp)\n\nCarregando pacotes exigidos: mvtnorm\n\n\nCarregando pacotes exigidos: survival\n\n\nWarning: pacote 'survival' foi compilado no R versão 4.4.1\n\n\nCarregando pacotes exigidos: TH.data\n\n\nCarregando pacotes exigidos: MASS\n\n\nWarning: pacote 'MASS' foi compilado no R versão 4.4.1\n\n\n\nAnexando pacote: 'MASS'\n\n\nO seguinte objeto é mascarado por 'package:patchwork':\n\n    area\n\n\nO seguinte objeto é mascarado por 'package:dplyr':\n\n    select\n\n\n\nAnexando pacote: 'TH.data'\n\n\nO seguinte objeto é mascarado por 'package:MASS':\n\n    geyser\n\ncld(medias_dfc, Letters = LETTERS)\n\n TRAT emmean    SE df lower.CL upper.CL .group\n 6      4.00 0.322 21     3.33     4.67  A    \n 7      4.08 0.322 21     3.41     4.74  A    \n 5      4.20 0.322 21     3.53     4.87  A    \n 8      4.58 0.322 21     3.91     5.24  AB   \n 4      4.75 0.322 21     4.08     5.42  AB   \n 3      6.05 0.322 21     5.38     6.72   BC  \n 2      6.42 0.322 21     5.76     7.09    C  \n 1     10.88 0.322 21    10.21    11.54     D \n\nResults are averaged over the levels of: BLOCO \nConfidence level used: 0.95 \nP value adjustment: tukey method for comparing a family of 8 estimates \nsignificance level used: alpha = 0.05 \nNOTE: If two or more means share the same grouping symbol,\n      then we cannot show them to be different.\n      But we also did not show them to be the same. \n\n\nFERRUGEM\n\naov_fer &lt;- lm(FER ~ TRAT + BLOCO,\n              data = soja)\nanova(aov_fer)\n\nAnalysis of Variance Table\n\nResponse: FER\n          Df Sum Sq Mean Sq F value    Pr(&gt;F)    \nTRAT       7 978.87 139.838 55.1717 4.218e-12 ***\nBLOCO      3   3.84   1.279  0.5045    0.6834    \nResiduals 21  53.23   2.535                      \n---\nSignif. codes:  0 '***' 0.001 '**' 0.01 '*' 0.05 '.' 0.1 ' ' 1\n\nlibrary(performance)\ncheck_heteroscedasticity(aov_fer)\n\nWarning: Heteroscedasticity (non-constant error variance) detected (p &lt; .001).\n\ncheck_normality(aov_fer)\n\nWarning: Non-normality of residuals detected (p = 0.008).\n\n#Transforação\n\nlibrary(DHARMa)\n\nWarning: pacote 'DHARMa' foi compilado no R versão 4.4.1\n\n\nThis is DHARMa 0.4.6. For overview type '?DHARMa'. For recent changes, type news(package = 'DHARMa')\n\nplot(simulateResiduals(aov_fer))\n\nqu = 0.25, log(sigma) = -3.082978 : outer Newton did not converge fully.\n\n\nqu = 0.25, log(sigma) = -3.153964 : outer Newton did not converge fully.\n\n\nqu = 0.25, log(sigma) = -3.330674 : outer Newton did not converge fully.\n\n\nqu = 0.25, log(sigma) = -3.25367 : outer Newton did not converge fully.\n\n\nqu = 0.25, log(sigma) = -3.254842 : outer Newton did not converge fully.\n\n\nqu = 0.25, log(sigma) = -3.25509 : outer Newton did not converge fully.\n\n\nqu = 0.25, log(sigma) = -3.254964 : outer Newton did not converge fully.\n\n\nqu = 0.75, log(sigma) = -2.678463 : outer Newton did not converge fully.\n\n\nqu = 0.75, log(sigma) = -2.88072 : outer Newton did not converge fully.\n\n\nqu = 0.75, log(sigma) = -3.005722 : outer Newton did not converge fully.\n\n\nqu = 0.75, log(sigma) = -3.130724 : outer Newton did not converge fully.\n\n\nqu = 0.75, log(sigma) = -3.160233 : outer Newton did not converge fully.\n\n\nqu = 0.75, log(sigma) = -3.913208 : outer Newton did not converge fully.\n\n\nqu = 0.75, log(sigma) = -3.91919 : outer Newton did not converge fully.\n\n\nqu = 0.75, log(sigma) = -3.918346 : outer Newton did not converge fully.\n\n\n\n\n\n\n\n\nlibrary(emmeans)\nmedias_fer &lt;- emmeans(aov_fer, ~TRAT, type = \"response\")\nmedias_fer\n\n TRAT emmean    SE df lower.CL upper.CL\n 1     20.25 0.796 21    18.59    21.91\n 2      5.88 0.796 21     4.22     7.53\n 3      4.00 0.796 21     2.34     5.66\n 4      3.12 0.796 21     1.47     4.78\n 5      3.25 0.796 21     1.59     4.91\n 6      3.00 0.796 21     1.34     4.66\n 7      3.38 0.796 21     1.72     5.03\n 8      3.50 0.796 21     1.84     5.16\n\nResults are averaged over the levels of: BLOCO \nConfidence level used: 0.95 \n\npwpm(medias_fer)\n\n        1       2       3       4       5       6       7       8\n1 [20.25]  &lt;.0001  &lt;.0001  &lt;.0001  &lt;.0001  &lt;.0001  &lt;.0001  &lt;.0001\n2  14.375 [ 5.87]  0.7076  0.2722  0.3229  0.2273  0.3792  0.4404\n3  16.250   1.875 [ 4.00]  0.9926  0.9971  0.9840  0.9991  0.9998\n4  17.125   2.750   0.875 [ 3.12]  1.0000  1.0000  1.0000  1.0000\n5  17.000   2.625   0.750  -0.125 [ 3.25]  1.0000  1.0000  1.0000\n6  17.250   2.875   1.000   0.125   0.250 [ 3.00]  1.0000  0.9998\n7  16.875   2.500   0.625  -0.250  -0.125  -0.375 [ 3.37]  1.0000\n8  16.750   2.375   0.500  -0.375  -0.250  -0.500  -0.125 [ 3.50]\n\nRow and column labels: TRAT\nUpper triangle: P values   adjust = \"tukey\"\nDiagonal: [Estimates] (emmean)   type = \"response\"\nLower triangle: Comparisons (estimate)   earlier vs. later\n\nlibrary(multcomp)\ncld(medias_fer, Letters = LETTERS)\n\n TRAT emmean    SE df lower.CL upper.CL .group\n 6      3.00 0.796 21     1.34     4.66  A    \n 4      3.12 0.796 21     1.47     4.78  A    \n 5      3.25 0.796 21     1.59     4.91  A    \n 7      3.38 0.796 21     1.72     5.03  A    \n 8      3.50 0.796 21     1.84     5.16  A    \n 3      4.00 0.796 21     2.34     5.66  A    \n 2      5.88 0.796 21     4.22     7.53  A    \n 1     20.25 0.796 21    18.59    21.91   B   \n\nResults are averaged over the levels of: BLOCO \nConfidence level used: 0.95 \nP value adjustment: tukey method for comparing a family of 8 estimates \nsignificance level used: alpha = 0.05 \nNOTE: If two or more means share the same grouping symbol,\n      then we cannot show them to be different.\n      But we also did not show them to be the same. \n\n\nTransformação Box-Cox\n\nb &lt;- boxcox(lm(soja$FER ~1))\n\n\n\n\n\n\n\nlambda &lt;- b$x[which.max(b$y)]\nlambda\n\n[1] -1.555556\n\nsoja$FER2 &lt;-(soja$FER ^lambda -1)/lambda\n\n\naov_fer2 &lt;- lm(FER2 ~ TRAT + BLOCO,\n              data = soja)\nanova(aov_fer2)\n\nAnalysis of Variance Table\n\nResponse: FER2\n          Df   Sum Sq   Mean Sq F value    Pr(&gt;F)    \nTRAT       7 0.041641 0.0059488 12.9020 2.436e-06 ***\nBLOCO      3 0.005895 0.0019649  4.2616   0.01687 *  \nResiduals 21 0.009683 0.0004611                      \n---\nSignif. codes:  0 '***' 0.001 '**' 0.01 '*' 0.05 '.' 0.1 ' ' 1\n\nlibrary(performance)\ncheck_heteroscedasticity(aov_fer2)\n\nOK: Error variance appears to be homoscedastic (p = 0.872).\n\ncheck_normality(aov_fer2)\n\nOK: residuals appear as normally distributed (p = 0.787).\n\n#Transforação\n\nlibrary(DHARMa)\nplot(simulateResiduals(aov_fer2))\n\n\n\n\n\n\n\nlibrary(emmeans)\nmedias_fer2 &lt;- emmeans(aov_fer2, ~TRAT, type = \"response\")\nmedias_fer2\n\n TRAT emmean     SE df lower.CL upper.CL\n 1     0.637 0.0107 21    0.614    0.659\n 2     0.596 0.0107 21    0.574    0.618\n 3     0.553 0.0107 21    0.530    0.575\n 4     0.527 0.0107 21    0.505    0.550\n 5     0.539 0.0107 21    0.517    0.561\n 6     0.523 0.0107 21    0.501    0.545\n 7     0.545 0.0107 21    0.523    0.567\n 8     0.549 0.0107 21    0.527    0.572\n\nResults are averaged over the levels of: BLOCO \nConfidence level used: 0.95 \n\npwpm(medias_fer2)\n\n         1        2        3        4        5        6        7       8\n1  [0.637]   0.1857   0.0004   &lt;.0001   &lt;.0001   &lt;.0001   0.0001  0.0002\n2  0.04058  [0.596]   0.1358   0.0039   0.0208   0.0020   0.0497  0.0880\n3  0.08380  0.04322  [0.553]   0.7032   0.9807   0.5313   0.9995  1.0000\n4  0.10920  0.06862  0.02540  [0.527]   0.9938   1.0000   0.9339  0.8261\n5  0.09775  0.05717  0.01395 -0.01145  [0.539]   0.9629   0.9999  0.9964\n6  0.11349  0.07292  0.02970  0.00429  0.01575  [0.523]   0.8261  0.6703\n7  0.09154  0.05097  0.00775 -0.01766 -0.00620 -0.02195  [0.545]  1.0000\n8  0.08725  0.04667  0.00345 -0.02195 -0.01050 -0.02624 -0.00429 [0.549]\n\nRow and column labels: TRAT\nUpper triangle: P values   adjust = \"tukey\"\nDiagonal: [Estimates] (emmean)   type = \"response\"\nLower triangle: Comparisons (estimate)   earlier vs. later\n\nlibrary(multcomp)\ncld(medias_fer2, Letters = LETTERS)\n\n TRAT emmean     SE df lower.CL upper.CL .group\n 6     0.523 0.0107 21    0.501    0.545  A    \n 4     0.527 0.0107 21    0.505    0.550  A    \n 5     0.539 0.0107 21    0.517    0.561  A    \n 7     0.545 0.0107 21    0.523    0.567  A    \n 8     0.549 0.0107 21    0.527    0.572  AB   \n 3     0.553 0.0107 21    0.530    0.575  AB   \n 2     0.596 0.0107 21    0.574    0.618   BC  \n 1     0.637 0.0107 21    0.614    0.659    C  \n\nResults are averaged over the levels of: BLOCO \nConfidence level used: 0.95 \nP value adjustment: tukey method for comparing a family of 8 estimates \nsignificance level used: alpha = 0.05 \nNOTE: If two or more means share the same grouping symbol,\n      then we cannot show them to be different.\n      But we also did not show them to be the same. \n\n\nPRODUTIVIDADE\n\naov_prod &lt;- lm(PROD ~ TRAT + BLOCO,\n              data = soja)\nanova(aov_prod)\n\nAnalysis of Variance Table\n\nResponse: PROD\n          Df  Sum Sq Mean Sq F value  Pr(&gt;F)  \nTRAT       7 2993906  427701  2.6367 0.04021 *\nBLOCO      3  105665   35222  0.2171 0.88340  \nResiduals 21 3406431  162211                  \n---\nSignif. codes:  0 '***' 0.001 '**' 0.01 '*' 0.05 '.' 0.1 ' ' 1\n\nlibrary(performance)\ncheck_heteroscedasticity(aov_prod)\n\nOK: Error variance appears to be homoscedastic (p = 0.215).\n\ncheck_normality(aov_prod)\n\nOK: residuals appear as normally distributed (p = 0.542).\n\n#Transforação\n\n\nlibrary(emmeans)\nmedias_prod &lt;- emmeans(aov_prod, ~TRAT)\nmedias_prod\n\n TRAT emmean  SE df lower.CL upper.CL\n 1      4219 201 21     3800     4638\n 2      4935 201 21     4516     5354\n 3      5110 201 21     4691     5529\n 4      5140 201 21     4721     5559\n 5      5122 201 21     4703     5541\n 6      5256 201 21     4837     5675\n 7      5128 201 21     4709     5546\n 8      5078 201 21     4659     5497\n\nResults are averaged over the levels of: BLOCO \nConfidence level used: 0.95 \n\npwpm(medias_prod)\n\n        1       2       3       4       5       6       7      8\n1  [4219]  0.2430  0.0792  0.0640  0.0728  0.0272  0.0700 0.0985\n2  -715.8  [4935]  0.9983  0.9953  0.9974  0.9430  0.9968 0.9995\n3  -890.8  -175.0  [5110]  1.0000  1.0000  0.9994  1.0000 1.0000\n4  -921.0  -205.3   -30.3  [5140]  1.0000  0.9999  1.0000 1.0000\n5  -902.8  -187.0   -12.0    18.3  [5122]  0.9997  1.0000 1.0000\n6 -1037.0  -321.3  -146.3  -116.0  -134.3  [5256]  0.9998 0.9981\n7  -908.3  -192.5   -17.5    12.8    -5.5   128.8  [5127] 1.0000\n8  -859.0  -143.3    31.7    62.0    43.7   178.0    49.2 [5078]\n\nRow and column labels: TRAT\nUpper triangle: P values   adjust = \"tukey\"\nDiagonal: [Estimates] (emmean) \nLower triangle: Comparisons (estimate)   earlier vs. later\n\nlibrary(multcomp)\ncld(medias_prod, Letters = LETTERS)\n\n TRAT emmean  SE df lower.CL upper.CL .group\n 1      4219 201 21     3800     4638  A    \n 2      4935 201 21     4516     5354  AB   \n 8      5078 201 21     4659     5497  AB   \n 3      5110 201 21     4691     5529  AB   \n 5      5122 201 21     4703     5541  AB   \n 7      5128 201 21     4709     5546  AB   \n 4      5140 201 21     4721     5559  AB   \n 6      5256 201 21     4837     5675   B   \n\nResults are averaged over the levels of: BLOCO \nConfidence level used: 0.95 \nP value adjustment: tukey method for comparing a family of 8 estimates \nsignificance level used: alpha = 0.05 \nNOTE: If two or more means share the same grouping symbol,\n      then we cannot show them to be different.\n      But we also did not show them to be the same. \n\nmedias_prod_grupo&lt;- cld(medias_prod, Letters = LETTERS)\n\nPlot dos rerultados - Uma tabela ficaria melhor\n\ndf_prod &lt;- data.frame(medias_prod_grupo)\ndf_prod |&gt; \n  ggplot(aes(TRAT, emmean))+\n  geom_point()+\n  ylim(3000,6500)+\n  geom_errorbar(aes(min = lower.CL, \n                    max = upper.CL),\n                width = 0.1)+\n  annotate(geom = \"text\", x = 1.2, y = 4200,\n           label = \"A\")\n\n\n\n\n\n\n\nknitr::kable(df_prod |&gt; dplyr::select(TRAT, emmean, .group))\n\n\n\n\n\nTRAT\nemmean\n.group\n\n\n\n\n1\n1\n4219.25\nA\n\n\n2\n2\n4935.00\nAB\n\n\n8\n8\n5078.25\nAB\n\n\n3\n3\n5110.00\nAB\n\n\n5\n5\n5122.00\nAB\n\n\n7\n7\n5127.50\nAB\n\n\n4\n4\n5140.25\nAB\n\n\n6\n6\n5256.25\nB\n\n\n\n\nlibrary(writexl)\n\nWarning: pacote 'writexl' foi compilado no R versão 4.4.1\n\nwrite_xlsx(df_prod, \"df.xlsx\")\n\nDADOS IRRIGAÇÃO\n\nlibrary(tidyverse)\nlibrary(gsheet)\ncurve &lt;- gsheet2tbl(\"https://docs.google.com/spreadsheets/d/1bq2N19DcZdtax2fQW9OHSGMR0X2__Z9T/edit#gid=1807247585\")\n\n\ncurve |&gt; \n  ggplot(aes(x= day, y= severity, color = Irrigation, shape = Irrigation))+\n  geom_line()+\n  geom_point()\n\n\n\n\n\n\n\n\n\nlibrary(epifitter)\n\nWarning: pacote 'epifitter' foi compilado no R versão 4.4.1\n\ncurve2 &lt;- curve |&gt;\n  group_by(Irrigation, rep) |&gt; \n  summarise(aacpd = AUDPC(day, severity)) #não está dando certo rever\n\n`summarise()` has grouped output by 'Irrigation'. You can override using the\n`.groups` argument.\n\nm_curve &lt;- lm(aacpd ~ Irrigation + factor(rep),\n              data = curve2)\n\nanova(m_curve)\n\nAnalysis of Variance Table\n\nResponse: aacpd\n            Df  Sum Sq  Mean Sq F value  Pr(&gt;F)  \nIrrigation   1 0.23602 0.236017  10.605 0.08275 .\nfactor(rep)  2 0.61291 0.306454  13.771 0.06770 .\nResiduals    2 0.04451 0.022254                  \n---\nSignif. codes:  0 '***' 0.001 '**' 0.01 '*' 0.05 '.' 0.1 ' ' 1\n\nlibrary(agricolae)\n\nWarning: pacote 'agricolae' foi compilado no R versão 4.4.1\n\ncv.model(m_curve)\n\n[1] 1.097572\n\n\nEficacia de controle, quanto foi reduzido do tratamento com maior valor em porcentagem. (Dá para usar para o café ao invés de AACPD)"
  },
  {
    "objectID": "aula_08.html#delineamento-em-blocos-casualisados",
    "href": "aula_08.html#delineamento-em-blocos-casualisados",
    "title": "Análise Estatística: Estatística inferencial - Parte 3",
    "section": "",
    "text": "Hoje iremos trabalhar com Delineamento Blocos Casualisados (DBC)\nPara trabalhar com blocos casualizados vamos tratar os Tratamentos e os Blocos como fatores.\n\nlibrary(tidyverse)\n\n── Attaching core tidyverse packages ──────────────────────── tidyverse 2.0.0 ──\n✔ dplyr     1.1.4     ✔ readr     2.1.5\n✔ forcats   1.0.0     ✔ stringr   1.5.1\n✔ ggplot2   3.5.1     ✔ tibble    3.2.1\n✔ lubridate 1.9.3     ✔ tidyr     1.3.1\n✔ purrr     1.0.2     \n── Conflicts ────────────────────────────────────────── tidyverse_conflicts() ──\n✖ dplyr::filter() masks stats::filter()\n✖ dplyr::lag()    masks stats::lag()\nℹ Use the conflicted package (&lt;http://conflicted.r-lib.org/&gt;) to force all conflicts to become errors\n\nlibrary(gsheet)\nsoja &lt;- gsheet2tbl(\"https://docs.google.com/spreadsheets/d/1bq2N19DcZdtax2fQW9OHSGMR0X2__Z9T/edit#gid=866852711\")\nsoja &lt;- soja |&gt; \n  mutate(TRAT = as.factor(TRAT),\n         BLOCO = as.factor(BLOCO))\n\n\ntheme_set(theme_bw())\n\nVamos plotar as os gráficos para observar se há diferença entre os tratamentos. Colocamos a média e o intervalo de confiança, o bootstrap aprende a média e o intervalo de confiança. #FALTOU PLOTAR OS DEMAIS#\n\ndfc &lt;- soja |&gt; \n  ggplot(aes(TRAT, DFC ))+\n  geom_jitter(width = 0.05, color = \"gray70\")+\n  stat_summary(fun.data = \"mean_cl_boot\", size =0.5, color = \"black\", alpha = 0.5)\ndfc\n\n\n\n\n\n\n\nfer &lt;- soja |&gt; \n  ggplot(aes(TRAT, FER ))+\n  geom_jitter(width = 0.05, color = \"gray70\")+\n  stat_summary(fun.data = \"mean_cl_boot\", size =0.5, color = \"black\", alpha = 0.5)\nfer\n\n\n\n\n\n\n\nprod &lt;- soja |&gt; \n  ggplot(aes(TRAT, PROD ))+\n  geom_jitter(width = 0.05, color = \"gray70\")+\n  stat_summary(fun.data = \"mean_cl_boot\", size =0.5, color = \"black\", alpha = 0.5)\nprod\n\n\n\n\n\n\n\n#library(r4pde)\nlibrary(patchwork)\n(dfc | fer | prod)\n\n\n\n\n\n\n\n\nAnova DBC\nMesmo não tendo efeito de bloco, deixa-se pois o experimento foi delineado em Blocos Casualisados.\n\naov_dfc &lt;- lm(DFC ~ TRAT + BLOCO,\n              data = soja)\nanova(aov_dfc)\n\nAnalysis of Variance Table\n\nResponse: DFC\n          Df  Sum Sq Mean Sq F value    Pr(&gt;F)    \nTRAT       7 149.299 21.3284 51.5490 8.218e-12 ***\nBLOCO      3   0.461  0.1537  0.3716    0.7743    \nResiduals 21   8.689  0.4138                      \n---\nSignif. codes:  0 '***' 0.001 '**' 0.01 '*' 0.05 '.' 0.1 ' ' 1\n\n\n\nlibrary(performance)\n\nWarning: pacote 'performance' foi compilado no R versão 4.4.1\n\ncheck_heteroscedasticity(aov_dfc)\n\nOK: Error variance appears to be homoscedastic (p = 0.532).\n\ncheck_normality(aov_dfc)\n\nOK: residuals appear as normally distributed (p = 0.978).\n\nlibrary(emmeans)\n\nWarning: pacote 'emmeans' foi compilado no R versão 4.4.1\n\n\nWelcome to emmeans.\nCaution: You lose important information if you filter this package's results.\nSee '? untidy'\n\nmedias_dfc &lt;- emmeans(aov_dfc, ~TRAT)\nmedias_dfc\n\n TRAT emmean    SE df lower.CL upper.CL\n 1     10.88 0.322 21    10.21    11.54\n 2      6.42 0.322 21     5.76     7.09\n 3      6.05 0.322 21     5.38     6.72\n 4      4.75 0.322 21     4.08     5.42\n 5      4.20 0.322 21     3.53     4.87\n 6      4.00 0.322 21     3.33     4.67\n 7      4.08 0.322 21     3.41     4.74\n 8      4.58 0.322 21     3.91     5.24\n\nResults are averaged over the levels of: BLOCO \nConfidence level used: 0.95 \n\npwpm(medias_dfc)\n\n        1       2       3       4       5       6       7       8\n1 [10.87]  &lt;.0001  &lt;.0001  &lt;.0001  &lt;.0001  &lt;.0001  &lt;.0001  &lt;.0001\n2   4.450 [ 6.42]  0.9896  0.0249  0.0017  0.0006  0.0009  0.0107\n3   4.825   0.375 [ 6.05]  0.1329  0.0107  0.0040  0.0058  0.0628\n4   6.125   1.675   1.300 [ 4.75]  0.9202  0.7173  0.8072  0.9999\n5   6.675   2.225   1.850   0.550 [ 4.20]  0.9998  1.0000  0.9896\n6   6.875   2.425   2.050   0.750   0.200 [ 4.00]  1.0000  0.9020\n7   6.800   2.350   1.975   0.675   0.125  -0.075 [ 4.07]  0.9499\n8   6.300   1.850   1.475   0.175  -0.375  -0.575  -0.500 [ 4.57]\n\nRow and column labels: TRAT\nUpper triangle: P values   adjust = \"tukey\"\nDiagonal: [Estimates] (emmean) \nLower triangle: Comparisons (estimate)   earlier vs. later\n\nlibrary(multcomp)\n\nCarregando pacotes exigidos: mvtnorm\n\n\nCarregando pacotes exigidos: survival\n\n\nWarning: pacote 'survival' foi compilado no R versão 4.4.1\n\n\nCarregando pacotes exigidos: TH.data\n\n\nCarregando pacotes exigidos: MASS\n\n\nWarning: pacote 'MASS' foi compilado no R versão 4.4.1\n\n\n\nAnexando pacote: 'MASS'\n\n\nO seguinte objeto é mascarado por 'package:patchwork':\n\n    area\n\n\nO seguinte objeto é mascarado por 'package:dplyr':\n\n    select\n\n\n\nAnexando pacote: 'TH.data'\n\n\nO seguinte objeto é mascarado por 'package:MASS':\n\n    geyser\n\ncld(medias_dfc, Letters = LETTERS)\n\n TRAT emmean    SE df lower.CL upper.CL .group\n 6      4.00 0.322 21     3.33     4.67  A    \n 7      4.08 0.322 21     3.41     4.74  A    \n 5      4.20 0.322 21     3.53     4.87  A    \n 8      4.58 0.322 21     3.91     5.24  AB   \n 4      4.75 0.322 21     4.08     5.42  AB   \n 3      6.05 0.322 21     5.38     6.72   BC  \n 2      6.42 0.322 21     5.76     7.09    C  \n 1     10.88 0.322 21    10.21    11.54     D \n\nResults are averaged over the levels of: BLOCO \nConfidence level used: 0.95 \nP value adjustment: tukey method for comparing a family of 8 estimates \nsignificance level used: alpha = 0.05 \nNOTE: If two or more means share the same grouping symbol,\n      then we cannot show them to be different.\n      But we also did not show them to be the same. \n\n\nFERRUGEM\n\naov_fer &lt;- lm(FER ~ TRAT + BLOCO,\n              data = soja)\nanova(aov_fer)\n\nAnalysis of Variance Table\n\nResponse: FER\n          Df Sum Sq Mean Sq F value    Pr(&gt;F)    \nTRAT       7 978.87 139.838 55.1717 4.218e-12 ***\nBLOCO      3   3.84   1.279  0.5045    0.6834    \nResiduals 21  53.23   2.535                      \n---\nSignif. codes:  0 '***' 0.001 '**' 0.01 '*' 0.05 '.' 0.1 ' ' 1\n\nlibrary(performance)\ncheck_heteroscedasticity(aov_fer)\n\nWarning: Heteroscedasticity (non-constant error variance) detected (p &lt; .001).\n\ncheck_normality(aov_fer)\n\nWarning: Non-normality of residuals detected (p = 0.008).\n\n#Transforação\n\nlibrary(DHARMa)\n\nWarning: pacote 'DHARMa' foi compilado no R versão 4.4.1\n\n\nThis is DHARMa 0.4.6. For overview type '?DHARMa'. For recent changes, type news(package = 'DHARMa')\n\nplot(simulateResiduals(aov_fer))\n\nqu = 0.25, log(sigma) = -3.082978 : outer Newton did not converge fully.\n\n\nqu = 0.25, log(sigma) = -3.153964 : outer Newton did not converge fully.\n\n\nqu = 0.25, log(sigma) = -3.330674 : outer Newton did not converge fully.\n\n\nqu = 0.25, log(sigma) = -3.25367 : outer Newton did not converge fully.\n\n\nqu = 0.25, log(sigma) = -3.254842 : outer Newton did not converge fully.\n\n\nqu = 0.25, log(sigma) = -3.25509 : outer Newton did not converge fully.\n\n\nqu = 0.25, log(sigma) = -3.254964 : outer Newton did not converge fully.\n\n\nqu = 0.75, log(sigma) = -2.678463 : outer Newton did not converge fully.\n\n\nqu = 0.75, log(sigma) = -2.88072 : outer Newton did not converge fully.\n\n\nqu = 0.75, log(sigma) = -3.005722 : outer Newton did not converge fully.\n\n\nqu = 0.75, log(sigma) = -3.130724 : outer Newton did not converge fully.\n\n\nqu = 0.75, log(sigma) = -3.160233 : outer Newton did not converge fully.\n\n\nqu = 0.75, log(sigma) = -3.913208 : outer Newton did not converge fully.\n\n\nqu = 0.75, log(sigma) = -3.91919 : outer Newton did not converge fully.\n\n\nqu = 0.75, log(sigma) = -3.918346 : outer Newton did not converge fully.\n\n\n\n\n\n\n\n\nlibrary(emmeans)\nmedias_fer &lt;- emmeans(aov_fer, ~TRAT, type = \"response\")\nmedias_fer\n\n TRAT emmean    SE df lower.CL upper.CL\n 1     20.25 0.796 21    18.59    21.91\n 2      5.88 0.796 21     4.22     7.53\n 3      4.00 0.796 21     2.34     5.66\n 4      3.12 0.796 21     1.47     4.78\n 5      3.25 0.796 21     1.59     4.91\n 6      3.00 0.796 21     1.34     4.66\n 7      3.38 0.796 21     1.72     5.03\n 8      3.50 0.796 21     1.84     5.16\n\nResults are averaged over the levels of: BLOCO \nConfidence level used: 0.95 \n\npwpm(medias_fer)\n\n        1       2       3       4       5       6       7       8\n1 [20.25]  &lt;.0001  &lt;.0001  &lt;.0001  &lt;.0001  &lt;.0001  &lt;.0001  &lt;.0001\n2  14.375 [ 5.87]  0.7076  0.2722  0.3229  0.2273  0.3792  0.4404\n3  16.250   1.875 [ 4.00]  0.9926  0.9971  0.9840  0.9991  0.9998\n4  17.125   2.750   0.875 [ 3.12]  1.0000  1.0000  1.0000  1.0000\n5  17.000   2.625   0.750  -0.125 [ 3.25]  1.0000  1.0000  1.0000\n6  17.250   2.875   1.000   0.125   0.250 [ 3.00]  1.0000  0.9998\n7  16.875   2.500   0.625  -0.250  -0.125  -0.375 [ 3.37]  1.0000\n8  16.750   2.375   0.500  -0.375  -0.250  -0.500  -0.125 [ 3.50]\n\nRow and column labels: TRAT\nUpper triangle: P values   adjust = \"tukey\"\nDiagonal: [Estimates] (emmean)   type = \"response\"\nLower triangle: Comparisons (estimate)   earlier vs. later\n\nlibrary(multcomp)\ncld(medias_fer, Letters = LETTERS)\n\n TRAT emmean    SE df lower.CL upper.CL .group\n 6      3.00 0.796 21     1.34     4.66  A    \n 4      3.12 0.796 21     1.47     4.78  A    \n 5      3.25 0.796 21     1.59     4.91  A    \n 7      3.38 0.796 21     1.72     5.03  A    \n 8      3.50 0.796 21     1.84     5.16  A    \n 3      4.00 0.796 21     2.34     5.66  A    \n 2      5.88 0.796 21     4.22     7.53  A    \n 1     20.25 0.796 21    18.59    21.91   B   \n\nResults are averaged over the levels of: BLOCO \nConfidence level used: 0.95 \nP value adjustment: tukey method for comparing a family of 8 estimates \nsignificance level used: alpha = 0.05 \nNOTE: If two or more means share the same grouping symbol,\n      then we cannot show them to be different.\n      But we also did not show them to be the same. \n\n\nTransformação Box-Cox\n\nb &lt;- boxcox(lm(soja$FER ~1))\n\n\n\n\n\n\n\nlambda &lt;- b$x[which.max(b$y)]\nlambda\n\n[1] -1.555556\n\nsoja$FER2 &lt;-(soja$FER ^lambda -1)/lambda\n\n\naov_fer2 &lt;- lm(FER2 ~ TRAT + BLOCO,\n              data = soja)\nanova(aov_fer2)\n\nAnalysis of Variance Table\n\nResponse: FER2\n          Df   Sum Sq   Mean Sq F value    Pr(&gt;F)    \nTRAT       7 0.041641 0.0059488 12.9020 2.436e-06 ***\nBLOCO      3 0.005895 0.0019649  4.2616   0.01687 *  \nResiduals 21 0.009683 0.0004611                      \n---\nSignif. codes:  0 '***' 0.001 '**' 0.01 '*' 0.05 '.' 0.1 ' ' 1\n\nlibrary(performance)\ncheck_heteroscedasticity(aov_fer2)\n\nOK: Error variance appears to be homoscedastic (p = 0.872).\n\ncheck_normality(aov_fer2)\n\nOK: residuals appear as normally distributed (p = 0.787).\n\n#Transforação\n\nlibrary(DHARMa)\nplot(simulateResiduals(aov_fer2))\n\n\n\n\n\n\n\nlibrary(emmeans)\nmedias_fer2 &lt;- emmeans(aov_fer2, ~TRAT, type = \"response\")\nmedias_fer2\n\n TRAT emmean     SE df lower.CL upper.CL\n 1     0.637 0.0107 21    0.614    0.659\n 2     0.596 0.0107 21    0.574    0.618\n 3     0.553 0.0107 21    0.530    0.575\n 4     0.527 0.0107 21    0.505    0.550\n 5     0.539 0.0107 21    0.517    0.561\n 6     0.523 0.0107 21    0.501    0.545\n 7     0.545 0.0107 21    0.523    0.567\n 8     0.549 0.0107 21    0.527    0.572\n\nResults are averaged over the levels of: BLOCO \nConfidence level used: 0.95 \n\npwpm(medias_fer2)\n\n         1        2        3        4        5        6        7       8\n1  [0.637]   0.1857   0.0004   &lt;.0001   &lt;.0001   &lt;.0001   0.0001  0.0002\n2  0.04058  [0.596]   0.1358   0.0039   0.0208   0.0020   0.0497  0.0880\n3  0.08380  0.04322  [0.553]   0.7032   0.9807   0.5313   0.9995  1.0000\n4  0.10920  0.06862  0.02540  [0.527]   0.9938   1.0000   0.9339  0.8261\n5  0.09775  0.05717  0.01395 -0.01145  [0.539]   0.9629   0.9999  0.9964\n6  0.11349  0.07292  0.02970  0.00429  0.01575  [0.523]   0.8261  0.6703\n7  0.09154  0.05097  0.00775 -0.01766 -0.00620 -0.02195  [0.545]  1.0000\n8  0.08725  0.04667  0.00345 -0.02195 -0.01050 -0.02624 -0.00429 [0.549]\n\nRow and column labels: TRAT\nUpper triangle: P values   adjust = \"tukey\"\nDiagonal: [Estimates] (emmean)   type = \"response\"\nLower triangle: Comparisons (estimate)   earlier vs. later\n\nlibrary(multcomp)\ncld(medias_fer2, Letters = LETTERS)\n\n TRAT emmean     SE df lower.CL upper.CL .group\n 6     0.523 0.0107 21    0.501    0.545  A    \n 4     0.527 0.0107 21    0.505    0.550  A    \n 5     0.539 0.0107 21    0.517    0.561  A    \n 7     0.545 0.0107 21    0.523    0.567  A    \n 8     0.549 0.0107 21    0.527    0.572  AB   \n 3     0.553 0.0107 21    0.530    0.575  AB   \n 2     0.596 0.0107 21    0.574    0.618   BC  \n 1     0.637 0.0107 21    0.614    0.659    C  \n\nResults are averaged over the levels of: BLOCO \nConfidence level used: 0.95 \nP value adjustment: tukey method for comparing a family of 8 estimates \nsignificance level used: alpha = 0.05 \nNOTE: If two or more means share the same grouping symbol,\n      then we cannot show them to be different.\n      But we also did not show them to be the same. \n\n\nPRODUTIVIDADE\n\naov_prod &lt;- lm(PROD ~ TRAT + BLOCO,\n              data = soja)\nanova(aov_prod)\n\nAnalysis of Variance Table\n\nResponse: PROD\n          Df  Sum Sq Mean Sq F value  Pr(&gt;F)  \nTRAT       7 2993906  427701  2.6367 0.04021 *\nBLOCO      3  105665   35222  0.2171 0.88340  \nResiduals 21 3406431  162211                  \n---\nSignif. codes:  0 '***' 0.001 '**' 0.01 '*' 0.05 '.' 0.1 ' ' 1\n\nlibrary(performance)\ncheck_heteroscedasticity(aov_prod)\n\nOK: Error variance appears to be homoscedastic (p = 0.215).\n\ncheck_normality(aov_prod)\n\nOK: residuals appear as normally distributed (p = 0.542).\n\n#Transforação\n\n\nlibrary(emmeans)\nmedias_prod &lt;- emmeans(aov_prod, ~TRAT)\nmedias_prod\n\n TRAT emmean  SE df lower.CL upper.CL\n 1      4219 201 21     3800     4638\n 2      4935 201 21     4516     5354\n 3      5110 201 21     4691     5529\n 4      5140 201 21     4721     5559\n 5      5122 201 21     4703     5541\n 6      5256 201 21     4837     5675\n 7      5128 201 21     4709     5546\n 8      5078 201 21     4659     5497\n\nResults are averaged over the levels of: BLOCO \nConfidence level used: 0.95 \n\npwpm(medias_prod)\n\n        1       2       3       4       5       6       7      8\n1  [4219]  0.2430  0.0792  0.0640  0.0728  0.0272  0.0700 0.0985\n2  -715.8  [4935]  0.9983  0.9953  0.9974  0.9430  0.9968 0.9995\n3  -890.8  -175.0  [5110]  1.0000  1.0000  0.9994  1.0000 1.0000\n4  -921.0  -205.3   -30.3  [5140]  1.0000  0.9999  1.0000 1.0000\n5  -902.8  -187.0   -12.0    18.3  [5122]  0.9997  1.0000 1.0000\n6 -1037.0  -321.3  -146.3  -116.0  -134.3  [5256]  0.9998 0.9981\n7  -908.3  -192.5   -17.5    12.8    -5.5   128.8  [5127] 1.0000\n8  -859.0  -143.3    31.7    62.0    43.7   178.0    49.2 [5078]\n\nRow and column labels: TRAT\nUpper triangle: P values   adjust = \"tukey\"\nDiagonal: [Estimates] (emmean) \nLower triangle: Comparisons (estimate)   earlier vs. later\n\nlibrary(multcomp)\ncld(medias_prod, Letters = LETTERS)\n\n TRAT emmean  SE df lower.CL upper.CL .group\n 1      4219 201 21     3800     4638  A    \n 2      4935 201 21     4516     5354  AB   \n 8      5078 201 21     4659     5497  AB   \n 3      5110 201 21     4691     5529  AB   \n 5      5122 201 21     4703     5541  AB   \n 7      5128 201 21     4709     5546  AB   \n 4      5140 201 21     4721     5559  AB   \n 6      5256 201 21     4837     5675   B   \n\nResults are averaged over the levels of: BLOCO \nConfidence level used: 0.95 \nP value adjustment: tukey method for comparing a family of 8 estimates \nsignificance level used: alpha = 0.05 \nNOTE: If two or more means share the same grouping symbol,\n      then we cannot show them to be different.\n      But we also did not show them to be the same. \n\nmedias_prod_grupo&lt;- cld(medias_prod, Letters = LETTERS)\n\nPlot dos rerultados - Uma tabela ficaria melhor\n\ndf_prod &lt;- data.frame(medias_prod_grupo)\ndf_prod |&gt; \n  ggplot(aes(TRAT, emmean))+\n  geom_point()+\n  ylim(3000,6500)+\n  geom_errorbar(aes(min = lower.CL, \n                    max = upper.CL),\n                width = 0.1)+\n  annotate(geom = \"text\", x = 1.2, y = 4200,\n           label = \"A\")\n\n\n\n\n\n\n\nknitr::kable(df_prod |&gt; dplyr::select(TRAT, emmean, .group))\n\n\n\n\n\nTRAT\nemmean\n.group\n\n\n\n\n1\n1\n4219.25\nA\n\n\n2\n2\n4935.00\nAB\n\n\n8\n8\n5078.25\nAB\n\n\n3\n3\n5110.00\nAB\n\n\n5\n5\n5122.00\nAB\n\n\n7\n7\n5127.50\nAB\n\n\n4\n4\n5140.25\nAB\n\n\n6\n6\n5256.25\nB\n\n\n\n\nlibrary(writexl)\n\nWarning: pacote 'writexl' foi compilado no R versão 4.4.1\n\nwrite_xlsx(df_prod, \"df.xlsx\")\n\nDADOS IRRIGAÇÃO\n\nlibrary(tidyverse)\nlibrary(gsheet)\ncurve &lt;- gsheet2tbl(\"https://docs.google.com/spreadsheets/d/1bq2N19DcZdtax2fQW9OHSGMR0X2__Z9T/edit#gid=1807247585\")\n\n\ncurve |&gt; \n  ggplot(aes(x= day, y= severity, color = Irrigation, shape = Irrigation))+\n  geom_line()+\n  geom_point()\n\n\n\n\n\n\n\n\n\nlibrary(epifitter)\n\nWarning: pacote 'epifitter' foi compilado no R versão 4.4.1\n\ncurve2 &lt;- curve |&gt;\n  group_by(Irrigation, rep) |&gt; \n  summarise(aacpd = AUDPC(day, severity)) #não está dando certo rever\n\n`summarise()` has grouped output by 'Irrigation'. You can override using the\n`.groups` argument.\n\nm_curve &lt;- lm(aacpd ~ Irrigation + factor(rep),\n              data = curve2)\n\nanova(m_curve)\n\nAnalysis of Variance Table\n\nResponse: aacpd\n            Df  Sum Sq  Mean Sq F value  Pr(&gt;F)  \nIrrigation   1 0.23602 0.236017  10.605 0.08275 .\nfactor(rep)  2 0.61291 0.306454  13.771 0.06770 .\nResiduals    2 0.04451 0.022254                  \n---\nSignif. codes:  0 '***' 0.001 '**' 0.01 '*' 0.05 '.' 0.1 ' ' 1\n\nlibrary(agricolae)\n\nWarning: pacote 'agricolae' foi compilado no R versão 4.4.1\n\ncv.model(m_curve)\n\n[1] 1.097572\n\n\nEficacia de controle, quanto foi reduzido do tratamento com maior valor em porcentagem. (Dá para usar para o café ao invés de AACPD)"
  },
  {
    "objectID": "aula_06.html",
    "href": "aula_06.html",
    "title": "Análise Estatística: Estatística inferencial - Parte 1",
    "section": "",
    "text": "Iniciaremos este tópico importando o dataset que iremos trabalhar.\n\nlibrary(gsheet)\nmg = gsheet2tbl(\"https://docs.google.com/spreadsheets/d/1bq2N19DcZdtax2fQW9OHSGMR0X2__Z9T/edit#gid=983033137\")\n\nO pacote gsheet permite importar dados diretamente de uma planilha do Google Sheets. A função gsheet2tbl converte a planilha em um tibble (um tipo de data frame otimizado).\nCaso haja dúvidas, existe um tópico específico tratando da importação dos dados neste site.\n\n\n\n\n\nUm boxplot, também conhecido como diagrama de caixa, é uma representação gráfica que resume a distribuição de um conjunto de dados baseado em cinco estatísticas: mínimo, primeiro quartil (Q1), mediana (Q2), terceiro quartil (Q3) e máximo e também pode destacar outliers.\nO pacote tidyverse engloba diversos pacotes, como o ggplot2 que é uma das bibliotecas mais populares para visualização de dados em R. Com esta biblioteca podemos utilizar a função geom_boxplot que cria um boxplot. Podemos aplicar temas aplicando um tema preto e branco ao gráfico, melhorando a clareza visual com a função theme_bw().\nUm exemplo de boxplot pode ser plotado utilizando os dados já carregados acima:\n\nlibrary(tidyverse)\n\n── Attaching core tidyverse packages ──────────────────────── tidyverse 2.0.0 ──\n✔ dplyr     1.1.4     ✔ readr     2.1.5\n✔ forcats   1.0.0     ✔ stringr   1.5.1\n✔ ggplot2   3.5.1     ✔ tibble    3.2.1\n✔ lubridate 1.9.3     ✔ tidyr     1.3.1\n✔ purrr     1.0.2     \n── Conflicts ────────────────────────────────────────── tidyverse_conflicts() ──\n✖ dplyr::filter() masks stats::filter()\n✖ dplyr::lag()    masks stats::lag()\nℹ Use the conflicted package (&lt;http://conflicted.r-lib.org/&gt;) to force all conflicts to become errors\n\nmg |&gt; \n  ggplot(aes(trat, comp))+\n  geom_boxplot()+\n  theme_bw()\n\n\n\n\n\n\n\n\nO boxplot é útil para visualizar a distribuição dos dados, incluindo a mediana, os quartis e possíveis outliers. O boxplot ainda pode ajuda a identificar a dispersão dos dados e a presença de possíveis valores atípicos. Além disso podemos identificar a diferença entre dois tratamentos usando um boxplot, começando pela observação a linha mediana dentro de cada caixa, que representa o valor central dos dados.\nComo as medianas estão em diferentes níveis, isso sugere que as medianas dos tratamentos são diferentes. Em seguida, examinamos a posição e a extensão das caixas (intervalo interquartil, IQR), e como as caixas dos dois tratamentos não se sobrepõem, as distribuições dos tratamentos são similares. Menos sobreposição indica uma maior probabilidade de diferença significativa entre os tratamentos.\n\n\n\n\nO Teste t é utilizado para comparar as médias de duas amostras, enquanto o Teste F, que veremos mais abaixo, seria para três ou mais. Ele verifica se a diferença entre as médias é estatisticamente significativa, ou seja, se é provável que as diferenças observadas se devam ao acaso.\n\n\nNo nosso exemplo, precisamos separar os dados para isso devemos passar do formato longo para o formato largo. A função pivot_wider transforma os dados de formato longo para formato largo. No formato longo, cada linha é uma observação única, enquanto no formato largo, cada linha representa um grupo de observações.\n\nmg2 &lt;- mg |&gt; \n  pivot_wider(names_from = trat, values_from = comp)\n\n\n\n\nA função t.test(),como o próprio nomde diz, realiza o teste t, que compara as médias de duas amostras para determinar se elas são estatisticamente diferentes. Um p-valor baixo (geralmente &lt; 0,05) indica que as médias são significativamente diferentes.\n\n# Teste t\nteste1 &lt;- t.test(mg2$Mg2, mg2$control)\nteste1\n\n\n    Welch Two Sample t-test\n\ndata:  mg2$Mg2 and mg2$control\nt = -8.1549, df = 17.354, p-value = 2.423e-07\nalternative hypothesis: true difference in means is not equal to 0\n95 percent confidence interval:\n -6.490393 -3.825607\nsample estimates:\nmean of x mean of y \n   10.520    15.678 \n\n\n\n\nA hipótese H0, também conhecida como hipótese nula, é uma afirmação inicial que presume que não há efeito ou diferença significativa em um estudo ou experimento. É uma posição de “inocência” até que evidências suficientes provem o contrário. Na prática estatística, a hipótese nula é formulada para ser testada e possivelmente rejeitada em favor de uma hipótese alternativa (H1), que sugere a existência de um efeito ou diferença.\nNo caso do exemplo acima, nossa hiótese é de que as médias dos tratamentos não diferem entre si. Como o p-valor ou p-value foi menor do que 0,05, rejeitamos nossa hipótese nula (H0) e aceitamos a hípotese alternativa (H1), que no caso as médias dos tratamentos diferem entre si.\n\n\n\n\nA função shapiro.test(), testa a hipótese de que os dados vêm de uma distribuição normal. A normalidade dos dados é um pressuposto importante para a validade do teste t.\n\nshapiro.test(mg2$control)\n\n\n    Shapiro-Wilk normality test\n\ndata:  mg2$control\nW = 0.93886, p-value = 0.5404\n\nshapiro.test(mg2$Mg2)\n\n\n    Shapiro-Wilk normality test\n\ndata:  mg2$Mg2\nW = 0.97269, p-value = 0.9146\n\n\nUm p-valor alto indica que os dados são normalmente distribuídos, como ocorre no caso acima.\n\n\n\nA função hist() é utilizada para criar um histograma, que mostra a distribuição dos dados. É útil para visualizar a forma da distribuição e identificar se ela é aproximadamente normal.\n\n# Histograma\nhist(mg2$control)\n\n\n\n\n\n\n\nhist(mg2$Mg2)\n\n\n\n\n\n\n\n\nO histograma do tratamento controle segue nitidamente uma distribuição Gaussiana, enquanto a distribuição do tratamento Mg2 não segue uma distribuição normal.\n\n\n\nA função var.test() realiza a comparação das variâncias de duas amostras para verificar se são homogeneamente distribuídas. A homogeneidade de variância é outro pressuposto importante para os testes estatísticos.\n\n#Teste de homogêneidade de variância\nvar.test(mg2$control, mg2$Mg2) #Se a variância não for homogênea tem que informar, var.equal = FALSE\n\n\n    F test to compare two variances\n\ndata:  mg2$control and mg2$Mg2\nF = 0.67654, num df = 9, denom df = 9, p-value = 0.5698\nalternative hypothesis: true ratio of variances is not equal to 1\n95 percent confidence interval:\n 0.1680428 2.7237436\nsample estimates:\nratio of variances \n         0.6765394 \n\n\nUm p-valor alto indica que as variâncias são homogêneas, como ocorre no exemplo acima (p-value = 0.5698).\n\n\n\nA função qqplot() é uma ferramenta valiosa para comparar distribuições de dados. Ela é amplamente usada para verificar a normalidade de uma amostra e para comparar distribuições de viariância de duas amostras diferentes. A interpretação do QQ plot é baseada no quão bem os pontos seguem uma linha reta, com desvios significativos indicando diferenças entre as distribuições.\n\nqqplot(mg2$control, mg2$Mg2)\n\n\n\n\n\n\n\n\n\n\n\nO reaport() gera um relatório detalhado dos resultados do teste t pareado.\n\nlibrary(report)\n\nWarning: pacote 'report' foi compilado no R versão 4.4.1\n\nreport(teste1)\n\nWarning: Function `format_text()` is deprecated and will be removed in a future\n  release. Please use `text_format()` instead.\n\n\nEffect sizes were labelled following Cohen's (1988) recommendations.\n\nThe Welch Two Sample t-test testing the difference between mg2$Mg2 and\nmg2$control (mean of x = 10.52, mean of y = 15.68) suggests that the effect is\nnegative, statistically significant, and large (difference = -5.16, 95% CI\n[-6.49, -3.83], t(17.35) = -8.15, p &lt; .001; Cohen's d = -3.65, 95% CI [-5.12,\n-2.14])\n\n\nUtilizamos o teste t para sabermos se há diferença entre as médias, o p-valor foi &lt;0,05, porém temos que calcular se as médias possuem normalidade, para saber se podemos confiar no teste t. Segundo o teste de shapiro-wilk os dados seguem normalidade (não rejeita Ho), quando plotamos o histograma dos dados podemos observar que segue uma distribuição normal.\nOutra observação que devemos fazer é se as variáveis são homogênas usando o teste F. E neste caso as variâncias são homogêneas (não rejeita Ho) e o boxplot já dava esses indicativos visuais. Podemos fazer também o grafico QQ Plot para mostras a variância dos dados, como foi realizado acima.\n\n\n\n\nPara dados dependentes, realiza-se um teste t pareado. Esse teste é usado quando as amostras são dependentes, como medições antes e depois do tratamento no mesmo grupo de indivíduos. Para fazer o teste t pareado tem que colocar o argumento paired = TRUE no código.\n\n\nInicialmente devemos importar e visualizar os dados, lembrando que gsheet() importa dados do Google Sheets e ggplot2 e geom_boxplot() cria um boxplot para visualização.\n\nlibrary(gsheet)\nescala = gsheet2tbl(\"https://docs.google.com/spreadsheets/d/1bq2N19DcZdtax2fQW9OHSGMR0X2__Z9T/edit?gid=1729131173\")\n\nescala |&gt; \n  ggplot(aes(assessment, acuracia))+\n  geom_boxplot()+\n  theme_bw()\n\n\n\n\n\n\n\n\nO boxplot, nos indica que há diferença entre os tratamentos, caso haja dúvidas sobre a interpretação há um tópico acima sobre a interpretação do boxplot.\n\n\n\nAntes de realizarmos os testes é necessário preparar os dados, selecionando as colunas específicas através da função select(). Além disso devemos transformar os dados de formato longo para formato largo pela função pivot_wider().\n\nescala2 &lt;- escala |&gt; \n  select(assessment, rater, acuracia) |&gt; \n  pivot_wider(names_from = assessment,\n              values_from = acuracia)\n\n\n\n\nPara o teste t pareado, temos que lembrar de colocar o argumento paried = TRUE, que por default ele vem como FALSE, este argumento indica que as amostras são pareadas. Assim, a função t.test(paired = TRUE) realiza um teste t pareado, que é usado quando as amostras são dependentes.\n\n#Tete t pareado\nteste2 &lt;- t.test(escala2$Aided1, escala2$Unaided, paried = TRUE, var.equal = FALSE)\n#Obs.: Os dados foram alterados para dar não paramétrico.\nteste2\n\n\n    Welch Two Sample t-test\n\ndata:  escala2$Aided1 and escala2$Unaided\nt = 4.4134, df = 9.8561, p-value = 0.001354\nalternative hypothesis: true difference in means is not equal to 0\n95 percent confidence interval:\n 0.1161235 0.3538765\nsample estimates:\nmean of x mean of y \n    0.917     0.682 \n\n\nOs dados foram alterados para que pudessemos fazer uma análise não paramétrica. Portanto, pelo teste de homogeneidade, os dados não possuem homogêneidade de variância e assim temos que colocar var.equal = FALSE. A função var.equal = FALSE indica que as variâncias das duas amostras não são iguais, ajustando o cálculo do teste t para essa condição.\nO p-valor pelo teste t pareado é igaual a 0.001354, logo. com o p-valor &lt; 0.05, rejeitase H0 a 5% de probabiliade pelo teste t pareado.\n\n\n\nUsamos a função shapiro.test(), que testa a normalidade dos dados em cada grupo. Para mais detalhes sobre normalidade, veja nos tópicos acima.\n\n#Teste de normalidade\nshapiro.test(escala2$Unaided)\n\n\n    Shapiro-Wilk normality test\n\ndata:  escala2$Unaided\nW = 0.7748, p-value = 0.007155\n\nshapiro.test(escala2$Aided1)\n\n\n    Shapiro-Wilk normality test\n\ndata:  escala2$Aided1\nW = 0.92852, p-value = 0.4335\n\n\nSegundo o teste de normalidade de Shapiro-Wilk, a variável Unaided não segue uma distribuição normal (p-valor &lt; 0.05), enquanto a variável Aided1 apresentou normalidade (p-valor &gt; 0.05).\n\n\n\nA função hist() cria histogramas para visualizar a distribuição dos dados.\n\n#Histograma\nhist(escala2$Unaided)\n\n\n\n\n\n\n\nhist(escala2$Aided1)\n\n\n\n\n\n\n\n\nObservando os plots dos histogramas, ambas as variáveis Unaided e Aided, não possuem uma distribuição normal. Apesar da variável Aided1 ter apresentado normalidade (p-valor &gt; 0.05) pelo teste de Shapiro-Wilk. Em experimentos, costuma-se considerar os testes em detrimento dos gráficos.\n\n\n\nA função var.test() compara as variâncias dos dois grupos.\n\n#Teste de homogêneidade de variância\nvar.test(escala2$Unaided, escala2$Aided1) #Se a variância não for homogênea tem que informar, var.equal = FALSE\n\n\n    F test to compare two variances\n\ndata:  escala2$Unaided and escala2$Aided1\nF = 20.978, num df = 9, denom df = 9, p-value = 0.000106\nalternative hypothesis: true ratio of variances is not equal to 1\n95 percent confidence interval:\n  5.210754 84.459185\nsample estimates:\nratio of variances \n          20.97847 \n\n#qqplot(escala2$control, escala2$Aided1)\n\nPara o nosso exemplo, utilizamos o teste F para comparação de duas variâncias, que apresentou um p-valor &lt; 0.05, ou seja, rejeita-se H0 e aceita-se H1, as variâncias não apresentam homogeneidade pelo teste F a 5% de probabilidade.\n\n\n\nComo já mencionado, o R possui o pacote report, que por sua vez possui a função report(), que faz um sumário do teste armazenado em um objeto. No nosso exemplo:\n\nreport(teste2)\n\nWarning: Function `format_text()` is deprecated and will be removed in a future\n  release. Please use `text_format()` instead.\n\n\nEffect sizes were labelled following Cohen's (1988) recommendations.\n\nThe Welch Two Sample t-test testing the difference between escala2$Aided1 and\nescala2$Unaided (mean of x = 0.92, mean of y = 0.68) suggests that the effect\nis positive, statistically significant, and large (difference = 0.23, 95% CI\n[0.12, 0.35], t(9.86) = 4.41, p = 0.001; Cohen's d = 1.97, 95% CI [0.72, 3.18])\n\n\n\n\n\nQuando os dados não atendem aos pressupostos do teste t (normalidade e homogeneidade de variância), pode-se usar uma alternativa não paramétrica, como o teste de Wilcoxon que é um teste equivalente ao teste t, mas não assume uma distribuição normal dos dados.\nPara isso, utilizamos a função wilcox.test(), uma função nativa do R. Esta função realiza o teste de Wilcoxon, entretanto a a necessidade de colocar o parametro paired = TRUE para amostras pareadas.\n\nteste3 &lt;- wilcox.test(escala2$Aided1,\n            escala2$Unaided,\n            paired = TRUE) #Lembrar que é dado pareado, logo paired = TRUE\n\nWarning in wilcox.test.default(escala2$Aided1, escala2$Unaided, paired = TRUE):\nnão é possível computar o valor de p exato com o de desempate\n\nteste3\n\n\n    Wilcoxon signed rank test with continuity correction\n\ndata:  escala2$Aided1 and escala2$Unaided\nV = 55, p-value = 0.005889\nalternative hypothesis: true location shift is not equal to 0\n\n\n\n\n\n\nPara comparar três ou mais grupos, utiliza-se o teste f através da ANOVA (Análise de Variância), que verifica se há diferenças significativas entre as médias de mais de dois grupos.\n\n\nSempre inciamos importando os dados, para maiores informações sobre como importar os dados, verifique o tópico específico. O mesmo é valido para o boxplot.\n\nmicelial = gsheet2tbl(\"https://docs.google.com/spreadsheets/d/1bq2N19DcZdtax2fQW9OHSGMR0X2__Z9T/edit#gid=959387827\")\n\nmicelial |&gt; \n  ggplot(aes(especie, tcm))+\n  geom_boxplot()+\n  theme_bw()\n\n\n\n\n\n\n\n\nAnálisando o box-plot, ao menos dois tratamentos diferem das demais, Fasi e Fgra. Entretanto, é necessário que sejam feitos testes para saber realmente há diferença e se seguem os pressupostos de normalidade e homogeneidade.\n\n\n\nPara realizarmos a ANOVA, podemos usar a função aov() ou lm(). Neste exemplo usaremos a função lm(), que cria um modelo linear que relaciona a variável de interesse (tcm) com os grupos (especie). Ao colocarmos espécie -1 já é calculada a média da estimativa.\nA função anova() realiza a análise de variância (ANOVA), que compara as médias de três ou mais grupos para determinar se há diferenças significativas.\n\nm1 &lt;- lm(tcm ~ especie -1, data = micelial)\nanova(m1)\n\nAnalysis of Variance Table\n\nResponse: tcm\n          Df Sum Sq Mean Sq F value    Pr(&gt;F)    \nespecie    5 51.677 10.3354   552.2 &lt; 2.2e-16 ***\nResiduals 25  0.468  0.0187                      \n---\nSignif. codes:  0 '***' 0.001 '**' 0.01 '*' 0.05 '.' 0.1 ' ' 1\n\nshapiro.test(m1$residuals)\n\n\n    Shapiro-Wilk normality test\n\ndata:  m1$residuals\nW = 0.9821, p-value = 0.8782\n\nbartlett.test(tcm ~ especie, data = micelial)\n\n\n    Bartlett test of homogeneity of variances\n\ndata:  tcm by especie\nBartlett's K-squared = 4.4367, df = 4, p-value = 0.3501\n\n\nSegundo os testes de Shapiro-Wilk, e Bartelett os dados apresentam normalidade e homogeneidade de variância, respectivamente, a 5% de probailidade (p-valor &gt; 0.05). Segundo a ANOVA, ao menos uma das médias difere das demais pelo teste F ao nível de 5% de probabilidade (p-valor &gt; 0.05).\n\n\nA função summary() fornece um resumo estatístico do modelo linear, incluindo coeficientes, erros padrão, valores t e p-valores.\n\nsummary(m1)\n\n\nCall:\nlm(formula = tcm ~ especie - 1, data = micelial)\n\nResiduals:\n     Min       1Q   Median       3Q      Max \n-0.23667 -0.09667  0.01583  0.08833  0.28333 \n\nCoefficients:\n            Estimate Std. Error t value Pr(&gt;|t|)    \nespecieFasi  1.57167    0.05585   28.14  &lt; 2e-16 ***\nespecieFaus  1.23667    0.05585   22.14  &lt; 2e-16 ***\nespecieFcor  1.32167    0.05585   23.66  &lt; 2e-16 ***\nespecieFgra  0.91167    0.05585   16.32 7.66e-15 ***\nespecieFmer  1.42667    0.05585   25.54  &lt; 2e-16 ***\n---\nSignif. codes:  0 '***' 0.001 '**' 0.01 '*' 0.05 '.' 0.1 ' ' 1\n\nResidual standard error: 0.1368 on 25 degrees of freedom\nMultiple R-squared:  0.991, Adjusted R-squared:  0.9892 \nF-statistic: 552.2 on 5 and 25 DF,  p-value: &lt; 2.2e-16\n\n\nOs resultados indicam que todas as espécies têm médias estimadas de tcm significativamente diferentes de zero (p &lt; 0.001 para todas). O modelo ajustado explica 99.1% da variabilidade total dos dados (R-squared = 0.991).\nA ANOVA sugere que há diferenças significativas nas médias de tcm entre as espécies (p &lt; 2.2e-16). O modelo apresenta um bom ajuste com um erro padrão residual baixo (0.1368) e coeficientes altamente significativos.\n\n\n\n\nPara comparar as médias dos grupos, usamos o pacote emmeans. Este pacote calcula as estimativas marginais dos efeitos e facilita a comparação entre os grupos.\nO pacote multcomp é utilizado para realizar comparações múltiplas entre as médias dos grupos. A função cld() gera diferenciadores compactos que indicam quais médias são significativamente diferentes entre si.\n\nlibrary(emmeans)\n\nWarning: pacote 'emmeans' foi compilado no R versão 4.4.1\n\n\nWelcome to emmeans.\nCaution: You lose important information if you filter this package's results.\nSee '? untidy'\n\nmedias1 &lt;- emmeans(m1, ~ especie)\nmedias1\n\n especie emmean     SE df lower.CL upper.CL\n Fasi     1.572 0.0559 25    1.457     1.69\n Faus     1.237 0.0559 25    1.122     1.35\n Fcor     1.322 0.0559 25    1.207     1.44\n Fgra     0.912 0.0559 25    0.797     1.03\n Fmer     1.427 0.0559 25    1.312     1.54\n\nConfidence level used: 0.95 \n\nlibrary(multcomp)\n\nCarregando pacotes exigidos: mvtnorm\n\n\nCarregando pacotes exigidos: survival\n\n\nWarning: pacote 'survival' foi compilado no R versão 4.4.1\n\n\nCarregando pacotes exigidos: TH.data\n\n\nCarregando pacotes exigidos: MASS\n\n\nWarning: pacote 'MASS' foi compilado no R versão 4.4.1\n\n\n\nAnexando pacote: 'MASS'\n\n\nO seguinte objeto é mascarado por 'package:dplyr':\n\n    select\n\n\n\nAnexando pacote: 'TH.data'\n\n\nO seguinte objeto é mascarado por 'package:MASS':\n\n    geyser\n\nlibrary(multcompView)\n\nWarning: pacote 'multcompView' foi compilado no R versão 4.4.1\n\ncld(medias1)\n\n especie emmean     SE df lower.CL upper.CL .group\n Fgra     0.912 0.0559 25    0.797     1.03  1    \n Faus     1.237 0.0559 25    1.122     1.35   2   \n Fcor     1.322 0.0559 25    1.207     1.44   2   \n Fmer     1.427 0.0559 25    1.312     1.54   23  \n Fasi     1.572 0.0559 25    1.457     1.69    3  \n\nConfidence level used: 0.95 \nP value adjustment: tukey method for comparing a family of 5 estimates \nsignificance level used: alpha = 0.05 \nNOTE: If two or more means share the same grouping symbol,\n      then we cannot show them to be different.\n      But we also did not show them to be the same. \n\n\nSegundo a tabela acima foram formados 3 grupos, a espécie Fgra diferenciou-se das demais com menor tcm, enquanto Faus, Fcor e Fmer formaram outro grupo, entretanto Fmer e Fasi não diferiram entre si, formando um grupo.\n\n\n\nUtilizamos o pacote DHARMa para gerar gráficos de resíduos simulados e verificar a adequação do modelo. Este pacote possui a função simulateResiduals(), que simula resíduos para verificar a adequação do modelo. A exibição é realizada pela função plot(), que plota os resíduos simulados para diagnóstico visual.\n\nlibrary(DHARMa)\n\nWarning: pacote 'DHARMa' foi compilado no R versão 4.4.1\n\n\nThis is DHARMa 0.4.6. For overview type '?DHARMa'. For recent changes, type news(package = 'DHARMa')\n\nplot(simulateResiduals(m1))\n\n\n\n\n\n\n\n\nOs gráficos de resíduos fornecidos pelo pacote DHARMa ajudam a diagnosticar possíveis problemas com o modelo. O gráfico de quantil-quantil (QQ plot) compara os resíduos observados com os esperados sob uma distribuição normal.\nAinda no gráfico, os pontos devem estar próximos da linha diagonal. Se estiverem, isso indica que os resíduos são aproximadamente normais. No gráfico do exemplo, os pontos seguem de perto a linha, indicando que os resíduos são aproximadamente normais.\nO gráfico Residuals vs. Predicted mostra os resíduos plotados contra os valores preditos. Uma distribuição aleatória dos pontos ao redor da linha horizontal (em zero) sugere que não há padrões sistemáticos nos resíduos.\nNo gráfico do exemplo, os pontos estão bem distribuídos, sugerindo que não há problemas significativos de heteroscedasticidade ou não-linearidade.\nAlém disso, o pacote DHARMa fornece análise de normalidade e homogeneidade e plota junto ao seu respectivo gráfico.\nApós, verificamos os pressupostos do modelo com o pacote performance. A função check_normality() verifica a normalidade dos resíduos, check_heteroscedasticity() verifica a presença de heteroscedasticidade e a função check_model() realiza verificações abrangentes do modelo, incluindo normalidade, heteroscedasticidade e outros diagnósticos.\n\nlibrary(performance)\n\nWarning: pacote 'performance' foi compilado no R versão 4.4.1\n\ncheck_normality(m1)\n\nOK: residuals appear as normally distributed (p = 0.878).\n\ncheck_heteroscedasticity(m1)\n\nOK: Error variance appears to be homoscedastic (p = 0.880).\n\ncheck_model(m1)\n\n\n\n\n\n\n\n\nO gráficoPosterior Predictive Check compara a densidade dos dados observados com as densidades preditas pelo modelo. As linhas azuis representam as predições do modelo e a linha verde representa os dados observados. Se as linhas preditas (azuis) estiverem próximas à linha dos dados observados (verde), isso sugere que o modelo se ajusta bem aos dados. No gráfico do exemplo, as linhas azuis estão próximas à linha verde, indicando um bom ajuste do modelo.\nO gráfico Linearity (Linearidade) exibe resíduos padronizados versus valores ajustados. A linha de referência deve ser plana e horizontal e os pontos devem estar distribuídos aleatoriamente ao redor da linha horizontal. No gráfico do exemplo, os pontos parecem estar distribuídos aleatoriamente, indicando que o pressuposto de linearidade é atendido.\nO gráfico Homogeneity of Variance (Homoscedasticidade) exibe os resíduos padronizados versus valores ajustados. A linha de referência também deve ser plana e horizontal e os resíduos devem ter variância constante em todos os níveis de valores ajustados. No gráfico do exemplo, os pontos estão distribuídos de maneira uniforme ao redor da linha, indicando homoscedasticidade.\nO gráfico Normality of Residuals (Normalidade dos Resíduos) exibe o QQ plot dos resíduos padronizados. Os pontos devem estar alinhados ao longo da linha diagonal, se os pontos seguem a linha diagonal, isso indica que os resíduos são normalmente distribuídos. No gráfico do exemplo, os pontos estão relativamente alinhados à linha, indicando que os resíduos são aproximadamente normais.\nPor fim, o gráfico Influential Observations (Observações Influentes) exibe os resíduos padronizados versus leverage (hi). As observações devem estar dentro das linhas de contorno, este gráfico ajuda a identificar observações que têm uma influência desproporcional no ajuste do modelo. No gráfico do exemplo, a maioria dos pontos está dentro das linhas de contorno, indicando que não há observações influentes significativas.\n\n\nOs gráficos de diagnóstico do exemplo indicam que o modelo ajustado atende aos pressupostos necessários para uma análise de regressão válida:\n\nLinearidade: O pressuposto de linearidade é atendido, pois os resíduos são distribuídos aleatoriamente ao redor da linha horizontal.\nHomoscedasticidade: A variância dos resíduos é constante, conforme indicado pela distribuição uniforme dos pontos.\nNormalidade dos Resíduos: Os resíduos são aproximadamente normais, conforme indicado pelo QQ plot.\nObservações Influentes: Não há observações influentes significativas que possam distorcer os resultados do modelo.\n\nEsses resultados sugerem que o modelo é bem ajustado e que as inferências feitas a partir dele são confiáveis."
  },
  {
    "objectID": "aula_06.html#importando-os-dados",
    "href": "aula_06.html#importando-os-dados",
    "title": "Análise Estatística: Estatística inferencial - Parte 1",
    "section": "",
    "text": "Iniciaremos este tópico importando o dataset que iremos trabalhar.\n\nlibrary(gsheet)\nmg = gsheet2tbl(\"https://docs.google.com/spreadsheets/d/1bq2N19DcZdtax2fQW9OHSGMR0X2__Z9T/edit#gid=983033137\")\n\nO pacote gsheet permite importar dados diretamente de uma planilha do Google Sheets. A função gsheet2tbl converte a planilha em um tibble (um tipo de data frame otimizado).\nCaso haja dúvidas, existe um tópico específico tratando da importação dos dados neste site."
  },
  {
    "objectID": "aula_06.html#visualização-dos-dados",
    "href": "aula_06.html#visualização-dos-dados",
    "title": "Análise Estatística: Estatística inferencial - Parte 1",
    "section": "",
    "text": "Um boxplot, também conhecido como diagrama de caixa, é uma representação gráfica que resume a distribuição de um conjunto de dados baseado em cinco estatísticas: mínimo, primeiro quartil (Q1), mediana (Q2), terceiro quartil (Q3) e máximo e também pode destacar outliers.\nO pacote tidyverse engloba diversos pacotes, como o ggplot2 que é uma das bibliotecas mais populares para visualização de dados em R. Com esta biblioteca podemos utilizar a função geom_boxplot que cria um boxplot. Podemos aplicar temas aplicando um tema preto e branco ao gráfico, melhorando a clareza visual com a função theme_bw().\nUm exemplo de boxplot pode ser plotado utilizando os dados já carregados acima:\n\nlibrary(tidyverse)\n\n── Attaching core tidyverse packages ──────────────────────── tidyverse 2.0.0 ──\n✔ dplyr     1.1.4     ✔ readr     2.1.5\n✔ forcats   1.0.0     ✔ stringr   1.5.1\n✔ ggplot2   3.5.1     ✔ tibble    3.2.1\n✔ lubridate 1.9.3     ✔ tidyr     1.3.1\n✔ purrr     1.0.2     \n── Conflicts ────────────────────────────────────────── tidyverse_conflicts() ──\n✖ dplyr::filter() masks stats::filter()\n✖ dplyr::lag()    masks stats::lag()\nℹ Use the conflicted package (&lt;http://conflicted.r-lib.org/&gt;) to force all conflicts to become errors\n\nmg |&gt; \n  ggplot(aes(trat, comp))+\n  geom_boxplot()+\n  theme_bw()\n\n\n\n\n\n\n\n\nO boxplot é útil para visualizar a distribuição dos dados, incluindo a mediana, os quartis e possíveis outliers. O boxplot ainda pode ajuda a identificar a dispersão dos dados e a presença de possíveis valores atípicos. Além disso podemos identificar a diferença entre dois tratamentos usando um boxplot, começando pela observação a linha mediana dentro de cada caixa, que representa o valor central dos dados.\nComo as medianas estão em diferentes níveis, isso sugere que as medianas dos tratamentos são diferentes. Em seguida, examinamos a posição e a extensão das caixas (intervalo interquartil, IQR), e como as caixas dos dois tratamentos não se sobrepõem, as distribuições dos tratamentos são similares. Menos sobreposição indica uma maior probabilidade de diferença significativa entre os tratamentos."
  },
  {
    "objectID": "aula_06.html#teste-t---dados-independentes",
    "href": "aula_06.html#teste-t---dados-independentes",
    "title": "Análise Estatística: Estatística inferencial - Parte 1",
    "section": "",
    "text": "O Teste t é utilizado para comparar as médias de duas amostras, enquanto o Teste F, que veremos mais abaixo, seria para três ou mais. Ele verifica se a diferença entre as médias é estatisticamente significativa, ou seja, se é provável que as diferenças observadas se devam ao acaso.\n\n\nNo nosso exemplo, precisamos separar os dados para isso devemos passar do formato longo para o formato largo. A função pivot_wider transforma os dados de formato longo para formato largo. No formato longo, cada linha é uma observação única, enquanto no formato largo, cada linha representa um grupo de observações.\n\nmg2 &lt;- mg |&gt; \n  pivot_wider(names_from = trat, values_from = comp)\n\n\n\n\nA função t.test(),como o próprio nomde diz, realiza o teste t, que compara as médias de duas amostras para determinar se elas são estatisticamente diferentes. Um p-valor baixo (geralmente &lt; 0,05) indica que as médias são significativamente diferentes.\n\n# Teste t\nteste1 &lt;- t.test(mg2$Mg2, mg2$control)\nteste1\n\n\n    Welch Two Sample t-test\n\ndata:  mg2$Mg2 and mg2$control\nt = -8.1549, df = 17.354, p-value = 2.423e-07\nalternative hypothesis: true difference in means is not equal to 0\n95 percent confidence interval:\n -6.490393 -3.825607\nsample estimates:\nmean of x mean of y \n   10.520    15.678 \n\n\n\n\nA hipótese H0, também conhecida como hipótese nula, é uma afirmação inicial que presume que não há efeito ou diferença significativa em um estudo ou experimento. É uma posição de “inocência” até que evidências suficientes provem o contrário. Na prática estatística, a hipótese nula é formulada para ser testada e possivelmente rejeitada em favor de uma hipótese alternativa (H1), que sugere a existência de um efeito ou diferença.\nNo caso do exemplo acima, nossa hiótese é de que as médias dos tratamentos não diferem entre si. Como o p-valor ou p-value foi menor do que 0,05, rejeitamos nossa hipótese nula (H0) e aceitamos a hípotese alternativa (H1), que no caso as médias dos tratamentos diferem entre si.\n\n\n\n\nA função shapiro.test(), testa a hipótese de que os dados vêm de uma distribuição normal. A normalidade dos dados é um pressuposto importante para a validade do teste t.\n\nshapiro.test(mg2$control)\n\n\n    Shapiro-Wilk normality test\n\ndata:  mg2$control\nW = 0.93886, p-value = 0.5404\n\nshapiro.test(mg2$Mg2)\n\n\n    Shapiro-Wilk normality test\n\ndata:  mg2$Mg2\nW = 0.97269, p-value = 0.9146\n\n\nUm p-valor alto indica que os dados são normalmente distribuídos, como ocorre no caso acima.\n\n\n\nA função hist() é utilizada para criar um histograma, que mostra a distribuição dos dados. É útil para visualizar a forma da distribuição e identificar se ela é aproximadamente normal.\n\n# Histograma\nhist(mg2$control)\n\n\n\n\n\n\n\nhist(mg2$Mg2)\n\n\n\n\n\n\n\n\nO histograma do tratamento controle segue nitidamente uma distribuição Gaussiana, enquanto a distribuição do tratamento Mg2 não segue uma distribuição normal.\n\n\n\nA função var.test() realiza a comparação das variâncias de duas amostras para verificar se são homogeneamente distribuídas. A homogeneidade de variância é outro pressuposto importante para os testes estatísticos.\n\n#Teste de homogêneidade de variância\nvar.test(mg2$control, mg2$Mg2) #Se a variância não for homogênea tem que informar, var.equal = FALSE\n\n\n    F test to compare two variances\n\ndata:  mg2$control and mg2$Mg2\nF = 0.67654, num df = 9, denom df = 9, p-value = 0.5698\nalternative hypothesis: true ratio of variances is not equal to 1\n95 percent confidence interval:\n 0.1680428 2.7237436\nsample estimates:\nratio of variances \n         0.6765394 \n\n\nUm p-valor alto indica que as variâncias são homogêneas, como ocorre no exemplo acima (p-value = 0.5698).\n\n\n\nA função qqplot() é uma ferramenta valiosa para comparar distribuições de dados. Ela é amplamente usada para verificar a normalidade de uma amostra e para comparar distribuições de viariância de duas amostras diferentes. A interpretação do QQ plot é baseada no quão bem os pontos seguem uma linha reta, com desvios significativos indicando diferenças entre as distribuições.\n\nqqplot(mg2$control, mg2$Mg2)\n\n\n\n\n\n\n\n\n\n\n\nO reaport() gera um relatório detalhado dos resultados do teste t pareado.\n\nlibrary(report)\n\nWarning: pacote 'report' foi compilado no R versão 4.4.1\n\nreport(teste1)\n\nWarning: Function `format_text()` is deprecated and will be removed in a future\n  release. Please use `text_format()` instead.\n\n\nEffect sizes were labelled following Cohen's (1988) recommendations.\n\nThe Welch Two Sample t-test testing the difference between mg2$Mg2 and\nmg2$control (mean of x = 10.52, mean of y = 15.68) suggests that the effect is\nnegative, statistically significant, and large (difference = -5.16, 95% CI\n[-6.49, -3.83], t(17.35) = -8.15, p &lt; .001; Cohen's d = -3.65, 95% CI [-5.12,\n-2.14])\n\n\nUtilizamos o teste t para sabermos se há diferença entre as médias, o p-valor foi &lt;0,05, porém temos que calcular se as médias possuem normalidade, para saber se podemos confiar no teste t. Segundo o teste de shapiro-wilk os dados seguem normalidade (não rejeita Ho), quando plotamos o histograma dos dados podemos observar que segue uma distribuição normal.\nOutra observação que devemos fazer é se as variáveis são homogênas usando o teste F. E neste caso as variâncias são homogêneas (não rejeita Ho) e o boxplot já dava esses indicativos visuais. Podemos fazer também o grafico QQ Plot para mostras a variância dos dados, como foi realizado acima."
  },
  {
    "objectID": "aula_06.html#teste-t---dados-dependentes",
    "href": "aula_06.html#teste-t---dados-dependentes",
    "title": "Análise Estatística: Estatística inferencial - Parte 1",
    "section": "",
    "text": "Para dados dependentes, realiza-se um teste t pareado. Esse teste é usado quando as amostras são dependentes, como medições antes e depois do tratamento no mesmo grupo de indivíduos. Para fazer o teste t pareado tem que colocar o argumento paired = TRUE no código.\n\n\nInicialmente devemos importar e visualizar os dados, lembrando que gsheet() importa dados do Google Sheets e ggplot2 e geom_boxplot() cria um boxplot para visualização.\n\nlibrary(gsheet)\nescala = gsheet2tbl(\"https://docs.google.com/spreadsheets/d/1bq2N19DcZdtax2fQW9OHSGMR0X2__Z9T/edit?gid=1729131173\")\n\nescala |&gt; \n  ggplot(aes(assessment, acuracia))+\n  geom_boxplot()+\n  theme_bw()\n\n\n\n\n\n\n\n\nO boxplot, nos indica que há diferença entre os tratamentos, caso haja dúvidas sobre a interpretação há um tópico acima sobre a interpretação do boxplot.\n\n\n\nAntes de realizarmos os testes é necessário preparar os dados, selecionando as colunas específicas através da função select(). Além disso devemos transformar os dados de formato longo para formato largo pela função pivot_wider().\n\nescala2 &lt;- escala |&gt; \n  select(assessment, rater, acuracia) |&gt; \n  pivot_wider(names_from = assessment,\n              values_from = acuracia)\n\n\n\n\nPara o teste t pareado, temos que lembrar de colocar o argumento paried = TRUE, que por default ele vem como FALSE, este argumento indica que as amostras são pareadas. Assim, a função t.test(paired = TRUE) realiza um teste t pareado, que é usado quando as amostras são dependentes.\n\n#Tete t pareado\nteste2 &lt;- t.test(escala2$Aided1, escala2$Unaided, paried = TRUE, var.equal = FALSE)\n#Obs.: Os dados foram alterados para dar não paramétrico.\nteste2\n\n\n    Welch Two Sample t-test\n\ndata:  escala2$Aided1 and escala2$Unaided\nt = 4.4134, df = 9.8561, p-value = 0.001354\nalternative hypothesis: true difference in means is not equal to 0\n95 percent confidence interval:\n 0.1161235 0.3538765\nsample estimates:\nmean of x mean of y \n    0.917     0.682 \n\n\nOs dados foram alterados para que pudessemos fazer uma análise não paramétrica. Portanto, pelo teste de homogeneidade, os dados não possuem homogêneidade de variância e assim temos que colocar var.equal = FALSE. A função var.equal = FALSE indica que as variâncias das duas amostras não são iguais, ajustando o cálculo do teste t para essa condição.\nO p-valor pelo teste t pareado é igaual a 0.001354, logo. com o p-valor &lt; 0.05, rejeitase H0 a 5% de probabiliade pelo teste t pareado.\n\n\n\nUsamos a função shapiro.test(), que testa a normalidade dos dados em cada grupo. Para mais detalhes sobre normalidade, veja nos tópicos acima.\n\n#Teste de normalidade\nshapiro.test(escala2$Unaided)\n\n\n    Shapiro-Wilk normality test\n\ndata:  escala2$Unaided\nW = 0.7748, p-value = 0.007155\n\nshapiro.test(escala2$Aided1)\n\n\n    Shapiro-Wilk normality test\n\ndata:  escala2$Aided1\nW = 0.92852, p-value = 0.4335\n\n\nSegundo o teste de normalidade de Shapiro-Wilk, a variável Unaided não segue uma distribuição normal (p-valor &lt; 0.05), enquanto a variável Aided1 apresentou normalidade (p-valor &gt; 0.05).\n\n\n\nA função hist() cria histogramas para visualizar a distribuição dos dados.\n\n#Histograma\nhist(escala2$Unaided)\n\n\n\n\n\n\n\nhist(escala2$Aided1)\n\n\n\n\n\n\n\n\nObservando os plots dos histogramas, ambas as variáveis Unaided e Aided, não possuem uma distribuição normal. Apesar da variável Aided1 ter apresentado normalidade (p-valor &gt; 0.05) pelo teste de Shapiro-Wilk. Em experimentos, costuma-se considerar os testes em detrimento dos gráficos.\n\n\n\nA função var.test() compara as variâncias dos dois grupos.\n\n#Teste de homogêneidade de variância\nvar.test(escala2$Unaided, escala2$Aided1) #Se a variância não for homogênea tem que informar, var.equal = FALSE\n\n\n    F test to compare two variances\n\ndata:  escala2$Unaided and escala2$Aided1\nF = 20.978, num df = 9, denom df = 9, p-value = 0.000106\nalternative hypothesis: true ratio of variances is not equal to 1\n95 percent confidence interval:\n  5.210754 84.459185\nsample estimates:\nratio of variances \n          20.97847 \n\n#qqplot(escala2$control, escala2$Aided1)\n\nPara o nosso exemplo, utilizamos o teste F para comparação de duas variâncias, que apresentou um p-valor &lt; 0.05, ou seja, rejeita-se H0 e aceita-se H1, as variâncias não apresentam homogeneidade pelo teste F a 5% de probabilidade.\n\n\n\nComo já mencionado, o R possui o pacote report, que por sua vez possui a função report(), que faz um sumário do teste armazenado em um objeto. No nosso exemplo:\n\nreport(teste2)\n\nWarning: Function `format_text()` is deprecated and will be removed in a future\n  release. Please use `text_format()` instead.\n\n\nEffect sizes were labelled following Cohen's (1988) recommendations.\n\nThe Welch Two Sample t-test testing the difference between escala2$Aided1 and\nescala2$Unaided (mean of x = 0.92, mean of y = 0.68) suggests that the effect\nis positive, statistically significant, and large (difference = 0.23, 95% CI\n[0.12, 0.35], t(9.86) = 4.41, p = 0.001; Cohen's d = 1.97, 95% CI [0.72, 3.18])\n\n\n\n\n\nQuando os dados não atendem aos pressupostos do teste t (normalidade e homogeneidade de variância), pode-se usar uma alternativa não paramétrica, como o teste de Wilcoxon que é um teste equivalente ao teste t, mas não assume uma distribuição normal dos dados.\nPara isso, utilizamos a função wilcox.test(), uma função nativa do R. Esta função realiza o teste de Wilcoxon, entretanto a a necessidade de colocar o parametro paired = TRUE para amostras pareadas.\n\nteste3 &lt;- wilcox.test(escala2$Aided1,\n            escala2$Unaided,\n            paired = TRUE) #Lembrar que é dado pareado, logo paired = TRUE\n\nWarning in wilcox.test.default(escala2$Aided1, escala2$Unaided, paired = TRUE):\nnão é possível computar o valor de p exato com o de desempate\n\nteste3\n\n\n    Wilcoxon signed rank test with continuity correction\n\ndata:  escala2$Aided1 and escala2$Unaided\nV = 55, p-value = 0.005889\nalternative hypothesis: true location shift is not equal to 0"
  },
  {
    "objectID": "aula_06.html#teste-f-para-três-ou-mais-grupos",
    "href": "aula_06.html#teste-f-para-três-ou-mais-grupos",
    "title": "Análise Estatística: Estatística inferencial - Parte 1",
    "section": "",
    "text": "Para comparar três ou mais grupos, utiliza-se o teste f através da ANOVA (Análise de Variância), que verifica se há diferenças significativas entre as médias de mais de dois grupos.\n\n\nSempre inciamos importando os dados, para maiores informações sobre como importar os dados, verifique o tópico específico. O mesmo é valido para o boxplot.\n\nmicelial = gsheet2tbl(\"https://docs.google.com/spreadsheets/d/1bq2N19DcZdtax2fQW9OHSGMR0X2__Z9T/edit#gid=959387827\")\n\nmicelial |&gt; \n  ggplot(aes(especie, tcm))+\n  geom_boxplot()+\n  theme_bw()\n\n\n\n\n\n\n\n\nAnálisando o box-plot, ao menos dois tratamentos diferem das demais, Fasi e Fgra. Entretanto, é necessário que sejam feitos testes para saber realmente há diferença e se seguem os pressupostos de normalidade e homogeneidade.\n\n\n\nPara realizarmos a ANOVA, podemos usar a função aov() ou lm(). Neste exemplo usaremos a função lm(), que cria um modelo linear que relaciona a variável de interesse (tcm) com os grupos (especie). Ao colocarmos espécie -1 já é calculada a média da estimativa.\nA função anova() realiza a análise de variância (ANOVA), que compara as médias de três ou mais grupos para determinar se há diferenças significativas.\n\nm1 &lt;- lm(tcm ~ especie -1, data = micelial)\nanova(m1)\n\nAnalysis of Variance Table\n\nResponse: tcm\n          Df Sum Sq Mean Sq F value    Pr(&gt;F)    \nespecie    5 51.677 10.3354   552.2 &lt; 2.2e-16 ***\nResiduals 25  0.468  0.0187                      \n---\nSignif. codes:  0 '***' 0.001 '**' 0.01 '*' 0.05 '.' 0.1 ' ' 1\n\nshapiro.test(m1$residuals)\n\n\n    Shapiro-Wilk normality test\n\ndata:  m1$residuals\nW = 0.9821, p-value = 0.8782\n\nbartlett.test(tcm ~ especie, data = micelial)\n\n\n    Bartlett test of homogeneity of variances\n\ndata:  tcm by especie\nBartlett's K-squared = 4.4367, df = 4, p-value = 0.3501\n\n\nSegundo os testes de Shapiro-Wilk, e Bartelett os dados apresentam normalidade e homogeneidade de variância, respectivamente, a 5% de probailidade (p-valor &gt; 0.05). Segundo a ANOVA, ao menos uma das médias difere das demais pelo teste F ao nível de 5% de probabilidade (p-valor &gt; 0.05).\n\n\nA função summary() fornece um resumo estatístico do modelo linear, incluindo coeficientes, erros padrão, valores t e p-valores.\n\nsummary(m1)\n\n\nCall:\nlm(formula = tcm ~ especie - 1, data = micelial)\n\nResiduals:\n     Min       1Q   Median       3Q      Max \n-0.23667 -0.09667  0.01583  0.08833  0.28333 \n\nCoefficients:\n            Estimate Std. Error t value Pr(&gt;|t|)    \nespecieFasi  1.57167    0.05585   28.14  &lt; 2e-16 ***\nespecieFaus  1.23667    0.05585   22.14  &lt; 2e-16 ***\nespecieFcor  1.32167    0.05585   23.66  &lt; 2e-16 ***\nespecieFgra  0.91167    0.05585   16.32 7.66e-15 ***\nespecieFmer  1.42667    0.05585   25.54  &lt; 2e-16 ***\n---\nSignif. codes:  0 '***' 0.001 '**' 0.01 '*' 0.05 '.' 0.1 ' ' 1\n\nResidual standard error: 0.1368 on 25 degrees of freedom\nMultiple R-squared:  0.991, Adjusted R-squared:  0.9892 \nF-statistic: 552.2 on 5 and 25 DF,  p-value: &lt; 2.2e-16\n\n\nOs resultados indicam que todas as espécies têm médias estimadas de tcm significativamente diferentes de zero (p &lt; 0.001 para todas). O modelo ajustado explica 99.1% da variabilidade total dos dados (R-squared = 0.991).\nA ANOVA sugere que há diferenças significativas nas médias de tcm entre as espécies (p &lt; 2.2e-16). O modelo apresenta um bom ajuste com um erro padrão residual baixo (0.1368) e coeficientes altamente significativos.\n\n\n\n\nPara comparar as médias dos grupos, usamos o pacote emmeans. Este pacote calcula as estimativas marginais dos efeitos e facilita a comparação entre os grupos.\nO pacote multcomp é utilizado para realizar comparações múltiplas entre as médias dos grupos. A função cld() gera diferenciadores compactos que indicam quais médias são significativamente diferentes entre si.\n\nlibrary(emmeans)\n\nWarning: pacote 'emmeans' foi compilado no R versão 4.4.1\n\n\nWelcome to emmeans.\nCaution: You lose important information if you filter this package's results.\nSee '? untidy'\n\nmedias1 &lt;- emmeans(m1, ~ especie)\nmedias1\n\n especie emmean     SE df lower.CL upper.CL\n Fasi     1.572 0.0559 25    1.457     1.69\n Faus     1.237 0.0559 25    1.122     1.35\n Fcor     1.322 0.0559 25    1.207     1.44\n Fgra     0.912 0.0559 25    0.797     1.03\n Fmer     1.427 0.0559 25    1.312     1.54\n\nConfidence level used: 0.95 \n\nlibrary(multcomp)\n\nCarregando pacotes exigidos: mvtnorm\n\n\nCarregando pacotes exigidos: survival\n\n\nWarning: pacote 'survival' foi compilado no R versão 4.4.1\n\n\nCarregando pacotes exigidos: TH.data\n\n\nCarregando pacotes exigidos: MASS\n\n\nWarning: pacote 'MASS' foi compilado no R versão 4.4.1\n\n\n\nAnexando pacote: 'MASS'\n\n\nO seguinte objeto é mascarado por 'package:dplyr':\n\n    select\n\n\n\nAnexando pacote: 'TH.data'\n\n\nO seguinte objeto é mascarado por 'package:MASS':\n\n    geyser\n\nlibrary(multcompView)\n\nWarning: pacote 'multcompView' foi compilado no R versão 4.4.1\n\ncld(medias1)\n\n especie emmean     SE df lower.CL upper.CL .group\n Fgra     0.912 0.0559 25    0.797     1.03  1    \n Faus     1.237 0.0559 25    1.122     1.35   2   \n Fcor     1.322 0.0559 25    1.207     1.44   2   \n Fmer     1.427 0.0559 25    1.312     1.54   23  \n Fasi     1.572 0.0559 25    1.457     1.69    3  \n\nConfidence level used: 0.95 \nP value adjustment: tukey method for comparing a family of 5 estimates \nsignificance level used: alpha = 0.05 \nNOTE: If two or more means share the same grouping symbol,\n      then we cannot show them to be different.\n      But we also did not show them to be the same. \n\n\nSegundo a tabela acima foram formados 3 grupos, a espécie Fgra diferenciou-se das demais com menor tcm, enquanto Faus, Fcor e Fmer formaram outro grupo, entretanto Fmer e Fasi não diferiram entre si, formando um grupo.\n\n\n\nUtilizamos o pacote DHARMa para gerar gráficos de resíduos simulados e verificar a adequação do modelo. Este pacote possui a função simulateResiduals(), que simula resíduos para verificar a adequação do modelo. A exibição é realizada pela função plot(), que plota os resíduos simulados para diagnóstico visual.\n\nlibrary(DHARMa)\n\nWarning: pacote 'DHARMa' foi compilado no R versão 4.4.1\n\n\nThis is DHARMa 0.4.6. For overview type '?DHARMa'. For recent changes, type news(package = 'DHARMa')\n\nplot(simulateResiduals(m1))\n\n\n\n\n\n\n\n\nOs gráficos de resíduos fornecidos pelo pacote DHARMa ajudam a diagnosticar possíveis problemas com o modelo. O gráfico de quantil-quantil (QQ plot) compara os resíduos observados com os esperados sob uma distribuição normal.\nAinda no gráfico, os pontos devem estar próximos da linha diagonal. Se estiverem, isso indica que os resíduos são aproximadamente normais. No gráfico do exemplo, os pontos seguem de perto a linha, indicando que os resíduos são aproximadamente normais.\nO gráfico Residuals vs. Predicted mostra os resíduos plotados contra os valores preditos. Uma distribuição aleatória dos pontos ao redor da linha horizontal (em zero) sugere que não há padrões sistemáticos nos resíduos.\nNo gráfico do exemplo, os pontos estão bem distribuídos, sugerindo que não há problemas significativos de heteroscedasticidade ou não-linearidade.\nAlém disso, o pacote DHARMa fornece análise de normalidade e homogeneidade e plota junto ao seu respectivo gráfico.\nApós, verificamos os pressupostos do modelo com o pacote performance. A função check_normality() verifica a normalidade dos resíduos, check_heteroscedasticity() verifica a presença de heteroscedasticidade e a função check_model() realiza verificações abrangentes do modelo, incluindo normalidade, heteroscedasticidade e outros diagnósticos.\n\nlibrary(performance)\n\nWarning: pacote 'performance' foi compilado no R versão 4.4.1\n\ncheck_normality(m1)\n\nOK: residuals appear as normally distributed (p = 0.878).\n\ncheck_heteroscedasticity(m1)\n\nOK: Error variance appears to be homoscedastic (p = 0.880).\n\ncheck_model(m1)\n\n\n\n\n\n\n\n\nO gráficoPosterior Predictive Check compara a densidade dos dados observados com as densidades preditas pelo modelo. As linhas azuis representam as predições do modelo e a linha verde representa os dados observados. Se as linhas preditas (azuis) estiverem próximas à linha dos dados observados (verde), isso sugere que o modelo se ajusta bem aos dados. No gráfico do exemplo, as linhas azuis estão próximas à linha verde, indicando um bom ajuste do modelo.\nO gráfico Linearity (Linearidade) exibe resíduos padronizados versus valores ajustados. A linha de referência deve ser plana e horizontal e os pontos devem estar distribuídos aleatoriamente ao redor da linha horizontal. No gráfico do exemplo, os pontos parecem estar distribuídos aleatoriamente, indicando que o pressuposto de linearidade é atendido.\nO gráfico Homogeneity of Variance (Homoscedasticidade) exibe os resíduos padronizados versus valores ajustados. A linha de referência também deve ser plana e horizontal e os resíduos devem ter variância constante em todos os níveis de valores ajustados. No gráfico do exemplo, os pontos estão distribuídos de maneira uniforme ao redor da linha, indicando homoscedasticidade.\nO gráfico Normality of Residuals (Normalidade dos Resíduos) exibe o QQ plot dos resíduos padronizados. Os pontos devem estar alinhados ao longo da linha diagonal, se os pontos seguem a linha diagonal, isso indica que os resíduos são normalmente distribuídos. No gráfico do exemplo, os pontos estão relativamente alinhados à linha, indicando que os resíduos são aproximadamente normais.\nPor fim, o gráfico Influential Observations (Observações Influentes) exibe os resíduos padronizados versus leverage (hi). As observações devem estar dentro das linhas de contorno, este gráfico ajuda a identificar observações que têm uma influência desproporcional no ajuste do modelo. No gráfico do exemplo, a maioria dos pontos está dentro das linhas de contorno, indicando que não há observações influentes significativas.\n\n\nOs gráficos de diagnóstico do exemplo indicam que o modelo ajustado atende aos pressupostos necessários para uma análise de regressão válida:\n\nLinearidade: O pressuposto de linearidade é atendido, pois os resíduos são distribuídos aleatoriamente ao redor da linha horizontal.\nHomoscedasticidade: A variância dos resíduos é constante, conforme indicado pela distribuição uniforme dos pontos.\nNormalidade dos Resíduos: Os resíduos são aproximadamente normais, conforme indicado pelo QQ plot.\nObservações Influentes: Não há observações influentes significativas que possam distorcer os resultados do modelo.\n\nEsses resultados sugerem que o modelo é bem ajustado e que as inferências feitas a partir dele são confiáveis."
  },
  {
    "objectID": "aula_03.html",
    "href": "aula_03.html",
    "title": "Análise exploratória: Visualização de dados",
    "section": "",
    "text": "A visualização de dados é um componente essencial na análise de dados, permitindo que você explore, entenda e comunique padrões, tendências e insights de forma eficaz. Utilizando gráficos e tabelas, você pode transformar dados brutos em informações visuais compreensíveis, facilitando a interpretação e tomada de decisões. No R, pacotes como ggplot2, tidyverse e patchwork oferecem ferramentas poderosas para criar visualizações sofisticadas e personalizadas.\n\n\nPara abrir uma planilha em formato .CSV, utilizamos o pacote tidyverse. Este pacote inclui o readr, que oferece a função read_csv para ler arquivos CSV de maneira eficiente.\nCaso hajam dúvidas sobre como abrir e importar arquivos ou os arquivos estejam em outros formatos, sugiro ler a aula “Importando Datasets” na aba “Básico”.\n\n\nUma dica importante é colocar dentro do primeiro chunk, #| warning: false e #| message: false para não sejam exibidos avisos e mensagens ao renderizar o documento. Se preferir, você pode aplicar essa configuração a todos os chunks colocando no cabeçalho do documento.\n\n#Carregando pacote\nlibrary(tidyverse)\n#Importando arquivo CSV do Git Hub\ncr &lt;- read_csv(\"https://raw.githubusercontent.com/emdelponte/paper-coffee-rust-Ethiopia/master/data/survey_clean.csv\")\n\n\n\n\nExplorar e entender os dados é fundamental para uma boa análise destes dados. A função head apresenta um sumário dos dados, com as 6 primeiras linhas e as colunas existentes, com o nome da variável e o tipo da variável. Assim essa função permite um entendimento do que são os seus dados, variáveis e tipo delas.\n\nhead(cr)\n\n# A tibble: 6 × 13\n   farm region zone       district      lon   lat altitude cultivar shade    \n  &lt;dbl&gt; &lt;chr&gt;  &lt;chr&gt;      &lt;chr&gt;       &lt;dbl&gt; &lt;dbl&gt;    &lt;dbl&gt; &lt;chr&gt;    &lt;chr&gt;    \n1     1 SNNPR  Bench Maji Debub Bench  35.4  6.90     1100 Local    Sun      \n2     2 SNNPR  Bench Maji Debub Bench  35.4  6.90     1342 Mixture  Mid shade\n3     3 SNNPR  Bench Maji Debub Bench  35.4  6.90     1434 Mixture  Mid shade\n4     4 SNNPR  Bench Maji Debub Bench  35.4  6.90     1100 Local    Sun      \n5     5 SNNPR  Bench Maji Debub Bench  35.4  6.90     1400 Local    Sun      \n6     6 SNNPR  Bench Maji Debub Bench  35.4  6.90     1342 Mixture  Mid shade\n# ℹ 4 more variables: cropping_system &lt;chr&gt;, farm_management &lt;chr&gt;, inc &lt;dbl&gt;,\n#   sev2 &lt;dbl&gt;\n\n\nOutra opção para visualizar o conjunto de dados é a função glimpse que mostra detalhes da tabela, como nome da variável, tipo e uma pequana amostra dos dados desta váriaveis.\n\nglimpse(cr)\n\nRows: 405\nColumns: 13\n$ farm            &lt;dbl&gt; 1, 2, 3, 4, 5, 6, 7, 8, 9, 10, 11, 12, 13, 14, 15, 16,…\n$ region          &lt;chr&gt; \"SNNPR\", \"SNNPR\", \"SNNPR\", \"SNNPR\", \"SNNPR\", \"SNNPR\", …\n$ zone            &lt;chr&gt; \"Bench Maji\", \"Bench Maji\", \"Bench Maji\", \"Bench Maji\"…\n$ district        &lt;chr&gt; \"Debub Bench\", \"Debub Bench\", \"Debub Bench\", \"Debub Be…\n$ lon             &lt;dbl&gt; 35.44250, 35.44250, 35.42861, 35.42861, 35.42861, 35.3…\n$ lat             &lt;dbl&gt; 6.904722, 6.904722, 6.904444, 6.904444, 6.904444, 6.90…\n$ altitude        &lt;dbl&gt; 1100, 1342, 1434, 1100, 1400, 1342, 1432, 1100, 1400, …\n$ cultivar        &lt;chr&gt; \"Local\", \"Mixture\", \"Mixture\", \"Local\", \"Local\", \"Mixt…\n$ shade           &lt;chr&gt; \"Sun\", \"Mid shade\", \"Mid shade\", \"Sun\", \"Sun\", \"Mid sh…\n$ cropping_system &lt;chr&gt; \"Plantation\", \"Plantation\", \"Plantation\", \"Plantation\"…\n$ farm_management &lt;chr&gt; \"Unmanaged\", \"Minimal\", \"Minimal\", \"Unmanaged\", \"Unman…\n$ inc             &lt;dbl&gt; 86.70805, 51.34354, 43.20000, 76.70805, 47.15808, 51.3…\n$ sev2            &lt;dbl&gt; 55.57986, 17.90349, 8.25120, 46.10154, 12.25167, 19.91…\n\n\n\n\n\nOs histogramas ajudam a observar a distribuição dos dados, a função para isso é geom_histogram() do pacote ggplot2. Podemos plotar um histograma para cada região utilizando o facet_wrap.\n\nlibrary(ggplot2)\n# Histogramas de incidência por região\ncr |&gt;\n  ggplot(aes(x = inc))+\n  geom_histogram()+ #Histograma\n  facet_wrap(~region) #Separa por região.\n\n`stat_bin()` using `bins = 30`. Pick better value with `binwidth`.\n\n\n\n\n\n\n\n\n\nAlém disso, o comando summary fornece um sumário estatístico das variáveis. E assim como foi plotado um histograma para cada região, podemos pedir um sumário para cada região ou até por cultivar agrupando utilizando a função group_by().\nDentro da função summarize, podemos utilizar as funções para obter a média, mediana e desvio padrão através das funções mean(), median() e sd(), respectivamente.\n\n# Sumário dos dados de incidência\nsummary(cr$inc)\n\n   Min. 1st Qu.  Median    Mean 3rd Qu.    Max. \n   9.50   19.43   32.50   34.89   48.20   86.71 \n\n\n\n# Estatísticas de incidência por região\ncr |&gt;\n  group_by(region) |&gt;\n  summarize(inc_mean = mean(inc),\n            inc_med = median(inc),\n            sd_mean = sd(inc))\n\n# A tibble: 2 × 4\n  region inc_mean inc_med sd_mean\n  &lt;chr&gt;     &lt;dbl&gt;   &lt;dbl&gt;   &lt;dbl&gt;\n1 Oromia     37.0    39.5    14.6\n2 SNNPR      33.4    29.6    18.9\n\n\n\n# Estatísticas de incidência por cultivar\ncr |&gt;\n  group_by(cultivar) |&gt;\n  summarize(inc_mean = mean(inc),\n            inc_med = median(inc),\n            sd_mean = sd(inc))\n\n# A tibble: 3 × 4\n  cultivar inc_mean inc_med sd_mean\n  &lt;chr&gt;       &lt;dbl&gt;   &lt;dbl&gt;   &lt;dbl&gt;\n1 Improved     16.4    15.2    5.66\n2 Local        53.4    50.9   14.3 \n3 Mixture      31.9    31.6   11.2 \n\n\n\n\n\nA média (mean) é a soma de todos os valores dividida pelo número total de observações. Ela fornece uma ideia do valor central dos dados.\nA mediana (Median) é o valor central de um conjunto de dados ordenado. Se o número de observações for par, é a média dos dois valores centrais. Ela divide os dados em duas metades iguais.\nO desvio padrão (Standard Deviation) mede a dispersão dos valores em relação à média. Um desvio padrão alto indica valores espalhados, enquanto um desvio padrão baixo indica valores próximos à média.\n\n\n\n\n\nPara observar a relação entre duas variáveis, podemos utilizar gráficos de dispersão e para observar essa relação pode ser utilizado a função geom_point().\n\ncr |&gt;\n  ggplot(aes(inc, sev2))+\n  geom_point()\n\n\n\n\n\n\n\n\nPodemos obervar melhor a simetria das variáveis, se a mediana e média dos dados forem mais próximas uma da outra, a curva é simétrica. Se os dados forem não simétricos, podemos observar uma assimetria com cauda para a direita ou a esquerda.\n\nlibrary(ggplot2)\ncr |&gt;\n  ggplot(aes(x = sev2))+\n  geom_histogram()+\n  facet_wrap(~region) #Separa por região.\n\n`stat_bin()` using `bins = 30`. Pick better value with `binwidth`.\n\n\n\n\n\n\n\n\nsummary(cr$sev2)\n\n   Min. 1st Qu.  Median    Mean 3rd Qu.    Max. \n 0.2248  2.6892  5.9490  9.0945 12.1593 55.5799 \n\ncr |&gt;\n  group_by(region) |&gt;\n  summarize(sev_mean = mean(sev2),\n            sev_med = median(sev2),\n            sd_mean = sd(sev2))\n\n# A tibble: 2 × 4\n  region sev_mean sev_med sd_mean\n  &lt;chr&gt;     &lt;dbl&gt;   &lt;dbl&gt;   &lt;dbl&gt;\n1 Oromia     8.06    6.23    6.82\n2 SNNPR      9.81    4.88   10.5 \n\n\nAssim, relembrando, a simetria das variáveis pode ser observada através de histogramas e variáveis simétricas terão médias e medianas próximas, enquanto variáveis assimétricas não apresentam médias e medianas próximas e podem mostrar caudas ao ser plotado o histograma como o exemplo acima.\nPorém, se formos olhar por cultivar, os dados ficam mais simétrico, como mostrado abaixo:\n\nlibrary(ggplot2)\ncr |&gt;\n  ggplot(aes(x = sev2))+\n  geom_histogram()+\n  facet_wrap(~cultivar) #Separa por região.\n\n`stat_bin()` using `bins = 30`. Pick better value with `binwidth`.\n\n\n\n\n\n\n\n\nsummary(cr$sev2)\n\n   Min. 1st Qu.  Median    Mean 3rd Qu.    Max. \n 0.2248  2.6892  5.9490  9.0945 12.1593 55.5799 \n\ncr |&gt;\n  group_by(cultivar) |&gt;\n  summarize(sev_mean = mean(sev2),\n            sev_med = median(sev2),\n            sd_mean = sd(sev2))\n\n# A tibble: 3 × 4\n  cultivar sev_mean sev_med sd_mean\n  &lt;chr&gt;       &lt;dbl&gt;   &lt;dbl&gt;   &lt;dbl&gt;\n1 Improved     2.16    1.64    1.82\n2 Local       18.7    17.2    11.1 \n3 Mixture      6.47    5.43    4.35\n\n\n\n\n\nOs gráficos podem ser personalizados de uma infinidade de formas, por exemplo, podemos modificar as cores por região. Lembrando de colocar fill na função ggplot, se for colocado depois ele irá alterar os gráficos. De mesma forma quando usamos um tema, como o theme_minimal usado no exemplo, tem que ver após o scale_fill_manual, pois irá sobrescever o tema anterior.\n\nlibrary(ggthemes)\ncr |&gt;\n  ggplot(aes(x = sev2, fill = region))+ #Aqui foi adicionado o fill\n  geom_histogram(color = \"white\")+ #Color aqui é para aborda das barras do histograma.\n  facet_wrap(region ~ cultivar, ncol = 6)+ #ncol coloca o número de colunas por plot\n  #scale_fill_colorblind() #Aqui altera a plheta de cores\n  scale_fill_manual(values = c(\"red\", \"blue\"))+ #escolha manual\n  theme_minimal(base_size = 14)+ #vem depois, se não sobrescreve o scale_fill_manual, aqui também altera a fonte com base_size)\n  theme(legend.position = \"bottom\")+\n  labs(y = \"Frequency\",\n       x = \"Severity (%)\",\n       fill = \"Region\") #Alterou o nome, que estava como o da variável\n\n`stat_bin()` using `bins = 30`. Pick better value with `binwidth`.\n\n\n\n\n\n\n\n\nggsave(\"cr1.png\", bg =\"white\")\n\nSaving 7 x 5 in image\n`stat_bin()` using `bins = 30`. Pick better value with `binwidth`.\n\n\n\n\n\n\n\n\nPara criar subconjuntos de dados, podemos selecionar as colunas com a função select() e podemos atribuir este subconjunto a um objeto, como no exemplo o objeto cr2. No exemplo foram selecionados as colunas, ou variáveis, fazenda (farm), região (region), cultivar (cultivar) e severidade (sev2).\n\ncr2 &lt;- cr |&gt;\n  select(farm, region, cultivar, sev2) #select é pra colunas\n\ncr2\n\n# A tibble: 405 × 4\n    farm region cultivar  sev2\n   &lt;dbl&gt; &lt;chr&gt;  &lt;chr&gt;    &lt;dbl&gt;\n 1     1 SNNPR  Local    55.6 \n 2     2 SNNPR  Mixture  17.9 \n 3     3 SNNPR  Mixture   8.25\n 4     4 SNNPR  Local    46.1 \n 5     5 SNNPR  Local    12.3 \n 6     6 SNNPR  Mixture  19.9 \n 7     7 SNNPR  Mixture  11.9 \n 8     8 SNNPR  Local    55.6 \n 9     9 SNNPR  Local    11.6 \n10    10 SNNPR  Mixture  11.4 \n# ℹ 395 more rows\n\n\nPodemos também, filtrar os dados usando o filter() do pacote dplyr em conjunto com a função select() para escolher colunas e filtrar as linhas.\n\n#Filtra Oromia\ncr_oromia &lt;- cr |&gt;\n  select(farm, region, cultivar, sev2) |&gt; #select é pra colunas\n  filter(region == \"Oromia\")\ncr_oromia\n\n# A tibble: 165 × 4\n    farm region cultivar  sev2\n   &lt;dbl&gt; &lt;chr&gt;  &lt;chr&gt;    &lt;dbl&gt;\n 1   286 Oromia Mixture   7.63\n 2   287 Oromia Mixture   9.39\n 3   288 Oromia Mixture   1.30\n 4   289 Oromia Mixture   9.79\n 5   290 Oromia Local    18.5 \n 6   291 Oromia Mixture  13.2 \n 7   292 Oromia Mixture   5.60\n 8   293 Oromia Mixture   1.06\n 9   294 Oromia Local    17.6 \n10   295 Oromia Mixture  15.4 \n# ℹ 155 more rows\n\n#Filtra SNNPR\ncr_pr &lt;- cr |&gt;\n  select(farm, region, cultivar, sev2) |&gt;#select é pra colunas\n  filter(region == \"SNNPR\")\ncr_pr\n\n# A tibble: 240 × 4\n    farm region cultivar  sev2\n   &lt;dbl&gt; &lt;chr&gt;  &lt;chr&gt;    &lt;dbl&gt;\n 1     1 SNNPR  Local    55.6 \n 2     2 SNNPR  Mixture  17.9 \n 3     3 SNNPR  Mixture   8.25\n 4     4 SNNPR  Local    46.1 \n 5     5 SNNPR  Local    12.3 \n 6     6 SNNPR  Mixture  19.9 \n 7     7 SNNPR  Mixture  11.9 \n 8     8 SNNPR  Local    55.6 \n 9     9 SNNPR  Local    11.6 \n10    10 SNNPR  Mixture  11.4 \n# ℹ 230 more rows\n\n\n\n\n\nAinda podemos gerar gráficos ggplot2 para cada subconjunto para uma melhor visualização dos dados. No caso utilizamos o boxplot através da função geom_boxplot(), também do pacote ggplot2.\nO box plot é uma representação gráfica que mostra a distribuição de um conjunto de dados de maneira resumida, destacando a mediana, os quartis e os outliers. Os componentes de um boxplot são:\n\nCaixa:\n\nQuartil Inferior (Q1): Marca os 25% mais baixos dos dados.\nMediana (Q2): O valor central dos dados (50%).\nQuartil Superior (Q3): Marca os 75% mais baixos dos dados.\n\nWhiskers:\n\nLinhas que se estendem dos quartis até o valor mínimo e máximo dentro de 1.5 vezes o intervalo interquartil (IQR).\n\nOutliers:\n\nPontos fora do alcance dos whiskers, indicando valores atípicos.\n\n\n\ncr_oromia |&gt;\n  ggplot(aes(x = cultivar,\n             y = sev2))+\n  geom_boxplot()+\n  labs(title = \"Oromia\",\n       X = \"Cultivar\",\n       y = \"Severity (%)\")\n\n\n\n\n\n\n\n\n\ncr_pr |&gt;\n  ggplot(aes(x = cultivar,\n             y = sev2))+\n  geom_boxplot()+\n  labs(title = \"SNNPR\",\n       X = \"Cultivar\",\n       y = \"Severity (%)\")\n\n\n\n\n\n\n\n\nO box plot é útil para identificar a mediana, a dispersão, a assimetria e os outliers em um conjunto de dados, facilitando a comparação entre diferentes grupos ou categorias.\n\n\n\nGráficos exibidos lado a lado podem auxiliar na percepção de diferença entre dois grupos quando queremos apresenta-las ao leitor de um artigo, por exemplo. Assim, para plotar dois gráficos lado a lado iremos utilizar a biblioteca patchwork, sem usar o face_wrap.\n\np1 &lt;- cr_oromia |&gt;\n  ggplot(aes(x = cultivar,\n             y = sev2,\n             fill = cultivar))+\n  geom_boxplot()+\n  labs(x = \"Cultivar\",\n       y = \"Severity (%)\")#+ #lembrar de tirar o comentário do +\n  #coord_flip() #rotaciona as coordenadas\n\np2 &lt;- cr_pr |&gt;\n  ggplot(aes(x = cultivar,\n             y = sev2,\n             fill = cultivar))+\n  geom_boxplot()+\n  labs(x = \"Cultivar\",\n       y = \"Severity (%)\")#+ #lembrar de tirar o comentário do +\n  coord_flip() #rotaciona as coordenadas\n\n&lt;ggproto object: Class CoordFlip, CoordCartesian, Coord, gg&gt;\n    aspect: function\n    backtransform_range: function\n    clip: on\n    default: FALSE\n    distance: function\n    expand: TRUE\n    is_free: function\n    is_linear: function\n    labels: function\n    limits: list\n    modify_scales: function\n    range: function\n    render_axis_h: function\n    render_axis_v: function\n    render_bg: function\n    render_fg: function\n    setup_data: function\n    setup_layout: function\n    setup_panel_guides: function\n    setup_panel_params: function\n    setup_params: function\n    train_panel_guides: function\n    transform: function\n    super:  &lt;ggproto object: Class CoordFlip, CoordCartesian, Coord, gg&gt;\n\nlibrary(patchwork)\n\n(p1 + p2) + #Pode ser + ou |, se colocar / coloca um sobre o outro. Ele funciona como equação, pode ser feito combinação dos gráficos como p1/(p2+p1)\nplot_layout(guides = \"collect\") + #Deixa somente uma legenda\nplot_annotation(tag_levels = \"A\") #Diferencia maiúsculas e minúsculas\n\n\n\n\n\n\n\nggsave(\"patch.png\")\n\nSaving 7 x 5 in image\n\n\nPodemos usar o artifício da função coord_flip(), para rotacionar as coordenadas de uma imagem ou das duas, caso fique visualmente mais adequado para a explicação dos dados.\n\np1 &lt;- cr_oromia |&gt;\n  ggplot(aes(x = cultivar,\n             y = sev2,\n             fill = cultivar))+\n  geom_boxplot()+\n  theme_few() +\n  labs(x = \"Cultivar\",\n       y = \"Severity (%)\")+\n  coord_flip() #rotaciona as coordenadas\n\np2 &lt;- cr_pr |&gt;\n  ggplot(aes(x = cultivar,\n             y = sev2,\n             fill = cultivar))+\n  geom_boxplot()+\n  theme_few() +\n  labs(x = \"Cultivar\",\n       y = \"Severity (%)\")+\n  coord_flip() #rotaciona as coordenadas\n\n#Não consegui instalar o patchwork\nlibrary(patchwork)\n\n(p1 / p2) + #pode ser + ou |, se colocar / coloca um sobre o outro. Ele funciona como equação, pode ser feito combinação dos gráficos como p1/(p2+p1)\nplot_layout(guides = \"collect\",\n            axes = \"collect\")+ #Deixa somente uma legenda\nplot_annotation(title = \"Coffe rust is Ethiopia\",\n                caption = \"source: Serafini (2024)\",\n                tag_levels = \"A\") #diferencia maiúsculas e minúsculas\n\n\n\n\n\n\n\nggsave(\"patch2.png\", width = 5, height = 4)\n\nOutra opção de combinações que o pacote permite é a sobreposição de gráficos através da função inset_element(), onde é inserido o gráfico que se deseja plotar e as dimensões/posições deste na imagem. Este é um excelente artifício para exibir informações gráficas complementares em uma mesma imagem.\n\np1 &lt;- cr_oromia |&gt;\n  ggplot(aes(x = cultivar,\n             y = sev2,\n             fill = cultivar))+\n  geom_boxplot()+\n  theme_few() +\n  labs(x = \"Cultivar\",\n       y = \"Severity (%)\")+\n  coord_flip() #rotaciona as coordenadas\n\np3 &lt;- cr_oromia |&gt;\n  ggplot(aes(x = sev2))+\n  geom_histogram() +\n  labs(y = \"Freq.\",\n       x = \"Severity (%)\")\n\np1 + inset_element(p3, left = 0.6,\n                    bottom = 0.6,\n                    right = 1,\n                    top = 1) +\n  plot_annotation(title = \"Coffe rust is Ethiopia\",\n                caption = \"source: Serafini (2024)\",\n                tag_levels = \"A\") #diferencia maiúsculas e minúsculas\n\n`stat_bin()` using `bins = 30`. Pick better value with `binwidth`.\n\n\n\n\n\n\n\n\nggsave(\"patch3.png\", width = 5, height = 4)\n\n`stat_bin()` using `bins = 30`. Pick better value with `binwidth`.\n\n\nO patchwork tem várias possíbilidades interessantes, vale a pena olhar a ajuda (help) deste pacote!"
  },
  {
    "objectID": "aula_03.html#abrindo-e-importando-arquivo-csv",
    "href": "aula_03.html#abrindo-e-importando-arquivo-csv",
    "title": "Análise exploratória: Visualização de dados",
    "section": "",
    "text": "Para abrir uma planilha em formato .CSV, utilizamos o pacote tidyverse. Este pacote inclui o readr, que oferece a função read_csv para ler arquivos CSV de maneira eficiente.\nCaso hajam dúvidas sobre como abrir e importar arquivos ou os arquivos estejam em outros formatos, sugiro ler a aula “Importando Datasets” na aba “Básico”.\n\n\nUma dica importante é colocar dentro do primeiro chunk, #| warning: false e #| message: false para não sejam exibidos avisos e mensagens ao renderizar o documento. Se preferir, você pode aplicar essa configuração a todos os chunks colocando no cabeçalho do documento.\n\n#Carregando pacote\nlibrary(tidyverse)\n#Importando arquivo CSV do Git Hub\ncr &lt;- read_csv(\"https://raw.githubusercontent.com/emdelponte/paper-coffee-rust-Ethiopia/master/data/survey_clean.csv\")\n\n\n\n\nExplorar e entender os dados é fundamental para uma boa análise destes dados. A função head apresenta um sumário dos dados, com as 6 primeiras linhas e as colunas existentes, com o nome da variável e o tipo da variável. Assim essa função permite um entendimento do que são os seus dados, variáveis e tipo delas.\n\nhead(cr)\n\n# A tibble: 6 × 13\n   farm region zone       district      lon   lat altitude cultivar shade    \n  &lt;dbl&gt; &lt;chr&gt;  &lt;chr&gt;      &lt;chr&gt;       &lt;dbl&gt; &lt;dbl&gt;    &lt;dbl&gt; &lt;chr&gt;    &lt;chr&gt;    \n1     1 SNNPR  Bench Maji Debub Bench  35.4  6.90     1100 Local    Sun      \n2     2 SNNPR  Bench Maji Debub Bench  35.4  6.90     1342 Mixture  Mid shade\n3     3 SNNPR  Bench Maji Debub Bench  35.4  6.90     1434 Mixture  Mid shade\n4     4 SNNPR  Bench Maji Debub Bench  35.4  6.90     1100 Local    Sun      \n5     5 SNNPR  Bench Maji Debub Bench  35.4  6.90     1400 Local    Sun      \n6     6 SNNPR  Bench Maji Debub Bench  35.4  6.90     1342 Mixture  Mid shade\n# ℹ 4 more variables: cropping_system &lt;chr&gt;, farm_management &lt;chr&gt;, inc &lt;dbl&gt;,\n#   sev2 &lt;dbl&gt;\n\n\nOutra opção para visualizar o conjunto de dados é a função glimpse que mostra detalhes da tabela, como nome da variável, tipo e uma pequana amostra dos dados desta váriaveis.\n\nglimpse(cr)\n\nRows: 405\nColumns: 13\n$ farm            &lt;dbl&gt; 1, 2, 3, 4, 5, 6, 7, 8, 9, 10, 11, 12, 13, 14, 15, 16,…\n$ region          &lt;chr&gt; \"SNNPR\", \"SNNPR\", \"SNNPR\", \"SNNPR\", \"SNNPR\", \"SNNPR\", …\n$ zone            &lt;chr&gt; \"Bench Maji\", \"Bench Maji\", \"Bench Maji\", \"Bench Maji\"…\n$ district        &lt;chr&gt; \"Debub Bench\", \"Debub Bench\", \"Debub Bench\", \"Debub Be…\n$ lon             &lt;dbl&gt; 35.44250, 35.44250, 35.42861, 35.42861, 35.42861, 35.3…\n$ lat             &lt;dbl&gt; 6.904722, 6.904722, 6.904444, 6.904444, 6.904444, 6.90…\n$ altitude        &lt;dbl&gt; 1100, 1342, 1434, 1100, 1400, 1342, 1432, 1100, 1400, …\n$ cultivar        &lt;chr&gt; \"Local\", \"Mixture\", \"Mixture\", \"Local\", \"Local\", \"Mixt…\n$ shade           &lt;chr&gt; \"Sun\", \"Mid shade\", \"Mid shade\", \"Sun\", \"Sun\", \"Mid sh…\n$ cropping_system &lt;chr&gt; \"Plantation\", \"Plantation\", \"Plantation\", \"Plantation\"…\n$ farm_management &lt;chr&gt; \"Unmanaged\", \"Minimal\", \"Minimal\", \"Unmanaged\", \"Unman…\n$ inc             &lt;dbl&gt; 86.70805, 51.34354, 43.20000, 76.70805, 47.15808, 51.3…\n$ sev2            &lt;dbl&gt; 55.57986, 17.90349, 8.25120, 46.10154, 12.25167, 19.91…\n\n\n\n\n\nOs histogramas ajudam a observar a distribuição dos dados, a função para isso é geom_histogram() do pacote ggplot2. Podemos plotar um histograma para cada região utilizando o facet_wrap.\n\nlibrary(ggplot2)\n# Histogramas de incidência por região\ncr |&gt;\n  ggplot(aes(x = inc))+\n  geom_histogram()+ #Histograma\n  facet_wrap(~region) #Separa por região.\n\n`stat_bin()` using `bins = 30`. Pick better value with `binwidth`.\n\n\n\n\n\n\n\n\n\nAlém disso, o comando summary fornece um sumário estatístico das variáveis. E assim como foi plotado um histograma para cada região, podemos pedir um sumário para cada região ou até por cultivar agrupando utilizando a função group_by().\nDentro da função summarize, podemos utilizar as funções para obter a média, mediana e desvio padrão através das funções mean(), median() e sd(), respectivamente.\n\n# Sumário dos dados de incidência\nsummary(cr$inc)\n\n   Min. 1st Qu.  Median    Mean 3rd Qu.    Max. \n   9.50   19.43   32.50   34.89   48.20   86.71 \n\n\n\n# Estatísticas de incidência por região\ncr |&gt;\n  group_by(region) |&gt;\n  summarize(inc_mean = mean(inc),\n            inc_med = median(inc),\n            sd_mean = sd(inc))\n\n# A tibble: 2 × 4\n  region inc_mean inc_med sd_mean\n  &lt;chr&gt;     &lt;dbl&gt;   &lt;dbl&gt;   &lt;dbl&gt;\n1 Oromia     37.0    39.5    14.6\n2 SNNPR      33.4    29.6    18.9\n\n\n\n# Estatísticas de incidência por cultivar\ncr |&gt;\n  group_by(cultivar) |&gt;\n  summarize(inc_mean = mean(inc),\n            inc_med = median(inc),\n            sd_mean = sd(inc))\n\n# A tibble: 3 × 4\n  cultivar inc_mean inc_med sd_mean\n  &lt;chr&gt;       &lt;dbl&gt;   &lt;dbl&gt;   &lt;dbl&gt;\n1 Improved     16.4    15.2    5.66\n2 Local        53.4    50.9   14.3 \n3 Mixture      31.9    31.6   11.2 \n\n\n\n\n\nA média (mean) é a soma de todos os valores dividida pelo número total de observações. Ela fornece uma ideia do valor central dos dados.\nA mediana (Median) é o valor central de um conjunto de dados ordenado. Se o número de observações for par, é a média dos dois valores centrais. Ela divide os dados em duas metades iguais.\nO desvio padrão (Standard Deviation) mede a dispersão dos valores em relação à média. Um desvio padrão alto indica valores espalhados, enquanto um desvio padrão baixo indica valores próximos à média.\n\n\n\n\n\nPara observar a relação entre duas variáveis, podemos utilizar gráficos de dispersão e para observar essa relação pode ser utilizado a função geom_point().\n\ncr |&gt;\n  ggplot(aes(inc, sev2))+\n  geom_point()\n\n\n\n\n\n\n\n\nPodemos obervar melhor a simetria das variáveis, se a mediana e média dos dados forem mais próximas uma da outra, a curva é simétrica. Se os dados forem não simétricos, podemos observar uma assimetria com cauda para a direita ou a esquerda.\n\nlibrary(ggplot2)\ncr |&gt;\n  ggplot(aes(x = sev2))+\n  geom_histogram()+\n  facet_wrap(~region) #Separa por região.\n\n`stat_bin()` using `bins = 30`. Pick better value with `binwidth`.\n\n\n\n\n\n\n\n\nsummary(cr$sev2)\n\n   Min. 1st Qu.  Median    Mean 3rd Qu.    Max. \n 0.2248  2.6892  5.9490  9.0945 12.1593 55.5799 \n\ncr |&gt;\n  group_by(region) |&gt;\n  summarize(sev_mean = mean(sev2),\n            sev_med = median(sev2),\n            sd_mean = sd(sev2))\n\n# A tibble: 2 × 4\n  region sev_mean sev_med sd_mean\n  &lt;chr&gt;     &lt;dbl&gt;   &lt;dbl&gt;   &lt;dbl&gt;\n1 Oromia     8.06    6.23    6.82\n2 SNNPR      9.81    4.88   10.5 \n\n\nAssim, relembrando, a simetria das variáveis pode ser observada através de histogramas e variáveis simétricas terão médias e medianas próximas, enquanto variáveis assimétricas não apresentam médias e medianas próximas e podem mostrar caudas ao ser plotado o histograma como o exemplo acima.\nPorém, se formos olhar por cultivar, os dados ficam mais simétrico, como mostrado abaixo:\n\nlibrary(ggplot2)\ncr |&gt;\n  ggplot(aes(x = sev2))+\n  geom_histogram()+\n  facet_wrap(~cultivar) #Separa por região.\n\n`stat_bin()` using `bins = 30`. Pick better value with `binwidth`.\n\n\n\n\n\n\n\n\nsummary(cr$sev2)\n\n   Min. 1st Qu.  Median    Mean 3rd Qu.    Max. \n 0.2248  2.6892  5.9490  9.0945 12.1593 55.5799 \n\ncr |&gt;\n  group_by(cultivar) |&gt;\n  summarize(sev_mean = mean(sev2),\n            sev_med = median(sev2),\n            sd_mean = sd(sev2))\n\n# A tibble: 3 × 4\n  cultivar sev_mean sev_med sd_mean\n  &lt;chr&gt;       &lt;dbl&gt;   &lt;dbl&gt;   &lt;dbl&gt;\n1 Improved     2.16    1.64    1.82\n2 Local       18.7    17.2    11.1 \n3 Mixture      6.47    5.43    4.35\n\n\n\n\n\nOs gráficos podem ser personalizados de uma infinidade de formas, por exemplo, podemos modificar as cores por região. Lembrando de colocar fill na função ggplot, se for colocado depois ele irá alterar os gráficos. De mesma forma quando usamos um tema, como o theme_minimal usado no exemplo, tem que ver após o scale_fill_manual, pois irá sobrescever o tema anterior.\n\nlibrary(ggthemes)\ncr |&gt;\n  ggplot(aes(x = sev2, fill = region))+ #Aqui foi adicionado o fill\n  geom_histogram(color = \"white\")+ #Color aqui é para aborda das barras do histograma.\n  facet_wrap(region ~ cultivar, ncol = 6)+ #ncol coloca o número de colunas por plot\n  #scale_fill_colorblind() #Aqui altera a plheta de cores\n  scale_fill_manual(values = c(\"red\", \"blue\"))+ #escolha manual\n  theme_minimal(base_size = 14)+ #vem depois, se não sobrescreve o scale_fill_manual, aqui também altera a fonte com base_size)\n  theme(legend.position = \"bottom\")+\n  labs(y = \"Frequency\",\n       x = \"Severity (%)\",\n       fill = \"Region\") #Alterou o nome, que estava como o da variável\n\n`stat_bin()` using `bins = 30`. Pick better value with `binwidth`.\n\n\n\n\n\n\n\n\nggsave(\"cr1.png\", bg =\"white\")\n\nSaving 7 x 5 in image\n`stat_bin()` using `bins = 30`. Pick better value with `binwidth`."
  },
  {
    "objectID": "aula_03.html#criação-de-subconjunto",
    "href": "aula_03.html#criação-de-subconjunto",
    "title": "Análise exploratória: Visualização de dados",
    "section": "",
    "text": "Para criar subconjuntos de dados, podemos selecionar as colunas com a função select() e podemos atribuir este subconjunto a um objeto, como no exemplo o objeto cr2. No exemplo foram selecionados as colunas, ou variáveis, fazenda (farm), região (region), cultivar (cultivar) e severidade (sev2).\n\ncr2 &lt;- cr |&gt;\n  select(farm, region, cultivar, sev2) #select é pra colunas\n\ncr2\n\n# A tibble: 405 × 4\n    farm region cultivar  sev2\n   &lt;dbl&gt; &lt;chr&gt;  &lt;chr&gt;    &lt;dbl&gt;\n 1     1 SNNPR  Local    55.6 \n 2     2 SNNPR  Mixture  17.9 \n 3     3 SNNPR  Mixture   8.25\n 4     4 SNNPR  Local    46.1 \n 5     5 SNNPR  Local    12.3 \n 6     6 SNNPR  Mixture  19.9 \n 7     7 SNNPR  Mixture  11.9 \n 8     8 SNNPR  Local    55.6 \n 9     9 SNNPR  Local    11.6 \n10    10 SNNPR  Mixture  11.4 \n# ℹ 395 more rows\n\n\nPodemos também, filtrar os dados usando o filter() do pacote dplyr em conjunto com a função select() para escolher colunas e filtrar as linhas.\n\n#Filtra Oromia\ncr_oromia &lt;- cr |&gt;\n  select(farm, region, cultivar, sev2) |&gt; #select é pra colunas\n  filter(region == \"Oromia\")\ncr_oromia\n\n# A tibble: 165 × 4\n    farm region cultivar  sev2\n   &lt;dbl&gt; &lt;chr&gt;  &lt;chr&gt;    &lt;dbl&gt;\n 1   286 Oromia Mixture   7.63\n 2   287 Oromia Mixture   9.39\n 3   288 Oromia Mixture   1.30\n 4   289 Oromia Mixture   9.79\n 5   290 Oromia Local    18.5 \n 6   291 Oromia Mixture  13.2 \n 7   292 Oromia Mixture   5.60\n 8   293 Oromia Mixture   1.06\n 9   294 Oromia Local    17.6 \n10   295 Oromia Mixture  15.4 \n# ℹ 155 more rows\n\n#Filtra SNNPR\ncr_pr &lt;- cr |&gt;\n  select(farm, region, cultivar, sev2) |&gt;#select é pra colunas\n  filter(region == \"SNNPR\")\ncr_pr\n\n# A tibble: 240 × 4\n    farm region cultivar  sev2\n   &lt;dbl&gt; &lt;chr&gt;  &lt;chr&gt;    &lt;dbl&gt;\n 1     1 SNNPR  Local    55.6 \n 2     2 SNNPR  Mixture  17.9 \n 3     3 SNNPR  Mixture   8.25\n 4     4 SNNPR  Local    46.1 \n 5     5 SNNPR  Local    12.3 \n 6     6 SNNPR  Mixture  19.9 \n 7     7 SNNPR  Mixture  11.9 \n 8     8 SNNPR  Local    55.6 \n 9     9 SNNPR  Local    11.6 \n10    10 SNNPR  Mixture  11.4 \n# ℹ 230 more rows\n\n\n\n\n\nAinda podemos gerar gráficos ggplot2 para cada subconjunto para uma melhor visualização dos dados. No caso utilizamos o boxplot através da função geom_boxplot(), também do pacote ggplot2.\nO box plot é uma representação gráfica que mostra a distribuição de um conjunto de dados de maneira resumida, destacando a mediana, os quartis e os outliers. Os componentes de um boxplot são:\n\nCaixa:\n\nQuartil Inferior (Q1): Marca os 25% mais baixos dos dados.\nMediana (Q2): O valor central dos dados (50%).\nQuartil Superior (Q3): Marca os 75% mais baixos dos dados.\n\nWhiskers:\n\nLinhas que se estendem dos quartis até o valor mínimo e máximo dentro de 1.5 vezes o intervalo interquartil (IQR).\n\nOutliers:\n\nPontos fora do alcance dos whiskers, indicando valores atípicos.\n\n\n\ncr_oromia |&gt;\n  ggplot(aes(x = cultivar,\n             y = sev2))+\n  geom_boxplot()+\n  labs(title = \"Oromia\",\n       X = \"Cultivar\",\n       y = \"Severity (%)\")\n\n\n\n\n\n\n\n\n\ncr_pr |&gt;\n  ggplot(aes(x = cultivar,\n             y = sev2))+\n  geom_boxplot()+\n  labs(title = \"SNNPR\",\n       X = \"Cultivar\",\n       y = \"Severity (%)\")\n\n\n\n\n\n\n\n\nO box plot é útil para identificar a mediana, a dispersão, a assimetria e os outliers em um conjunto de dados, facilitando a comparação entre diferentes grupos ou categorias.\n\n\n\nGráficos exibidos lado a lado podem auxiliar na percepção de diferença entre dois grupos quando queremos apresenta-las ao leitor de um artigo, por exemplo. Assim, para plotar dois gráficos lado a lado iremos utilizar a biblioteca patchwork, sem usar o face_wrap.\n\np1 &lt;- cr_oromia |&gt;\n  ggplot(aes(x = cultivar,\n             y = sev2,\n             fill = cultivar))+\n  geom_boxplot()+\n  labs(x = \"Cultivar\",\n       y = \"Severity (%)\")#+ #lembrar de tirar o comentário do +\n  #coord_flip() #rotaciona as coordenadas\n\np2 &lt;- cr_pr |&gt;\n  ggplot(aes(x = cultivar,\n             y = sev2,\n             fill = cultivar))+\n  geom_boxplot()+\n  labs(x = \"Cultivar\",\n       y = \"Severity (%)\")#+ #lembrar de tirar o comentário do +\n  coord_flip() #rotaciona as coordenadas\n\n&lt;ggproto object: Class CoordFlip, CoordCartesian, Coord, gg&gt;\n    aspect: function\n    backtransform_range: function\n    clip: on\n    default: FALSE\n    distance: function\n    expand: TRUE\n    is_free: function\n    is_linear: function\n    labels: function\n    limits: list\n    modify_scales: function\n    range: function\n    render_axis_h: function\n    render_axis_v: function\n    render_bg: function\n    render_fg: function\n    setup_data: function\n    setup_layout: function\n    setup_panel_guides: function\n    setup_panel_params: function\n    setup_params: function\n    train_panel_guides: function\n    transform: function\n    super:  &lt;ggproto object: Class CoordFlip, CoordCartesian, Coord, gg&gt;\n\nlibrary(patchwork)\n\n(p1 + p2) + #Pode ser + ou |, se colocar / coloca um sobre o outro. Ele funciona como equação, pode ser feito combinação dos gráficos como p1/(p2+p1)\nplot_layout(guides = \"collect\") + #Deixa somente uma legenda\nplot_annotation(tag_levels = \"A\") #Diferencia maiúsculas e minúsculas\n\n\n\n\n\n\n\nggsave(\"patch.png\")\n\nSaving 7 x 5 in image\n\n\nPodemos usar o artifício da função coord_flip(), para rotacionar as coordenadas de uma imagem ou das duas, caso fique visualmente mais adequado para a explicação dos dados.\n\np1 &lt;- cr_oromia |&gt;\n  ggplot(aes(x = cultivar,\n             y = sev2,\n             fill = cultivar))+\n  geom_boxplot()+\n  theme_few() +\n  labs(x = \"Cultivar\",\n       y = \"Severity (%)\")+\n  coord_flip() #rotaciona as coordenadas\n\np2 &lt;- cr_pr |&gt;\n  ggplot(aes(x = cultivar,\n             y = sev2,\n             fill = cultivar))+\n  geom_boxplot()+\n  theme_few() +\n  labs(x = \"Cultivar\",\n       y = \"Severity (%)\")+\n  coord_flip() #rotaciona as coordenadas\n\n#Não consegui instalar o patchwork\nlibrary(patchwork)\n\n(p1 / p2) + #pode ser + ou |, se colocar / coloca um sobre o outro. Ele funciona como equação, pode ser feito combinação dos gráficos como p1/(p2+p1)\nplot_layout(guides = \"collect\",\n            axes = \"collect\")+ #Deixa somente uma legenda\nplot_annotation(title = \"Coffe rust is Ethiopia\",\n                caption = \"source: Serafini (2024)\",\n                tag_levels = \"A\") #diferencia maiúsculas e minúsculas\n\n\n\n\n\n\n\nggsave(\"patch2.png\", width = 5, height = 4)\n\nOutra opção de combinações que o pacote permite é a sobreposição de gráficos através da função inset_element(), onde é inserido o gráfico que se deseja plotar e as dimensões/posições deste na imagem. Este é um excelente artifício para exibir informações gráficas complementares em uma mesma imagem.\n\np1 &lt;- cr_oromia |&gt;\n  ggplot(aes(x = cultivar,\n             y = sev2,\n             fill = cultivar))+\n  geom_boxplot()+\n  theme_few() +\n  labs(x = \"Cultivar\",\n       y = \"Severity (%)\")+\n  coord_flip() #rotaciona as coordenadas\n\np3 &lt;- cr_oromia |&gt;\n  ggplot(aes(x = sev2))+\n  geom_histogram() +\n  labs(y = \"Freq.\",\n       x = \"Severity (%)\")\n\np1 + inset_element(p3, left = 0.6,\n                    bottom = 0.6,\n                    right = 1,\n                    top = 1) +\n  plot_annotation(title = \"Coffe rust is Ethiopia\",\n                caption = \"source: Serafini (2024)\",\n                tag_levels = \"A\") #diferencia maiúsculas e minúsculas\n\n`stat_bin()` using `bins = 30`. Pick better value with `binwidth`.\n\n\n\n\n\n\n\n\nggsave(\"patch3.png\", width = 5, height = 4)\n\n`stat_bin()` using `bins = 30`. Pick better value with `binwidth`.\n\n\nO patchwork tem várias possíbilidades interessantes, vale a pena olhar a ajuda (help) deste pacote!"
  },
  {
    "objectID": "aula_02a.html",
    "href": "aula_02a.html",
    "title": "Pacotes no R",
    "section": "",
    "text": "Pacotes são coleções de funções, dados e documentação que expandem as capacidades básicas do R. O tidyverse, que usaremos como exemplo, é um conjunto de pacotes R projetados para a ciência de dados, incluindo ggplot2, dplyr, tidyr, readr, purrr, tibble, stringr e forcats.\n\n\nPara instalar pacotes como tidyverse, você pode usar a função install.packages():\ninstall.packages(\"tidyverse\")\nCaso esteje utilizando o RStudio, pode acessar o menu de instalação de pacotes e instalar seguindo os seguintes passos:\n\nNo menu superior do RStudio, clique em Tools.\nSelecione Install Packages... no menu suspenso.\nNa janela que se abre, digite o nome do pacote, no nosso caso o tidyverse, no campo de texto.\nCertifique-se de que a opção “Install dependencies” está marcada, para que todas as dependências sejam instaladas também.\nClique no botão Install.\n\n\n\n\nO carregamento de pacotes pode ser feito pelo menu ou então com um comando no console. Após a instalação, você precisa carregar o pacote para utilizá-lo em sua sessão de R. Isso é feito com a função library():\nlibrary(tidyverse)\nUma vez carregado, você pode utilizar as funções e dados disponíveis no pacote carregado.\n\n\n\nPara obter ajuda sobre um pacote ou uma função específica, você pode usar a função help() ou ?. Por exemplo, para obter ajuda sobre o pacote tidyverse:\nhelp(package = \"tidyverse\")\nOu para obter ajuda sobre uma função específica dentro do dplyr, como mutate:\n?mutate\nVocê também pode usar a função help.search() para buscar tópicos de ajuda relacionados a um termo específico:\nhelp.search(\"mutate\")\nAlém disso, a função vignette() pode ser usada para acessar tutoriais e exemplos incluídos no pacote. Para listar todas as vinhetas disponíveis:\nvignette(package = \"tidyverse\")\nE para abrir uma vinheta específica:\nvignette(\"tidy-data\")"
  },
  {
    "objectID": "aula_02a.html#como-instalar",
    "href": "aula_02a.html#como-instalar",
    "title": "Pacotes no R",
    "section": "",
    "text": "Para instalar pacotes como tidyverse, você pode usar a função install.packages():\ninstall.packages(\"tidyverse\")\nCaso esteje utilizando o RStudio, pode acessar o menu de instalação de pacotes e instalar seguindo os seguintes passos:\n\nNo menu superior do RStudio, clique em Tools.\nSelecione Install Packages... no menu suspenso.\nNa janela que se abre, digite o nome do pacote, no nosso caso o tidyverse, no campo de texto.\nCertifique-se de que a opção “Install dependencies” está marcada, para que todas as dependências sejam instaladas também.\nClique no botão Install."
  },
  {
    "objectID": "aula_02a.html#como-carregar-os-pacotes",
    "href": "aula_02a.html#como-carregar-os-pacotes",
    "title": "Pacotes no R",
    "section": "",
    "text": "O carregamento de pacotes pode ser feito pelo menu ou então com um comando no console. Após a instalação, você precisa carregar o pacote para utilizá-lo em sua sessão de R. Isso é feito com a função library():\nlibrary(tidyverse)\nUma vez carregado, você pode utilizar as funções e dados disponíveis no pacote carregado."
  },
  {
    "objectID": "aula_02a.html#como-pedir-ou-ver-ajuda-sobre-o-pacote",
    "href": "aula_02a.html#como-pedir-ou-ver-ajuda-sobre-o-pacote",
    "title": "Pacotes no R",
    "section": "",
    "text": "Para obter ajuda sobre um pacote ou uma função específica, você pode usar a função help() ou ?. Por exemplo, para obter ajuda sobre o pacote tidyverse:\nhelp(package = \"tidyverse\")\nOu para obter ajuda sobre uma função específica dentro do dplyr, como mutate:\n?mutate\nVocê também pode usar a função help.search() para buscar tópicos de ajuda relacionados a um termo específico:\nhelp.search(\"mutate\")\nAlém disso, a função vignette() pode ser usada para acessar tutoriais e exemplos incluídos no pacote. Para listar todas as vinhetas disponíveis:\nvignette(package = \"tidyverse\")\nE para abrir uma vinheta específica:\nvignette(\"tidy-data\")"
  },
  {
    "objectID": "aula_01a.html",
    "href": "aula_01a.html",
    "title": "Instalação",
    "section": "",
    "text": "A linguagem de programação R é um ambiente de software livre voltado para computação estatística e gráficos, amplamente utilizada por estatísticos, cientistas de dados e analistas. Desenvolvida inicialmente na Universidade de Auckland, R é conhecida por suas capacidades avançadas de análise de dados, visualização gráfica e extensa biblioteca de pacotes disponíveis no CRAN. Sua flexibilidade permite a realização de tarefas que vão desde a manipulação de dados simples até modelagem estatística complexa. Gratuito e de código aberto, R conta com uma comunidade ativa que contribui para seu contínuo desenvolvimento e aplicação em diversas áreas, incluindo pesquisa acadêmica, finanças e bioinformática.\nO RStudio é um ambiente de desenvolvimento integrado (IDE) para a linguagem R, projetado para facilitar a análise de dados e o desenvolvimento de código, apesar de não ser obrigatório para o funcionamento do software R sua instalação e utilização é amplamente recomendada. Ele oferece um editor de código avançado, um console interativo, ferramentas de visualização de dados, gerenciamento de pacotes e suporte a RMarkdown, além de integração com sistemas de controle de versão como Git e SVN. Com uma interface intuitiva e recursos que aumentam a produtividade, RStudio é amplamente utilizado tanto por iniciantes quanto por especialistas em ciência de dados.\n\n\nInstalar o R é um processo simples e direto. Siga os passos abaixo para instalar o R no seu sistema:\n\n\n\nAcesse o site oficial do R:\n\nAbra seu navegador e vá para CRAN (The Comprehensive R Archive Network).\n\nEscolha seu sistema operacional:\n\nWindows: Clique em “Download R for Windows”.\nmacOS: Clique em “Download R for (Mac) OS X”.\nLinux: Clique em “Download R for Linux”.\n\nBaixe o instalador:\nExecute o instalador:\nSiga as instruções do instalador:\n\nOBS.: A instalação varia de acordo com o sistema operacional do seu computador, um passo a passo mais detalhado pode ser fácilmente encontrado no site do R-Project, onde realizou o download do software.\n\n\n\n\nAbrir o R:\n\nNo Windows e macOS, procure o ícone do R no menu Iniciar ou no Launchpad, respectivamente, e clique para abrir.\nNo Linux, abra um terminal e digite R para iniciar o console do R.\n\nVerificar a versão do R:\n\nNo console do R, digite o comando version e pressione Enter. Isso exibirá informações sobre a versão do R instalada.\n\n\n\n\n\n\n\nBaixar o RStudio:\n\nAcesse o site doRStudio e baixe a versão apropriada para seu sistema operacional.\n\nInstalar o RStudio:\n\nNo Windows, execute o instalador baixado e siga as instruções.\nNo macOS, abra o pacote .dmg baixado e arraste o ícone do RStudio para a pasta Aplicativos.\nNo Linux, siga as instruções específicas para a sua distribuição no site do RStudio.\n\nAbrir o RStudio:\n\nApós a instalação, abra o RStudio a partir do menu Iniciar, Launchpad ou terminal."
  },
  {
    "objectID": "aula_01a.html#instalando-o-r-guia-rápido",
    "href": "aula_01a.html#instalando-o-r-guia-rápido",
    "title": "Instalação",
    "section": "",
    "text": "Instalar o R é um processo simples e direto. Siga os passos abaixo para instalar o R no seu sistema:\n\n\n\nAcesse o site oficial do R:\n\nAbra seu navegador e vá para CRAN (The Comprehensive R Archive Network).\n\nEscolha seu sistema operacional:\n\nWindows: Clique em “Download R for Windows”.\nmacOS: Clique em “Download R for (Mac) OS X”.\nLinux: Clique em “Download R for Linux”.\n\nBaixe o instalador:\nExecute o instalador:\nSiga as instruções do instalador:\n\nOBS.: A instalação varia de acordo com o sistema operacional do seu computador, um passo a passo mais detalhado pode ser fácilmente encontrado no site do R-Project, onde realizou o download do software.\n\n\n\n\nAbrir o R:\n\nNo Windows e macOS, procure o ícone do R no menu Iniciar ou no Launchpad, respectivamente, e clique para abrir.\nNo Linux, abra um terminal e digite R para iniciar o console do R.\n\nVerificar a versão do R:\n\nNo console do R, digite o comando version e pressione Enter. Isso exibirá informações sobre a versão do R instalada."
  },
  {
    "objectID": "aula_01a.html#instalando-o-rstudio",
    "href": "aula_01a.html#instalando-o-rstudio",
    "title": "Instalação",
    "section": "",
    "text": "Baixar o RStudio:\n\nAcesse o site doRStudio e baixe a versão apropriada para seu sistema operacional.\n\nInstalar o RStudio:\n\nNo Windows, execute o instalador baixado e siga as instruções.\nNo macOS, abra o pacote .dmg baixado e arraste o ícone do RStudio para a pasta Aplicativos.\nNo Linux, siga as instruções específicas para a sua distribuição no site do RStudio.\n\nAbrir o RStudio:\n\nApós a instalação, abra o RStudio a partir do menu Iniciar, Launchpad ou terminal."
  },
  {
    "objectID": "about.html",
    "href": "about.html",
    "title": "About",
    "section": "",
    "text": "About this site\n\n1 + 1\n\n[1] 2"
  },
  {
    "objectID": "aula_01b.html",
    "href": "aula_01b.html",
    "title": "R Markdown e Quarto Document",
    "section": "",
    "text": "Ferramentas de autoria são softwares ou plataformas que permitem aos usuários criar, editar e publicar conteúdo. Essas ferramentas são projetadas para facilitar a produção de documentos, apresentações, relatórios, livros e outros tipos de conteúdo técnico ou educacional. Elas geralmente oferecem recursos que combinam texto, multimídia e, em alguns casos, código de programação para gerar documentos dinâmicos e interativos.\n\n\nR Markdown é uma ferramenta que permite combinar texto, código R e os resultados do código (como gráficos e tabelas) em um único documento. É usada para criar relatórios dinâmicos, apresentações e documentos que podem ser exportados para formatos como HTML, PDF e Word. É especialmente útil para criar análises reprodutíveis, pois integra o código diretamente no documento.\n\n\n\nQuarto é uma plataforma que expande as capacidades do R Markdown, suportando as linguagens R, Python, Julia e Observable JavaScript. Ele permite a criação de documentos técnicos, relatórios, blogs, livros e apresentações. Quarto oferece maior flexibilidade, suporte a múltiplas linguagens e integração com ferramentas modernas como GitHub Actions.\n\n\n\n\nR Markdown: Principalmente para R, focado em relatórios reprodutíveis e apresentações.\nQuarto: Suporta várias linguagens, oferece mais personalização e é ideal para uma ampla gama de documentos técnicos.\n\nOBS.: Nas aulas, foi optado pelo Quarto para documentar as aulas devido a sua ampla gama de ferrementas e capacidade de integração com outras ferramentas."
  },
  {
    "objectID": "aula_01b.html#r-markdown",
    "href": "aula_01b.html#r-markdown",
    "title": "R Markdown e Quarto Document",
    "section": "",
    "text": "R Markdown é uma ferramenta que permite combinar texto, código R e os resultados do código (como gráficos e tabelas) em um único documento. É usada para criar relatórios dinâmicos, apresentações e documentos que podem ser exportados para formatos como HTML, PDF e Word. É especialmente útil para criar análises reprodutíveis, pois integra o código diretamente no documento."
  },
  {
    "objectID": "aula_01b.html#quarto-document",
    "href": "aula_01b.html#quarto-document",
    "title": "R Markdown e Quarto Document",
    "section": "",
    "text": "Quarto é uma plataforma que expande as capacidades do R Markdown, suportando as linguagens R, Python, Julia e Observable JavaScript. Ele permite a criação de documentos técnicos, relatórios, blogs, livros e apresentações. Quarto oferece maior flexibilidade, suporte a múltiplas linguagens e integração com ferramentas modernas como GitHub Actions."
  },
  {
    "objectID": "aula_01b.html#diferenças",
    "href": "aula_01b.html#diferenças",
    "title": "R Markdown e Quarto Document",
    "section": "",
    "text": "R Markdown: Principalmente para R, focado em relatórios reprodutíveis e apresentações.\nQuarto: Suporta várias linguagens, oferece mais personalização e é ideal para uma ampla gama de documentos técnicos.\n\nOBS.: Nas aulas, foi optado pelo Quarto para documentar as aulas devido a sua ampla gama de ferrementas e capacidade de integração com outras ferramentas."
  },
  {
    "objectID": "aula_02b.html",
    "href": "aula_02b.html",
    "title": "Importando e Manipulando dados",
    "section": "",
    "text": "A importação de dados é um passo crucial na análise de dados, pois permite que você traga informações de várias fontes para dentro do ambiente R, onde podem ser limpas, manipuladas e analisadas. Com R, você pode importar dados de diversos formatos, como CSV, Excel, e até mesmo planilhas online do Google Sheets. Utilizar pacotes específicos para cada tipo de arquivo garante que os dados sejam lidos de maneira eficiente e sem erros.\n\n\nMuitas vezes, com o intuito de que o usuário possa testar algumas funções dos pacotes, estes pacotes possuem conjuntos de dados que podem ser importados ou carregados e utilizados.\nA título de ensino, vamos começar com a instalação e carregamento do pacote ec50estimator, que é utilizado para estimativas de EC50 em análises biológicas. Neste pacote, utilizaremos o conjunto de dados multi_isolate.\n\nlibrary(ec50estimator)\n\nWarning: pacote 'ec50estimator' foi compilado no R versão 4.4.1\n\nhead(multi_isolate)\n\n  isolate   field   fungicida  dose     growth\n1       1 Organic Fungicide A 0e+00 20.2082399\n2       1 Organic Fungicide A 1e-05 20.1168279\n3       1 Organic Fungicide A 1e-04 19.2479678\n4       1 Organic Fungicide A 1e-03 15.8123455\n5       1 Organic Fungicide A 1e-02  7.3206757\n6       1 Organic Fungicide A 1e-01  0.6985264\n\n\nPodemos atribuir os dados a um objeto, neste caso ao objeto df1 e usaremos a função View(df1) para abrir uma nova aba exibindo os dados. View() é particularmente útil para uma inspeção rápida dos dados em uma interface tabular.\n\ndf1 &lt;- multi_isolate\nView(df1)\n\n\n\n\nOutra opção é a importação de arquivos existentes no próprio computador do usuário, como arquivos de dados em Excel. Para a leitura e importação de dados em Excel, utilizaremos o pacote readxl, e para isso é necessário que instale e carregue este pacote.\nO pacote readxl, que permite a leitura de arquivos Excel (.xlsx). Este pacote é especialmente útil para importar dados que são frequentemente armazenados em planilhas.\nPara ler um arquivo Excel na pasta do projeto, use o comando read_excel(\"nome_do_arquivo.xlsx\"), caso o arquivo esteja em outra pasta é necessário colocar, dentro dos parênteses, o caminho do arquivo antes do nome.\nSe você precisar abrir uma planilha específica, como “escala”, utilize o argumento sheet. O segundo argumento é um parâmetro opcional, podendo ser o nome da aba ou apenas o número da aba sem aspas.\n\nlibrary(readxl)\ndf2 &lt;- read_excel(\"dados-diversos.xlsx\")\ndf21 &lt;- read_excel(\"dados-diversos.xlsx\", sheet = \"escala\")\n#Outras formas de abri e/ou atribuir abas específicas\n#df21 &lt;- read_excel(\"dados-diversos.xlsx\", \"escala\")\n#df21 &lt;- read_excel(\"dados-diversos.xlsx\", 2)\n\n\n\n\nOutra opção, para arquivos CSV, é a utilização do pacote tidyverse, uma coleção de pacotes R para ciência de dados, incluindo readr para leitura de arquivos CSV. O tidyverse simplifica e uniformiza várias operações de manipulação de dados.\nNeste caso utilizamos a função read_csv``(\"nome_do_arquivo.xlsx\"), lembrando que, caso o arquivo esteja em outra pasta é necessário colocar o caminho do arquivo antes do nome.\n\nlibrary(tidyverse)\n\n── Attaching core tidyverse packages ──────────────────────── tidyverse 2.0.0 ──\n✔ dplyr     1.1.4     ✔ readr     2.1.5\n✔ forcats   1.0.0     ✔ stringr   1.5.1\n✔ ggplot2   3.5.1     ✔ tibble    3.2.1\n✔ lubridate 1.9.3     ✔ tidyr     1.3.1\n✔ purrr     1.0.2     \n── Conflicts ────────────────────────────────────────── tidyverse_conflicts() ──\n✖ dplyr::filter() masks stats::filter()\n✖ dplyr::lag()    masks stats::lag()\nℹ Use the conflicted package (&lt;http://conflicted.r-lib.org/&gt;) to force all conflicts to become errors\n\ndf3 &lt;- read_csv(\"dados-diversos.csv\")\n\nRows: 60 Columns: 4\n── Column specification ────────────────────────────────────────────────────────\nDelimiter: \",\"\nchr (1): Irrigation\ndbl (3): rep, day, severity\n\nℹ Use `spec()` to retrieve the full column specification for this data.\nℹ Specify the column types or set `show_col_types = FALSE` to quiet this message.\n\n\n\n\n\nAtualmente a utilização de drives em nuvem para salvar bancos de dados está amplamente difundida Isso é devido a facilidade de acesso aos dados, que pode ser feita de qualquer dispositivo, desde que se tenha acesso a internet.\nPara utilizar um banco de dados diretamente do Google Drive, por exemplo, pode-se utilizar os pacotes gsheet e googlesheets4. O pacote gsheet permite a leitura rápida de Google Sheets usando URLs, enquanto o googlesheets4 oferece funcionalidade mais abrangente para leitura e escrita em Google Sheets.\nNo caso do pacote gsheet, a função utilizada para abrir e importar dados de arquivos no Google Drive é o gsheet2tbl(``\"link_do_arquivo\").\n\nlibrary(gsheet)\ndf4 &lt;- gsheet2tbl(\"https://docs.google.com/spreadsheets/d/1bq2N19DcZdtax2fQW9OHSGMR0X2__Z9T/edit?gid=983033137#gid=983033137\")\n\ndf41 &lt;- gsheet2tbl(\"https://docs.google.com/spreadsheets/d/1bq2N19DcZdtax2fQW9OHSGMR0X2__Z9T/edit?usp=drive_link&ouid=104144100918915406194&rtpof=true&sd=true\", sheetid = \"3\")\n\nPara o pacote googlesheets4, o nome da função é read_sheet``(\"link_do_arquivo\"). Ele permite não somente baixar, mas ele permite também escrever nos arquivos.\nlibrary(googlesheets4) df5 &lt;- read_sheet(\"https://docs.google.com/spreadsheets/d/1aID5Dh6PlBVCKzU1j7k-WA6zuWQWE2NhtWEgdJtt5iA/edit?usp=sharing\")\n\n\n\nPara criar gráficos para análise exploratória das variáveis, utilizaremos o ggplot2, um dos pacotes mais populares do R para visualização de dados. A função geom_point mostra os pontos de uma variável, mas pode ocorrer destes pontos estarem sobrepostos, assim pode-se utilizar a função geom_jitter para desagregar os pontos.\nPodemos adicionar camadas com o operador +, como geom_boxplot. A ordem das camadas determina como elas serão exibidas: a primeira camada chamada fica na parte inferior e as subsequentes são empilhadas acima.\nPara evitar duplicação de outliers, utilize outlier.colour = NA.\nTemas específicos também podem ser aplicados, como theme_bw() para um visual preto e branco utilizado em artigos cientificos, ou theme_classic.\n\nlibrary(ggplot2)\ng1 &lt;- df4 |&gt;\n  ggplot(aes(trat, comp))+\n  geom_point(color = \"red\", shape = 2, size = 3)\ng1 + theme_classic()+\n  labs(x = \"Tratamento\", #Label do eixo x\n       y = \"Comprimento\", #Label do eixo y\n       title = \"Meu primeiro ggplot\", #Adiciona título ao gráfico\n       caption = \"Fonte: Dados diversos\") #Adiciona fonte ao gráfico\n\n\n\n\n\n\n\ng2 &lt;- df4 |&gt;\n  ggplot(aes(trat, comp))+\n  geom_boxplot(outlier.colour = NA,\n               fill = \"green\")+\n  geom_jitter(width = 0.05,\n              color = \"blue\",\n              shape = 3,\n              size = 2)\ng2 + theme_bw() +\n  #ylim(0,20) #Outra opção para a função abaixo\n  scale_y_continuous(limits = c(0,20),\n                     n.breaks = 5) #n.breaks é o número de quebras, se colocar breaks apenas, fica só a linha correspondente aquele número.\n\n\n\n\n\n\n\n\nApós a criação do gráfico, através do pacote ggplot2, podemos salvar os gráficos utilizando a função ggsave. A função ggsave é usada para salvar gráficos criados com ggplot2 em diferentes formatos de arquivo, como PNG, PDF, JPEG, entre outros. Isso é útil para documentar visualizações, compartilhar resultados ou incluir gráficos em relatórios e apresentações.\n\nggsave(\"plot1.png\", bg = \"white\") #O parâmetro \"bg\" é a cor de fundo ou \"background\"\n\nSaving 7 x 5 in image\n\n\nEntendendo esses passos, você será capaz de importar dados de diversas fontes, realizar manipulações e criar visualizações ricas utilizando R e seus pacotes associados. Cada pacote desempenha um papel crucial na simplificação e eficiência das suas tarefas de análise de dados."
  },
  {
    "objectID": "aula_02b.html#importando-dados-de-pacotes",
    "href": "aula_02b.html#importando-dados-de-pacotes",
    "title": "Importando e Manipulando dados",
    "section": "",
    "text": "Muitas vezes, com o intuito de que o usuário possa testar algumas funções dos pacotes, estes pacotes possuem conjuntos de dados que podem ser importados ou carregados e utilizados.\nA título de ensino, vamos começar com a instalação e carregamento do pacote ec50estimator, que é utilizado para estimativas de EC50 em análises biológicas. Neste pacote, utilizaremos o conjunto de dados multi_isolate.\n\nlibrary(ec50estimator)\n\nWarning: pacote 'ec50estimator' foi compilado no R versão 4.4.1\n\nhead(multi_isolate)\n\n  isolate   field   fungicida  dose     growth\n1       1 Organic Fungicide A 0e+00 20.2082399\n2       1 Organic Fungicide A 1e-05 20.1168279\n3       1 Organic Fungicide A 1e-04 19.2479678\n4       1 Organic Fungicide A 1e-03 15.8123455\n5       1 Organic Fungicide A 1e-02  7.3206757\n6       1 Organic Fungicide A 1e-01  0.6985264\n\n\nPodemos atribuir os dados a um objeto, neste caso ao objeto df1 e usaremos a função View(df1) para abrir uma nova aba exibindo os dados. View() é particularmente útil para uma inspeção rápida dos dados em uma interface tabular.\n\ndf1 &lt;- multi_isolate\nView(df1)"
  },
  {
    "objectID": "aula_02b.html#leitura-e-importação-de-dados-de-arquivos-excel",
    "href": "aula_02b.html#leitura-e-importação-de-dados-de-arquivos-excel",
    "title": "Importando e Manipulando dados",
    "section": "",
    "text": "Outra opção é a importação de arquivos existentes no próprio computador do usuário, como arquivos de dados em Excel. Para a leitura e importação de dados em Excel, utilizaremos o pacote readxl, e para isso é necessário que instale e carregue este pacote.\nO pacote readxl, que permite a leitura de arquivos Excel (.xlsx). Este pacote é especialmente útil para importar dados que são frequentemente armazenados em planilhas.\nPara ler um arquivo Excel na pasta do projeto, use o comando read_excel(\"nome_do_arquivo.xlsx\"), caso o arquivo esteja em outra pasta é necessário colocar, dentro dos parênteses, o caminho do arquivo antes do nome.\nSe você precisar abrir uma planilha específica, como “escala”, utilize o argumento sheet. O segundo argumento é um parâmetro opcional, podendo ser o nome da aba ou apenas o número da aba sem aspas.\n\nlibrary(readxl)\ndf2 &lt;- read_excel(\"dados-diversos.xlsx\")\ndf21 &lt;- read_excel(\"dados-diversos.xlsx\", sheet = \"escala\")\n#Outras formas de abri e/ou atribuir abas específicas\n#df21 &lt;- read_excel(\"dados-diversos.xlsx\", \"escala\")\n#df21 &lt;- read_excel(\"dados-diversos.xlsx\", 2)"
  },
  {
    "objectID": "aula_02b.html#leitura-e-importação-de-dados-de-arquivos-csv",
    "href": "aula_02b.html#leitura-e-importação-de-dados-de-arquivos-csv",
    "title": "Importando e Manipulando dados",
    "section": "",
    "text": "Outra opção, para arquivos CSV, é a utilização do pacote tidyverse, uma coleção de pacotes R para ciência de dados, incluindo readr para leitura de arquivos CSV. O tidyverse simplifica e uniformiza várias operações de manipulação de dados.\nNeste caso utilizamos a função read_csv``(\"nome_do_arquivo.xlsx\"), lembrando que, caso o arquivo esteja em outra pasta é necessário colocar o caminho do arquivo antes do nome.\n\nlibrary(tidyverse)\n\n── Attaching core tidyverse packages ──────────────────────── tidyverse 2.0.0 ──\n✔ dplyr     1.1.4     ✔ readr     2.1.5\n✔ forcats   1.0.0     ✔ stringr   1.5.1\n✔ ggplot2   3.5.1     ✔ tibble    3.2.1\n✔ lubridate 1.9.3     ✔ tidyr     1.3.1\n✔ purrr     1.0.2     \n── Conflicts ────────────────────────────────────────── tidyverse_conflicts() ──\n✖ dplyr::filter() masks stats::filter()\n✖ dplyr::lag()    masks stats::lag()\nℹ Use the conflicted package (&lt;http://conflicted.r-lib.org/&gt;) to force all conflicts to become errors\n\ndf3 &lt;- read_csv(\"dados-diversos.csv\")\n\nRows: 60 Columns: 4\n── Column specification ────────────────────────────────────────────────────────\nDelimiter: \",\"\nchr (1): Irrigation\ndbl (3): rep, day, severity\n\nℹ Use `spec()` to retrieve the full column specification for this data.\nℹ Specify the column types or set `show_col_types = FALSE` to quiet this message."
  },
  {
    "objectID": "aula_02b.html#leitura-e-importação-de-dados-de-arquivos-do-drive-utilizando-google-sheets",
    "href": "aula_02b.html#leitura-e-importação-de-dados-de-arquivos-do-drive-utilizando-google-sheets",
    "title": "Importando e Manipulando dados",
    "section": "",
    "text": "Atualmente a utilização de drives em nuvem para salvar bancos de dados está amplamente difundida Isso é devido a facilidade de acesso aos dados, que pode ser feita de qualquer dispositivo, desde que se tenha acesso a internet.\nPara utilizar um banco de dados diretamente do Google Drive, por exemplo, pode-se utilizar os pacotes gsheet e googlesheets4. O pacote gsheet permite a leitura rápida de Google Sheets usando URLs, enquanto o googlesheets4 oferece funcionalidade mais abrangente para leitura e escrita em Google Sheets.\nNo caso do pacote gsheet, a função utilizada para abrir e importar dados de arquivos no Google Drive é o gsheet2tbl(``\"link_do_arquivo\").\n\nlibrary(gsheet)\ndf4 &lt;- gsheet2tbl(\"https://docs.google.com/spreadsheets/d/1bq2N19DcZdtax2fQW9OHSGMR0X2__Z9T/edit?gid=983033137#gid=983033137\")\n\ndf41 &lt;- gsheet2tbl(\"https://docs.google.com/spreadsheets/d/1bq2N19DcZdtax2fQW9OHSGMR0X2__Z9T/edit?usp=drive_link&ouid=104144100918915406194&rtpof=true&sd=true\", sheetid = \"3\")\n\nPara o pacote googlesheets4, o nome da função é read_sheet``(\"link_do_arquivo\"). Ele permite não somente baixar, mas ele permite também escrever nos arquivos.\nlibrary(googlesheets4) df5 &lt;- read_sheet(\"https://docs.google.com/spreadsheets/d/1aID5Dh6PlBVCKzU1j7k-WA6zuWQWE2NhtWEgdJtt5iA/edit?usp=sharing\")"
  },
  {
    "objectID": "aula_02b.html#visualização-de-dados",
    "href": "aula_02b.html#visualização-de-dados",
    "title": "Importando e Manipulando dados",
    "section": "",
    "text": "Para criar gráficos para análise exploratória das variáveis, utilizaremos o ggplot2, um dos pacotes mais populares do R para visualização de dados. A função geom_point mostra os pontos de uma variável, mas pode ocorrer destes pontos estarem sobrepostos, assim pode-se utilizar a função geom_jitter para desagregar os pontos.\nPodemos adicionar camadas com o operador +, como geom_boxplot. A ordem das camadas determina como elas serão exibidas: a primeira camada chamada fica na parte inferior e as subsequentes são empilhadas acima.\nPara evitar duplicação de outliers, utilize outlier.colour = NA.\nTemas específicos também podem ser aplicados, como theme_bw() para um visual preto e branco utilizado em artigos cientificos, ou theme_classic.\n\nlibrary(ggplot2)\ng1 &lt;- df4 |&gt;\n  ggplot(aes(trat, comp))+\n  geom_point(color = \"red\", shape = 2, size = 3)\ng1 + theme_classic()+\n  labs(x = \"Tratamento\", #Label do eixo x\n       y = \"Comprimento\", #Label do eixo y\n       title = \"Meu primeiro ggplot\", #Adiciona título ao gráfico\n       caption = \"Fonte: Dados diversos\") #Adiciona fonte ao gráfico\n\n\n\n\n\n\n\ng2 &lt;- df4 |&gt;\n  ggplot(aes(trat, comp))+\n  geom_boxplot(outlier.colour = NA,\n               fill = \"green\")+\n  geom_jitter(width = 0.05,\n              color = \"blue\",\n              shape = 3,\n              size = 2)\ng2 + theme_bw() +\n  #ylim(0,20) #Outra opção para a função abaixo\n  scale_y_continuous(limits = c(0,20),\n                     n.breaks = 5) #n.breaks é o número de quebras, se colocar breaks apenas, fica só a linha correspondente aquele número.\n\n\n\n\n\n\n\n\nApós a criação do gráfico, através do pacote ggplot2, podemos salvar os gráficos utilizando a função ggsave. A função ggsave é usada para salvar gráficos criados com ggplot2 em diferentes formatos de arquivo, como PNG, PDF, JPEG, entre outros. Isso é útil para documentar visualizações, compartilhar resultados ou incluir gráficos em relatórios e apresentações.\n\nggsave(\"plot1.png\", bg = \"white\") #O parâmetro \"bg\" é a cor de fundo ou \"background\"\n\nSaving 7 x 5 in image\n\n\nEntendendo esses passos, você será capaz de importar dados de diversas fontes, realizar manipulações e criar visualizações ricas utilizando R e seus pacotes associados. Cada pacote desempenha um papel crucial na simplificação e eficiência das suas tarefas de análise de dados."
  },
  {
    "objectID": "aula_04.html",
    "href": "aula_04.html",
    "title": "Visualização de dados, outras abordagens",
    "section": "",
    "text": "A visualização de dados é essencial para entender e comunicar padrões e insights, existindo inúmeras possíbilidades de importação de dados. Agora iremos explorar outras técnicas e pacotes no R que facilitam a importação e visualização de datasets.\n\n\nUma das formas é a concatenação de dados de forma manual os atribuindo a um objeto. Para isso podemos utilizar a função nativa c() que concatena os dados, separados por vírgula.\n\ncomp &lt;- c(\"9\", \"12.5\", \"10\", \"8\", \"13.2\", \"11\", \"10.8\", \"9.5\", \"10.8\", \"10.4\", \"13.72\", \"15.91\", \"15.7\", \"14.2\", \"15.9\", \"16.54\", \"18\", \"14.4\", \"16.41\", \"16\")\ncomp\n\n [1] \"9\"     \"12.5\"  \"10\"    \"8\"     \"13.2\"  \"11\"    \"10.8\"  \"9.5\"   \"10.8\" \n[10] \"10.4\"  \"13.72\" \"15.91\" \"15.7\"  \"14.2\"  \"15.9\"  \"16.54\" \"18\"    \"14.4\" \n[19] \"16.41\" \"16\"   \n\ncomp &lt;- c(9, 12.5, 10, 8, 13.2, 11, 10.8, 9.5, 10.8, 10.4, 13.72, 15.91, 15.7, 14.2, 15.9, 16.54, 18, 14.4, 16.41, 16)\ncomp\n\n [1]  9.00 12.50 10.00  8.00 13.20 11.00 10.80  9.50 10.80 10.40 13.72 15.91\n[13] 15.70 14.20 15.90 16.54 18.00 14.40 16.41 16.00\n\n\nTambém podemos utilizar o pacote datapasta, que permite copiar dados de qualquer lugar e colar diretamente no R como uma tibble.\n\nlibrary(datapasta)\nvisitas &lt;- tibble::tribble(\n             ~`codigo`,          ~país, ~`n2`,\n             1L,     \"Brazil\",      4303L,\n               2L,     \"Mozambique\",      43L,\n               3L,       \"Portugal\",      33L,\n               4L,  \"United States\",      23L,\n               5L,         \"Angola\",      19L,\n               6L,          \"Spain\",      16L,\n               7L,      \"(not set)\",      12L,\n               8L,       \"Colombia\",       8L,\n               9L,        \"Germany\",       5L,\n              10L,        \"Hungary\",       5L,\n              11L, \"United Kingdom\",       5L,\n              12L,    \"Netherlands\",       4L,\n              13L,        \"Ecuador\",       3L,\n              14L,         \"France\",       3L,\n              15L,          \"Chile\",       2L,\n              16L,       \"Paraguay\",       2L,\n              17L,           \"Peru\",       2L,\n              18L,      \"Argentina\",       1L,\n              19L,        \"Austria\",       1L,\n              20L,        \"Bolivia\",       1L,\n              21L,     \"Cape Verde\",       1L,\n              22L,          \"China\",       1L,\n              23L,          \"Egypt\",       1L,\n              24L,        \"Finland\",       1L,\n              25L,          \"India\",       1L,\n              26L,          \"Italy\",       1L,\n              27L,       \"Malaysia\",       1L,\n              28L,       \"Pakistan\",       1L,\n              29L,         \"Poland\",       1L,\n              30L,      \"Singapore\",       1L,\n              31L,    \"Timor-Leste\",       1L,\n              32L,        \"Uruguay\",       1L\n             )\nhead(visitas)\n\n# A tibble: 6 × 3\n  codigo país             n2\n   &lt;int&gt; &lt;chr&gt;         &lt;int&gt;\n1      1 Brazil         4303\n2      2 Mozambique       43\n3      3 Portugal         33\n4      4 United States    23\n5      5 Angola           19\n6      6 Spain            16\n\n\n\n\n\nO pacote pak permite que os dados sejam baixados de outros repositórios. Para isso, inicialmente precisamos instalar o pacote.\n\n#install.packages(\"pak\")\n\nAgora, poderemos instalar pacotes de outros repositórios, como o Icens, que será utilizado em outros tópicos. Muitos destes pacotes contem datasets que podem ser utilizados para testes de funções.\n\n#pak::pkg_install(\"Icens\")\n\nTambém podemos baixar os pacortes diretamente do github, como o pacote do Prof. Emerson, r4pde através do caminho “emdelponte/r4pde”.\n\n#pak::pkg_install(\"emdelponte/r4pde\")\n\n\n\n\nVocê pode transformar dados de formato largo para formato longo (e vice-versa) usando tidyverse. Para isso vamos praticar utilizando a função tribble, para colarmos os dados do caopítulo 10.4 do livro r4pde.\n\nlibrary(tidyverse)\n\n── Attaching core tidyverse packages ──────────────────────── tidyverse 2.0.0 ──\n✔ dplyr     1.1.4     ✔ readr     2.1.5\n✔ forcats   1.0.0     ✔ stringr   1.5.1\n✔ ggplot2   3.5.1     ✔ tibble    3.2.1\n✔ lubridate 1.9.3     ✔ tidyr     1.3.1\n✔ purrr     1.0.2     \n── Conflicts ────────────────────────────────────────── tidyverse_conflicts() ──\n✖ dplyr::filter() masks stats::filter()\n✖ dplyr::lag()    masks stats::lag()\nℹ Use the conflicted package (&lt;http://conflicted.r-lib.org/&gt;) to force all conflicts to become errors\n\npepper &lt;- \n  tribble(\n   ~t,  ~`1`,  ~`2`,  ~`3`,\n   0,  0.08, 0.001, 0.001,\n   7,  0.13,  0.01, 0.001,\n  14,  0.78,  0.09,  0.01,\n  21,  0.92,  0.25,  0.05,\n  28,  0.99,   0.8,  0.18,\n  35, 0.995,  0.98,  0.34,\n  42, 0.999,  0.99,  0.48,\n  49, 0.999, 0.999,  0.74\n  ) \n\n\n\nNo ggplot2, annotate é uma função usada para adicionar anotações diretamente a um gráfico. Anotações podem ser texto, formas ou outras marcas visuais que ajudam a destacar ou explicar partes específicas do gráfico.\nA função annotate permite que você adicione elementos como texto, segmentos, retângulos e outros tipos de geometrias ao seu gráfico. Isso é útil para chamar a atenção para pontos específicos, adicionar rótulos personalizados ou destacar áreas de interesse.\nAproveitando o exemplo anterior, podemos inserir textos no gráfico fornecendo as coordenadas dos textos no mapa. Por exemplo, podemos adicionar os valores dos tratamentos para cada curva:\n\nlibrary(ggplot2)\npepper |&gt; \n  pivot_longer(2:4,\n               names_to = \"epidemic\",\n               values_to = \"inc\") |&gt; \n  ggplot(aes(t, inc, color = epidemic))+\n  geom_point()+\n  geom_line()+\n  annotate(geom = \"text\", x = 12, y = 0.75, label = \"1\")+\n  annotate(geom = \"text\", x = 25, y = 0.75, label = \"2\")+\n  annotate(geom = \"text\", x = 45, y = 0.75, label = \"3\")+\n  theme(legend.position = \"none\") #retirar a legenda para não ficar redundante\n\n\n\n\n\n\n\n\n\n\n\n\nAs tabelas de contingência permitem cruzar variáveis e observar suas interações. O pacote janitor facilita a criação dessas tabelas.\nPor exemplo a função count conta quantas observações existem na variável e exibe em uma tabela, podemos filtrar colocando mais variáveis.\n\ncr &lt;- read_csv(\"https://raw.githubusercontent.com/emdelponte/paper-coffee-rust-Ethiopia/master/data/survey_clean.csv\")\n\nRows: 405 Columns: 13\n── Column specification ────────────────────────────────────────────────────────\nDelimiter: \",\"\nchr (7): region, zone, district, cultivar, shade, cropping_system, farm_mana...\ndbl (6): farm, lon, lat, altitude, inc, sev2\n\nℹ Use `spec()` to retrieve the full column specification for this data.\nℹ Specify the column types or set `show_col_types = FALSE` to quiet this message.\n\ncr |&gt; \n  count(region, zone)\n\n# A tibble: 9 × 3\n  region zone             n\n  &lt;chr&gt;  &lt;chr&gt;        &lt;int&gt;\n1 Oromia Bale            30\n2 Oromia Ilu AbaBora     45\n3 Oromia Jimma           45\n4 Oromia West Wellega    45\n5 SNNPR  Bench Maji      45\n6 SNNPR  Gedio           45\n7 SNNPR  Keffa           45\n8 SNNPR  Sheka           45\n9 SNNPR  Sidama          60\n\n\nPodemos cruzar as variáveis usando a função de contingência tabyl para cruzarmos duas variáveis, como por exemplo:\n\nlibrary(janitor)\n\n\nAnexando pacote: 'janitor'\n\n\nOs seguintes objetos são mascarados por 'package:stats':\n\n    chisq.test, fisher.test\n\ncr |&gt; \n  tabyl(region, zone)\n\n region Bale Bench Maji Gedio Ilu AbaBora Jimma Keffa Sheka Sidama West Wellega\n Oromia   30          0     0          45    45     0     0      0           45\n  SNNPR    0         45    45           0     0    45    45     60            0\n\n\n\ncr |&gt; \n  tabyl(zone, region)\n\n         zone Oromia SNNPR\n         Bale     30     0\n   Bench Maji      0    45\n        Gedio      0    45\n  Ilu AbaBora     45     0\n        Jimma     45     0\n        Keffa      0    45\n        Sheka      0    45\n       Sidama      0    60\n West Wellega     45     0\n\n\n\ncr |&gt; \n  tabyl(cultivar, region)\n\n cultivar Oromia SNNPR\n Improved     23    60\n    Local     50    66\n  Mixture     92   114\n\n\nEsse artifício é interessante para obervações, como por exemplo, podemos observar abaixo que na cultivar melhorada só se trabalha com manejo intensivo enquanto que a cultivar local não se tem manejo, ou ele é minimo.\n\ncr |&gt; \n  tabyl(cultivar, farm_management)\n\n cultivar Intensive Minimal Moderate Unmanaged\n Improved        83       0        0         0\n    Local         0      10        4       102\n  Mixture        82      59       65         0\n\n\n\n\n\n\n\nPodemos empilhar colunas e visualizar a distribuição de categorias, para isso podemos utilizar o geom_col, como no exemplo abaixo:\n\ncr |&gt; \n  count(farm_management, cultivar) |&gt; \n  ggplot(aes(cultivar, n, fill = farm_management))+\n  geom_col()\n\n\n\n\n\n\n\n\n\n\n\nPara visualizar colunas separadas, podemos utilizar position = \"dodge2\", assim as colunas podem ser separadas por cultivares como nos exemplos abaixo.\n\ncr |&gt; \n  count(farm_management, cultivar) |&gt; \n  ggplot(aes(cultivar, n, fill = farm_management))+\n  geom_col(position = \"dodge2\")\n\n\n\n\n\n\n\n\n\nlibrary(ggthemes)\ncr |&gt; \n  count(farm_management, cultivar) |&gt; \n  ggplot(aes(cultivar, n, fill = farm_management))+\n  geom_col(position = \"dodge2\")+\n  scale_fill_calc()+\n  theme_bw()+\n  theme(strip.text.x = element_blank(),\n        legend.position = \"top\")+ #Tira o nome em cima\n  #geom_text(position = position_dodge(width = 0.9))+\n  facet_wrap(~cultivar, scales = \"free_x\")"
  },
  {
    "objectID": "aula_04.html#importando-datasets",
    "href": "aula_04.html#importando-datasets",
    "title": "Visualização de dados, outras abordagens",
    "section": "",
    "text": "Uma das formas é a concatenação de dados de forma manual os atribuindo a um objeto. Para isso podemos utilizar a função nativa c() que concatena os dados, separados por vírgula.\n\ncomp &lt;- c(\"9\", \"12.5\", \"10\", \"8\", \"13.2\", \"11\", \"10.8\", \"9.5\", \"10.8\", \"10.4\", \"13.72\", \"15.91\", \"15.7\", \"14.2\", \"15.9\", \"16.54\", \"18\", \"14.4\", \"16.41\", \"16\")\ncomp\n\n [1] \"9\"     \"12.5\"  \"10\"    \"8\"     \"13.2\"  \"11\"    \"10.8\"  \"9.5\"   \"10.8\" \n[10] \"10.4\"  \"13.72\" \"15.91\" \"15.7\"  \"14.2\"  \"15.9\"  \"16.54\" \"18\"    \"14.4\" \n[19] \"16.41\" \"16\"   \n\ncomp &lt;- c(9, 12.5, 10, 8, 13.2, 11, 10.8, 9.5, 10.8, 10.4, 13.72, 15.91, 15.7, 14.2, 15.9, 16.54, 18, 14.4, 16.41, 16)\ncomp\n\n [1]  9.00 12.50 10.00  8.00 13.20 11.00 10.80  9.50 10.80 10.40 13.72 15.91\n[13] 15.70 14.20 15.90 16.54 18.00 14.40 16.41 16.00\n\n\nTambém podemos utilizar o pacote datapasta, que permite copiar dados de qualquer lugar e colar diretamente no R como uma tibble.\n\nlibrary(datapasta)\nvisitas &lt;- tibble::tribble(\n             ~`codigo`,          ~país, ~`n2`,\n             1L,     \"Brazil\",      4303L,\n               2L,     \"Mozambique\",      43L,\n               3L,       \"Portugal\",      33L,\n               4L,  \"United States\",      23L,\n               5L,         \"Angola\",      19L,\n               6L,          \"Spain\",      16L,\n               7L,      \"(not set)\",      12L,\n               8L,       \"Colombia\",       8L,\n               9L,        \"Germany\",       5L,\n              10L,        \"Hungary\",       5L,\n              11L, \"United Kingdom\",       5L,\n              12L,    \"Netherlands\",       4L,\n              13L,        \"Ecuador\",       3L,\n              14L,         \"France\",       3L,\n              15L,          \"Chile\",       2L,\n              16L,       \"Paraguay\",       2L,\n              17L,           \"Peru\",       2L,\n              18L,      \"Argentina\",       1L,\n              19L,        \"Austria\",       1L,\n              20L,        \"Bolivia\",       1L,\n              21L,     \"Cape Verde\",       1L,\n              22L,          \"China\",       1L,\n              23L,          \"Egypt\",       1L,\n              24L,        \"Finland\",       1L,\n              25L,          \"India\",       1L,\n              26L,          \"Italy\",       1L,\n              27L,       \"Malaysia\",       1L,\n              28L,       \"Pakistan\",       1L,\n              29L,         \"Poland\",       1L,\n              30L,      \"Singapore\",       1L,\n              31L,    \"Timor-Leste\",       1L,\n              32L,        \"Uruguay\",       1L\n             )\nhead(visitas)\n\n# A tibble: 6 × 3\n  codigo país             n2\n   &lt;int&gt; &lt;chr&gt;         &lt;int&gt;\n1      1 Brazil         4303\n2      2 Mozambique       43\n3      3 Portugal         33\n4      4 United States    23\n5      5 Angola           19\n6      6 Spain            16"
  },
  {
    "objectID": "aula_04.html#instalando-pacotes-de-outros-repositórios",
    "href": "aula_04.html#instalando-pacotes-de-outros-repositórios",
    "title": "Visualização de dados, outras abordagens",
    "section": "",
    "text": "O pacote pak permite que os dados sejam baixados de outros repositórios. Para isso, inicialmente precisamos instalar o pacote.\n\n#install.packages(\"pak\")\n\nAgora, poderemos instalar pacotes de outros repositórios, como o Icens, que será utilizado em outros tópicos. Muitos destes pacotes contem datasets que podem ser utilizados para testes de funções.\n\n#pak::pkg_install(\"Icens\")\n\nTambém podemos baixar os pacortes diretamente do github, como o pacote do Prof. Emerson, r4pde através do caminho “emdelponte/r4pde”.\n\n#pak::pkg_install(\"emdelponte/r4pde\")"
  },
  {
    "objectID": "aula_04.html#transformando-formatos-com-tidyverse",
    "href": "aula_04.html#transformando-formatos-com-tidyverse",
    "title": "Visualização de dados, outras abordagens",
    "section": "",
    "text": "Você pode transformar dados de formato largo para formato longo (e vice-versa) usando tidyverse. Para isso vamos praticar utilizando a função tribble, para colarmos os dados do caopítulo 10.4 do livro r4pde.\n\nlibrary(tidyverse)\n\n── Attaching core tidyverse packages ──────────────────────── tidyverse 2.0.0 ──\n✔ dplyr     1.1.4     ✔ readr     2.1.5\n✔ forcats   1.0.0     ✔ stringr   1.5.1\n✔ ggplot2   3.5.1     ✔ tibble    3.2.1\n✔ lubridate 1.9.3     ✔ tidyr     1.3.1\n✔ purrr     1.0.2     \n── Conflicts ────────────────────────────────────────── tidyverse_conflicts() ──\n✖ dplyr::filter() masks stats::filter()\n✖ dplyr::lag()    masks stats::lag()\nℹ Use the conflicted package (&lt;http://conflicted.r-lib.org/&gt;) to force all conflicts to become errors\n\npepper &lt;- \n  tribble(\n   ~t,  ~`1`,  ~`2`,  ~`3`,\n   0,  0.08, 0.001, 0.001,\n   7,  0.13,  0.01, 0.001,\n  14,  0.78,  0.09,  0.01,\n  21,  0.92,  0.25,  0.05,\n  28,  0.99,   0.8,  0.18,\n  35, 0.995,  0.98,  0.34,\n  42, 0.999,  0.99,  0.48,\n  49, 0.999, 0.999,  0.74\n  ) \n\n\n\nNo ggplot2, annotate é uma função usada para adicionar anotações diretamente a um gráfico. Anotações podem ser texto, formas ou outras marcas visuais que ajudam a destacar ou explicar partes específicas do gráfico.\nA função annotate permite que você adicione elementos como texto, segmentos, retângulos e outros tipos de geometrias ao seu gráfico. Isso é útil para chamar a atenção para pontos específicos, adicionar rótulos personalizados ou destacar áreas de interesse.\nAproveitando o exemplo anterior, podemos inserir textos no gráfico fornecendo as coordenadas dos textos no mapa. Por exemplo, podemos adicionar os valores dos tratamentos para cada curva:\n\nlibrary(ggplot2)\npepper |&gt; \n  pivot_longer(2:4,\n               names_to = \"epidemic\",\n               values_to = \"inc\") |&gt; \n  ggplot(aes(t, inc, color = epidemic))+\n  geom_point()+\n  geom_line()+\n  annotate(geom = \"text\", x = 12, y = 0.75, label = \"1\")+\n  annotate(geom = \"text\", x = 25, y = 0.75, label = \"2\")+\n  annotate(geom = \"text\", x = 45, y = 0.75, label = \"3\")+\n  theme(legend.position = \"none\") #retirar a legenda para não ficar redundante"
  },
  {
    "objectID": "aula_04.html#tabelas-de-contingência-com-janitor",
    "href": "aula_04.html#tabelas-de-contingência-com-janitor",
    "title": "Visualização de dados, outras abordagens",
    "section": "",
    "text": "As tabelas de contingência permitem cruzar variáveis e observar suas interações. O pacote janitor facilita a criação dessas tabelas.\nPor exemplo a função count conta quantas observações existem na variável e exibe em uma tabela, podemos filtrar colocando mais variáveis.\n\ncr &lt;- read_csv(\"https://raw.githubusercontent.com/emdelponte/paper-coffee-rust-Ethiopia/master/data/survey_clean.csv\")\n\nRows: 405 Columns: 13\n── Column specification ────────────────────────────────────────────────────────\nDelimiter: \",\"\nchr (7): region, zone, district, cultivar, shade, cropping_system, farm_mana...\ndbl (6): farm, lon, lat, altitude, inc, sev2\n\nℹ Use `spec()` to retrieve the full column specification for this data.\nℹ Specify the column types or set `show_col_types = FALSE` to quiet this message.\n\ncr |&gt; \n  count(region, zone)\n\n# A tibble: 9 × 3\n  region zone             n\n  &lt;chr&gt;  &lt;chr&gt;        &lt;int&gt;\n1 Oromia Bale            30\n2 Oromia Ilu AbaBora     45\n3 Oromia Jimma           45\n4 Oromia West Wellega    45\n5 SNNPR  Bench Maji      45\n6 SNNPR  Gedio           45\n7 SNNPR  Keffa           45\n8 SNNPR  Sheka           45\n9 SNNPR  Sidama          60\n\n\nPodemos cruzar as variáveis usando a função de contingência tabyl para cruzarmos duas variáveis, como por exemplo:\n\nlibrary(janitor)\n\n\nAnexando pacote: 'janitor'\n\n\nOs seguintes objetos são mascarados por 'package:stats':\n\n    chisq.test, fisher.test\n\ncr |&gt; \n  tabyl(region, zone)\n\n region Bale Bench Maji Gedio Ilu AbaBora Jimma Keffa Sheka Sidama West Wellega\n Oromia   30          0     0          45    45     0     0      0           45\n  SNNPR    0         45    45           0     0    45    45     60            0\n\n\n\ncr |&gt; \n  tabyl(zone, region)\n\n         zone Oromia SNNPR\n         Bale     30     0\n   Bench Maji      0    45\n        Gedio      0    45\n  Ilu AbaBora     45     0\n        Jimma     45     0\n        Keffa      0    45\n        Sheka      0    45\n       Sidama      0    60\n West Wellega     45     0\n\n\n\ncr |&gt; \n  tabyl(cultivar, region)\n\n cultivar Oromia SNNPR\n Improved     23    60\n    Local     50    66\n  Mixture     92   114\n\n\nEsse artifício é interessante para obervações, como por exemplo, podemos observar abaixo que na cultivar melhorada só se trabalha com manejo intensivo enquanto que a cultivar local não se tem manejo, ou ele é minimo.\n\ncr |&gt; \n  tabyl(cultivar, farm_management)\n\n cultivar Intensive Minimal Moderate Unmanaged\n Improved        83       0        0         0\n    Local         0      10        4       102\n  Mixture        82      59       65         0"
  },
  {
    "objectID": "aula_04.html#visualizando-dados-com-gráficos",
    "href": "aula_04.html#visualizando-dados-com-gráficos",
    "title": "Visualização de dados, outras abordagens",
    "section": "",
    "text": "Podemos empilhar colunas e visualizar a distribuição de categorias, para isso podemos utilizar o geom_col, como no exemplo abaixo:\n\ncr |&gt; \n  count(farm_management, cultivar) |&gt; \n  ggplot(aes(cultivar, n, fill = farm_management))+\n  geom_col()\n\n\n\n\n\n\n\n\n\n\n\nPara visualizar colunas separadas, podemos utilizar position = \"dodge2\", assim as colunas podem ser separadas por cultivares como nos exemplos abaixo.\n\ncr |&gt; \n  count(farm_management, cultivar) |&gt; \n  ggplot(aes(cultivar, n, fill = farm_management))+\n  geom_col(position = \"dodge2\")\n\n\n\n\n\n\n\n\n\nlibrary(ggthemes)\ncr |&gt; \n  count(farm_management, cultivar) |&gt; \n  ggplot(aes(cultivar, n, fill = farm_management))+\n  geom_col(position = \"dodge2\")+\n  scale_fill_calc()+\n  theme_bw()+\n  theme(strip.text.x = element_blank(),\n        legend.position = \"top\")+ #Tira o nome em cima\n  #geom_text(position = position_dodge(width = 0.9))+\n  facet_wrap(~cultivar, scales = \"free_x\")"
  },
  {
    "objectID": "aula_07.html",
    "href": "aula_07.html",
    "title": "Análise Estatística: Estatística inferencial - Parte 2",
    "section": "",
    "text": "A One-Way ANOVA (Análise de Variância de um Fator) é um teste estatístico utilizado para determinar se existem diferenças significativas entre as médias de três ou mais grupos independentes. A “one-way” refere-se ao fato de que há apenas uma variável independente (fator) sendo testada. Este teste é usado quando se quer comparar as médias de diferentes grupos para verificar se pelo menos um grupo difere significativamente dos outros.\nDesta vez iniciaremos garantindo que todos os gráficos tenham uma aparência unica ao longo do documento, para isso, configuraremos o tema para theme_bw() usando a função theme_set().\n\nlibrary(tidyverse)\n\n── Attaching core tidyverse packages ──────────────────────── tidyverse 2.0.0 ──\n✔ dplyr     1.1.4     ✔ readr     2.1.5\n✔ forcats   1.0.0     ✔ stringr   1.5.1\n✔ ggplot2   3.5.1     ✔ tibble    3.2.1\n✔ lubridate 1.9.3     ✔ tidyr     1.3.1\n✔ purrr     1.0.2     \n── Conflicts ────────────────────────────────────────── tidyverse_conflicts() ──\n✖ dplyr::filter() masks stats::filter()\n✖ dplyr::lag()    masks stats::lag()\nℹ Use the conflicted package (&lt;http://conflicted.r-lib.org/&gt;) to force all conflicts to become errors\n\ntheme_set(theme_bw())\n\nPara este tópico utilizamos o conjunto de dados InsectSprays para nossa análise. Este conjunto de dados contém informações sobre a contagem de insetos após a aplicação de diferentes sprays.\n\ninseticida &lt;- InsectSprays\nhead(inseticida)\n\n  count spray\n1    10     A\n2     7     A\n3    20     A\n4    14     A\n5    14     A\n6    12     A\n\n\nAntes de prosseguir com a análise, é útil entender a distribuição das observações entre os diferentes tipos de spray. Para isso, utilizamos a função count() do pacote tidyverse, que conta o número de ocorrências de cada categoria na variável spray.\n\nlibrary(tidyverse)\ninseticida |&gt; \n  count(spray)\n\n  spray  n\n1     A 12\n2     B 12\n3     C 12\n4     D 12\n5     E 12\n6     F 12\n\n\nA função count() é usada para contar as ocorrências de valores únicos em uma coluna. No caso acima, estamos contando quantas vezes cada tipo de spray aparece no conjunto de dados InsectSprays.\nPara ter uma visão geral da contagem por tipo de spray, usamos o boxplot (gráfico de caixa) e jitter para a dispersão.\n\nlibrary(ggplot2)\ninseticida |&gt;\n  ggplot(aes(x = spray, y = count))+\n  geom_boxplot()+\n  geom_jitter()+\n  theme_bw()\n\n\n\n\n\n\n\n\nO boxplot dá indícios de que as médias C, D e E diferem das demais. Entretanto, o plot da variatiância dos dados é bem grande e com presença de outliers.\n\nm1 &lt;- lm(count ~ spray,\n         data = inseticida)\nsummary(m1)\n\n\nCall:\nlm(formula = count ~ spray, data = inseticida)\n\nResiduals:\n   Min     1Q Median     3Q    Max \n-8.333 -1.958 -0.500  1.667  9.333 \n\nCoefficients:\n            Estimate Std. Error t value Pr(&gt;|t|)    \n(Intercept)  14.5000     1.1322  12.807  &lt; 2e-16 ***\nsprayB        0.8333     1.6011   0.520    0.604    \nsprayC      -12.4167     1.6011  -7.755 7.27e-11 ***\nsprayD       -9.5833     1.6011  -5.985 9.82e-08 ***\nsprayE      -11.0000     1.6011  -6.870 2.75e-09 ***\nsprayF        2.1667     1.6011   1.353    0.181    \n---\nSignif. codes:  0 '***' 0.001 '**' 0.01 '*' 0.05 '.' 0.1 ' ' 1\n\nResidual standard error: 3.922 on 66 degrees of freedom\nMultiple R-squared:  0.7244,    Adjusted R-squared:  0.7036 \nF-statistic:  34.7 on 5 and 66 DF,  p-value: &lt; 2.2e-16\n\nanova(m1)\n\nAnalysis of Variance Table\n\nResponse: count\n          Df Sum Sq Mean Sq F value    Pr(&gt;F)    \nspray      5 2668.8  533.77  34.702 &lt; 2.2e-16 ***\nResiduals 66 1015.2   15.38                      \n---\nSignif. codes:  0 '***' 0.001 '**' 0.01 '*' 0.05 '.' 0.1 ' ' 1\n\n\nSegundo a one-way ANOVA, o p-valor associado ao teste F foi &lt; 0.05, indicando que há uma diferença estatisticamente significativa entre pelo menos um par de grupos de spray.\n\n\nPara garantir que o modelo ANOVA seja válido, verificamos os resíduos do modelo para normalidade e homocedasticidade. Inicialmente a normalidade dos resíduos e a homocedasticidade foram verificadas usando um histograma e um gráfico QQ, respectivamente.\n\nm1$residuals\n\n          1           2           3           4           5           6 \n-4.50000000 -7.50000000  5.50000000 -0.50000000 -0.50000000 -2.50000000 \n          7           8           9          10          11          12 \n-4.50000000  8.50000000  2.50000000  5.50000000 -0.50000000 -1.50000000 \n         13          14          15          16          17          18 \n-4.33333333  1.66666667  5.66666667 -4.33333333  0.66666667 -1.33333333 \n         19          20          21          22          23          24 \n 1.66666667  1.66666667  3.66666667  5.66666667 -8.33333333 -2.33333333 \n         25          26          27          28          29          30 \n-2.08333333 -1.08333333  4.91666667 -0.08333333  0.91666667 -1.08333333 \n         31          32          33          34          35          36 \n-0.08333333 -1.08333333  0.91666667 -2.08333333 -1.08333333  1.91666667 \n         37          38          39          40          41          42 \n-1.91666667  0.08333333  7.08333333  1.08333333 -0.91666667 -1.91666667 \n         43          44          45          46          47          48 \n 0.08333333  0.08333333  0.08333333  0.08333333 -2.91666667 -0.91666667 \n         49          50          51          52          53          54 \n-0.50000000  1.50000000 -0.50000000  1.50000000 -0.50000000  2.50000000 \n         55          56          57          58          59          60 \n-2.50000000 -2.50000000 -0.50000000 -1.50000000  2.50000000  0.50000000 \n         61          62          63          64          65          66 \n-5.66666667 -7.66666667 -1.66666667  5.33333333 -1.66666667 -0.66666667 \n         67          68          69          70          71          72 \n-3.66666667 -6.66666667  9.33333333  9.33333333  7.33333333 -3.66666667 \n\nhist(m1$residuals)\n\n\n\n\n\n\n\nqqnorm(m1$residuals)\nqqline(m1$residuals)\n\n\n\n\n\n\n\n\nSegundo obvervado no histograma, os residuos aparentemente seguem uma distribuição normal. Olhando o gráfico QQ os pontos extremos se distanciam em muito a linha central, o que indica não haver homocedesticidade.\nEntretanto, para sabermos definitivamente, de uma forma não subjetiva, se os dados atendem aos preceitos estátisticos, foram feitos o teste de Shapiro-Wilk, para verificar a normalidade e Bartlett para testarmos a homogeneidade de variância.\n\nshapiro.test(m1$residuals)\n\n\n    Shapiro-Wilk normality test\n\ndata:  m1$residuals\nW = 0.96006, p-value = 0.02226\n\nbartlett.test(count ~ spray,\n              data = inseticida)\n\n\n    Bartlett test of homogeneity of variances\n\ndata:  count by spray\nBartlett's K-squared = 25.96, df = 5, p-value = 9.085e-05\n\n\nEm ambos os testes o p-valor foi &lt; 0.05, assim os dados não apresentam normalidade e homogeneidade de variância pelo teste de Shapiro-Wilk e Bartllet, respectivamente. Destre deste preceitos estatísticos, a falta de normalidade é mais “leve” do que a falta de homocedasticidade.\nOutras funções como check_normality() e check_heteroscedasticity() do pacote performance são outras opções poderosas de ferramentas para verificar os pressupostos de normalidade e homocedasticidade.\n\nlibrary(performance)\n\nWarning: pacote 'performance' foi compilado no R versão 4.4.1\n\ncheck_normality(m1)\n\nWarning: Non-normality of residuals detected (p = 0.022).\n\ncheck_heteroscedasticity(m1)\n\nWarning: Heteroscedasticity (non-constant error variance) detected (p &lt; .001).\n\n\nAs funções do pacote performance oferecem uma saída escrita e em cores que identificam se atendeu (verde) ou não (vermelho) ao teste em que os dados foram submetidos. Essas verificações são essenciais para garantir que as inferências estatísticas sejam válidas.\nNo caso do exemplo, como dito anteriormente, os dados não apresentaram normalidade e homogeneidade de variância.\nOutra opção é a utilização do pacote DHARMa (Residual Diagnostics for Hierarchical (Multi-Level / Mixed) Regression Models), ecificamente a função simulateResiduals(). Esta função é usada para gerar resíduos simulados a partir do modelo ajustado. Isso é feito para criar uma distribuição de referência que é usada para diagnosticar o modelo.\n\nlibrary(DHARMa)\n\nWarning: pacote 'DHARMa' foi compilado no R versão 4.4.1\n\n\nThis is DHARMa 0.4.6. For overview type '?DHARMa'. For recent changes, type news(package = 'DHARMa')\n\nplot(simulateResiduals(m1))\n\n\n\n\n\n\n\n\nO gráfico da esquerda, QQ Plot Residuals, tem por objetivo verificar a normalidade dos resíduos. Este gráfico compara os quantis dos resíduos observados com os quantis de uma distribuição normal teórica. Os pontos no gráfico representam os resíduos simulados, e a linha diagonal representa a distribuição normal teórica. Na imagem, os pontos estão próximos da linha diagonal, indicando que os resíduos são aproximadamente normais.\nEsta mesma função realiza o teste de Kolmogorov-Smirnov (KS), este teste é usado para testar a hipótese de que os resíduos seguem uma distribuição normal. Um p-valor de 0.380 indica que não rejeitamos a hipótese nula de normalidade, sugerindo que os resíduos são normalmente distribuídos.\nJá o gráfico da direita, um Boxplot de Resíduos vs. Valores Ajustados, tem por objetico verificar a homocedasticidade (igualdade das variâncias) dos resíduos. Este boxplot mostra a distribuição dos resíduos simulados para diferentes valores preditos pelo modelo (valores ajustados). Neste gráfico as caixas parecem ter tamanhos muito diferentes, indicando possível heterocedasticidade.\nO teste de Levene, que é usado para testar a hipótese de homogeneidade das variâncias, também é aplicado ao se utilizar a funçãosimulateResiduals() e significância do teste de Levene sugere que há heterocedasticidade, ou seja, a variância dos resíduos não é constante ao longo dos valores ajustados.\n\n\n\n\nQuando os dados não atendem aos pressupostos de normalidade e homocedasticidade, podemos aplicar uma transformação, como a raiz quadrada, Arco Seno, Logarítmica, Box Cox ou outros, para tentar normalizar os dados e estabilizar a variância.\n\n\nQuando temos dado de contagem geralmente se utiliza a raiz quadrada. Para isso transformamos a variável de contagem aplicando a raiz quadrada e visualizamos novamente os dados. Como no exempo:\n\ninseticida &lt;- inseticida |&gt;\n  mutate(count2 = sqrt(count))\ninseticida |&gt;\n  ggplot(aes(x = spray, y = count2))+\n  geom_boxplot()+\n  geom_jitter()+\n  theme_bw()\n\n\n\n\n\n\n\n\n\nm2 &lt;- lm(count2 ~ spray,\n         data = inseticida)\nsummary(m2)\n\n\nCall:\nlm(formula = count2 ~ spray, data = inseticida)\n\nResiduals:\n     Min       1Q   Median       3Q      Max \n-1.24486 -0.39970 -0.01902  0.42661  1.40089 \n\nCoefficients:\n            Estimate Std. Error t value Pr(&gt;|t|)    \n(Intercept)   3.7607     0.1814  20.733  &lt; 2e-16 ***\nsprayB        0.1160     0.2565   0.452    0.653    \nsprayC       -2.5158     0.2565  -9.807 1.64e-14 ***\nsprayD       -1.5963     0.2565  -6.223 3.80e-08 ***\nsprayE       -1.9512     0.2565  -7.606 1.34e-10 ***\nsprayF        0.2579     0.2565   1.006    0.318    \n---\nSignif. codes:  0 '***' 0.001 '**' 0.01 '*' 0.05 '.' 0.1 ' ' 1\n\nResidual standard error: 0.6283 on 66 degrees of freedom\nMultiple R-squared:  0.7724,    Adjusted R-squared:  0.7552 \nF-statistic:  44.8 on 5 and 66 DF,  p-value: &lt; 2.2e-16\n\nanova(m2)\n\nAnalysis of Variance Table\n\nResponse: count2\n          Df Sum Sq Mean Sq F value    Pr(&gt;F)    \nspray      5 88.438 17.6876  44.799 &lt; 2.2e-16 ***\nResiduals 66 26.058  0.3948                      \n---\nSignif. codes:  0 '***' 0.001 '**' 0.01 '*' 0.05 '.' 0.1 ' ' 1\n\nm2$residuals\n\n          1           2           3           4           5           6 \n-0.59840073 -1.11492708  0.71145756 -0.01902101 -0.01902101 -0.29657678 \n          7           8           9          10          11          12 \n-0.59840073  1.03515313  0.36242723  0.71145756 -0.01902101 -0.15512712 \n         13          14          15          16          17          18 \n-0.56000661  0.24647423  0.70594430 -0.56000661  0.12336860 -0.13497401 \n         19          20          21          22          23          24 \n 0.24647423  0.24647423  0.48226755  0.70594430 -1.23088009 -0.27108012 \n         25          26          27          28          29          30 \n-1.24485667 -0.24485667  1.40089464  0.16935689  0.48719414 -0.24485667 \n         31          32          33          34          35          36 \n 0.16935689 -0.24485667  0.48719414 -1.24485667 -0.24485667  0.75514333 \n         37          38          39          40          41          42 \n-0.43230306  0.07171411  1.29974775  0.28513587 -0.16435387 -0.43230306 \n         43          44          45          46          47          48 \n 0.07171411  0.07171411  0.07171411  0.07171411 -0.75014031 -0.16435387 \n         49          50          51          52          53          54 \n-0.07741021  0.42660696 -0.07741021  0.42660696 -0.07741021  0.64002872 \n         55          56          57          58          59          60 \n-0.80946102 -0.80946102 -0.07741021 -0.39524746  0.64002872  0.19053898 \n         61          62          63          64          65          66 \n-0.70199237 -1.01861716 -0.14563382  0.67179860 -0.14563382 -0.01861716 \n         67          68          69          70          71          72 \n-0.41306589 -0.85633950  1.08040235  1.08040235  0.88036232 -0.41306589 \n\nhist(m2$residuals)\n\n\n\n\n\n\n\nqqnorm(m2$residuals)\nqqline(m2$residuals)\n\n\n\n\n\n\n\n\n\nshapiro.test(m2$residuals)\n\n\n    Shapiro-Wilk normality test\n\ndata:  m2$residuals\nW = 0.98721, p-value = 0.6814\n\nbartlett.test(count2 ~ spray,\n              data = inseticida)\n\n\n    Bartlett test of homogeneity of variances\n\ndata:  count2 by spray\nBartlett's K-squared = 3.7525, df = 5, p-value = 0.5856\n\n\n\nlibrary(DHARMa)\nplot(simulateResiduals(m2))\n\n\n\n\n\n\n\nlibrary(performance)\ncheck_normality(m2)\n\nOK: residuals appear as normally distributed (p = 0.681).\n\ncheck_heteroscedasticity(m2)\n\nOK: Error variance appears to be homoscedastic (p = 0.854).\n\n\nAgora os dados atendem a normalidade e homocedasticidade.\nemmeans mostra o intervalo de confiança\n\nlibrary(emmeans)\n\nWarning: pacote 'emmeans' foi compilado no R versão 4.4.1\n\n\nWelcome to emmeans.\nCaution: You lose important information if you filter this package's results.\nSee '? untidy'\n\nm1_medias &lt;- emmeans(m1, ~ spray)\nplot(m1_medias)\n\n\n\n\n\n\n\n\n\nlibrary(multcomp)\n\nCarregando pacotes exigidos: mvtnorm\n\n\nCarregando pacotes exigidos: survival\n\n\nWarning: pacote 'survival' foi compilado no R versão 4.4.1\n\n\nCarregando pacotes exigidos: TH.data\n\n\nCarregando pacotes exigidos: MASS\n\n\nWarning: pacote 'MASS' foi compilado no R versão 4.4.1\n\n\n\nAnexando pacote: 'MASS'\n\n\nO seguinte objeto é mascarado por 'package:dplyr':\n\n    select\n\n\n\nAnexando pacote: 'TH.data'\n\n\nO seguinte objeto é mascarado por 'package:MASS':\n\n    geyser\n\ncld(m1_medias)\n\n spray emmean   SE df lower.CL upper.CL .group\n C       2.08 1.13 66   -0.177     4.34  1    \n E       3.50 1.13 66    1.240     5.76  1    \n D       4.92 1.13 66    2.656     7.18  1    \n A      14.50 1.13 66   12.240    16.76   2   \n B      15.33 1.13 66   13.073    17.59   2   \n F      16.67 1.13 66   14.406    18.93   2   \n\nConfidence level used: 0.95 \nP value adjustment: tukey method for comparing a family of 6 estimates \nsignificance level used: alpha = 0.05 \nNOTE: If two or more means share the same grouping symbol,\n      then we cannot show them to be different.\n      But we also did not show them to be the same. \n\n\n\nlibrary(emmeans)\nm2_medias &lt;- emmeans(m2, ~ spray)\nplot(m2_medias)\n\n\n\n\n\n\n\n\n\nlibrary(multcomp)\ncld(m2_medias)\n\n spray emmean    SE df lower.CL upper.CL .group\n C       1.24 0.181 66    0.883     1.61  1    \n E       1.81 0.181 66    1.447     2.17  12   \n D       2.16 0.181 66    1.802     2.53   2   \n A       3.76 0.181 66    3.399     4.12    3  \n B       3.88 0.181 66    3.514     4.24    3  \n F       4.02 0.181 66    3.656     4.38    3  \n\nConfidence level used: 0.95 \nP value adjustment: tukey method for comparing a family of 6 estimates \nsignificance level used: alpha = 0.05 \nNOTE: If two or more means share the same grouping symbol,\n      then we cannot show them to be different.\n      But we also did not show them to be the same. \n\n\n\npwpm(m2_medias)\n\n       A      B      C      D      E      F\nA [3.76] 0.9975 &lt;.0001 &lt;.0001 &lt;.0001 0.9145\nB -0.116 [3.88] &lt;.0001 &lt;.0001 &lt;.0001 0.9936\nC  2.516  2.632 [1.24] 0.0081 0.2513 &lt;.0001\nD  1.596  1.712 -0.919 [2.16] 0.7366 &lt;.0001\nE  1.951  2.067 -0.565  0.355 [1.81] &lt;.0001\nF -0.258 -0.142 -2.774 -1.854 -2.209 [4.02]\n\nRow and column labels: spray\nUpper triangle: P values   adjust = \"tukey\"\nDiagonal: [Estimates] (emmean) \nLower triangle: Comparisons (estimate)   earlier vs. later\n\npwpp(m2_medias)\n\n\n\n\n\n\n\n\n\npairs(m2_medias)\n\n contrast estimate    SE df t.ratio p.value\n A - B      -0.116 0.257 66  -0.452  0.9975\n A - C       2.516 0.257 66   9.807  &lt;.0001\n A - D       1.596 0.257 66   6.223  &lt;.0001\n A - E       1.951 0.257 66   7.606  &lt;.0001\n A - F      -0.258 0.257 66  -1.006  0.9145\n B - C       2.632 0.257 66  10.259  &lt;.0001\n B - D       1.712 0.257 66   6.675  &lt;.0001\n B - E       2.067 0.257 66   8.058  &lt;.0001\n B - F      -0.142 0.257 66  -0.554  0.9936\n C - D      -0.919 0.257 66  -3.584  0.0081\n C - E      -0.565 0.257 66  -2.201  0.2513\n C - F      -2.774 0.257 66 -10.813  &lt;.0001\n D - E       0.355 0.257 66   1.383  0.7366\n D - F      -1.854 0.257 66  -7.229  &lt;.0001\n E - F      -2.209 0.257 66  -8.612  &lt;.0001\n\nP value adjustment: tukey method for comparing a family of 6 estimates \n\n\npodemos aplicar de Box-Cox\n\nlibrary(MASS)\nb &lt;- boxcox(lm(inseticida$count + 0.1 ~ 1))\n\n\n\n\n\n\n\nlambda &lt;- b$x[which.max(b$y)]\nlambda\n\n[1] 0.4242424\n\n\n\ninseticida$count3 &lt;- (inseticida$count^lambda-1)/lambda\ninseticida$count3\n\n [1]  3.903635  3.024469  6.043993  4.864268  4.864268  4.407118  3.903635\n [8]  6.557185  5.484274  6.043993  4.864268  4.640760  4.161975  5.484274\n[15]  6.219699  4.161975  5.285168  4.864268  5.484274  5.484274  5.863153\n[22]  6.219699  3.024469  4.640760 -2.357143  0.000000  3.024469  0.805831\n[29]  1.399509  0.000000  0.805831  0.000000  1.399509 -2.357143  0.000000\n[36]  1.887150  1.399509  2.308577  4.407118  2.683787  1.887150  1.399509\n[43]  2.308577  2.308577  2.308577  2.308577  0.805831  1.887150  1.399509\n[50]  2.308577  1.399509  2.308577  1.399509  2.683787  0.000000  0.000000\n[57]  1.399509  0.805831  2.683787  1.887150  4.161975  3.629951  5.078760\n[64]  6.390651  5.078760  5.285168  4.640760  3.903635  7.033117  7.033117\n[71]  6.719601  4.640760\n\n\nSe lambda for igual a 0.5 é igual a raiz quadrada\n\nm5 &lt;- lm(count3 ~ spray,\n         data = inseticida)\nlibrary(DHARMa)\nplot(simulateResiduals(m5))\n\n\n\n\n\n\n\nlibrary(performance)\ncheck_normality(m5)\n\nOK: residuals appear as normally distributed (p = 0.772).\n\ncheck_heteroscedasticity(m5)\n\nOK: Error variance appears to be homoscedastic (p = 0.246).\n\n\nAlternativa, usando testes não paramétricos\n\nlibrary(agricolae)\n\nWarning: pacote 'agricolae' foi compilado no R versão 4.4.1\n\nprint('-=-=-=-=-=-=- DO PRÓPRIO R -=-=-=-=-=-=-')\n\n[1] \"-=-=-=-=-=-=- DO PRÓPRIO R -=-=-=-=-=-=-\"\n\nkruskal.test(count ~ spray,\n             data = inseticida)\n\n\n    Kruskal-Wallis rank sum test\n\ndata:  count by spray\nKruskal-Wallis chi-squared = 54.691, df = 5, p-value = 1.511e-10\n\nprint('-=-=-=-=-=-=- DO PACOTE AGRICOLAE -=-=-=-=-=-=-')\n\n[1] \"-=-=-=-=-=-=- DO PACOTE AGRICOLAE -=-=-=-=-=-=-\"\n\nm3 &lt;- kruskal(inseticida$count,\n        inseticida$spray,\n        group = TRUE)\nm3\n\n$statistics\n     Chisq Df      p.chisq  t.value      MSD\n  54.69134  5 1.510845e-10 1.996564 8.462804\n\n$parameters\n            test p.ajusted           name.t ntr alpha\n  Kruskal-Wallis      none inseticida$spray   6  0.05\n\n$means\n  inseticida.count     rank      std  r Min Max   Q25  Q50   Q75\nA        14.500000 52.16667 4.719399 12   7  23 11.50 14.0 17.75\nB        15.333333 54.83333 4.271115 12   7  21 12.50 16.5 17.50\nC         2.083333 11.45833 1.975225 12   0   7  1.00  1.5  3.00\nD         4.916667 25.58333 2.503028 12   2  12  3.75  5.0  5.00\nE         3.500000 19.33333 1.732051 12   1   6  2.75  3.0  5.00\nF        16.666667 55.62500 6.213378 12   9  26 12.50 15.0 22.50\n\n$comparison\nNULL\n\n$groups\n  inseticida$count groups\nF         55.62500      a\nB         54.83333      a\nA         52.16667      a\nD         25.58333      b\nE         19.33333     bc\nC         11.45833      c\n\nattr(,\"class\")\n[1] \"group\"\n\n\ngeneralizado é mais bonito, mais moderno, mais aceito.\nAlternativa usando GLMs\n\nm4 &lt;- glm(count ~spray,\n          family = gaussian,\n          data = inseticida)\nsummary(m4)\n\n\nCall:\nglm(formula = count ~ spray, family = gaussian, data = inseticida)\n\nCoefficients:\n            Estimate Std. Error t value Pr(&gt;|t|)    \n(Intercept)  14.5000     1.1322  12.807  &lt; 2e-16 ***\nsprayB        0.8333     1.6011   0.520    0.604    \nsprayC      -12.4167     1.6011  -7.755 7.27e-11 ***\nsprayD       -9.5833     1.6011  -5.985 9.82e-08 ***\nsprayE      -11.0000     1.6011  -6.870 2.75e-09 ***\nsprayF        2.1667     1.6011   1.353    0.181    \n---\nSignif. codes:  0 '***' 0.001 '**' 0.01 '*' 0.05 '.' 0.1 ' ' 1\n\n(Dispersion parameter for gaussian family taken to be 15.38131)\n\n    Null deviance: 3684.0  on 71  degrees of freedom\nResidual deviance: 1015.2  on 66  degrees of freedom\nAIC: 408.85\n\nNumber of Fisher Scoring iterations: 2\n\nanova(m4)\n\nAnalysis of Deviance Table\n\nModel: gaussian, link: identity\n\nResponse: count\n\nTerms added sequentially (first to last)\n\n      Df Deviance Resid. Df Resid. Dev      F    Pr(&gt;F)    \nNULL                     71     3684.0                     \nspray  5   2668.8        66     1015.2 34.702 &lt; 2.2e-16 ***\n---\nSignif. codes:  0 '***' 0.001 '**' 0.01 '*' 0.05 '.' 0.1 ' ' 1\n\nlibrary(car)\n\nCarregando pacotes exigidos: carData\n\n\n\nAnexando pacote: 'car'\n\n\nO seguinte objeto é mascarado por 'package:dplyr':\n\n    recode\n\n\nO seguinte objeto é mascarado por 'package:purrr':\n\n    some\n\nAnova(m4)\n\nAnalysis of Deviance Table (Type II tests)\n\nResponse: count\n      LR Chisq Df Pr(&gt;Chisq)    \nspray   173.51  5  &lt; 2.2e-16 ***\n---\nSignif. codes:  0 '***' 0.001 '**' 0.01 '*' 0.05 '.' 0.1 ' ' 1\n\n\nTem que olhar a familia da distribuição olhando os pressupostos.\n\nlibrary(DHARMa)\nm5 &lt;- glm(count ~spray,\n          family = poisson,\n          data = inseticida)\nsummary(m5)\n\n\nCall:\nglm(formula = count ~ spray, family = poisson, data = inseticida)\n\nCoefficients:\n            Estimate Std. Error z value Pr(&gt;|z|)    \n(Intercept)  2.67415    0.07581  35.274  &lt; 2e-16 ***\nsprayB       0.05588    0.10574   0.528    0.597    \nsprayC      -1.94018    0.21389  -9.071  &lt; 2e-16 ***\nsprayD      -1.08152    0.15065  -7.179 7.03e-13 ***\nsprayE      -1.42139    0.17192  -8.268  &lt; 2e-16 ***\nsprayF       0.13926    0.10367   1.343    0.179    \n---\nSignif. codes:  0 '***' 0.001 '**' 0.01 '*' 0.05 '.' 0.1 ' ' 1\n\n(Dispersion parameter for poisson family taken to be 1)\n\n    Null deviance: 409.041  on 71  degrees of freedom\nResidual deviance:  98.329  on 66  degrees of freedom\nAIC: 376.59\n\nNumber of Fisher Scoring iterations: 5\n\nAnova(m5)\n\nAnalysis of Deviance Table (Type II tests)\n\nResponse: count\n      LR Chisq Df Pr(&gt;Chisq)    \nspray   310.71  5  &lt; 2.2e-16 ***\n---\nSignif. codes:  0 '***' 0.001 '**' 0.01 '*' 0.05 '.' 0.1 ' ' 1\n\nplot(simulateResiduals(m5))\n\n\n\n\n\n\n\n\n\nm5_medias &lt;- emmeans(m5, ~ spray,\n                     type = 'response')\nlibrary(multcomp)\nlibrary(multcompView)\n\nWarning: pacote 'multcompView' foi compilado no R versão 4.4.1\n\ncld(m5_medias)\n\n spray  rate    SE  df asymp.LCL asymp.UCL .group\n C      2.08 0.417 Inf      1.41      3.08  1    \n E      3.50 0.540 Inf      2.59      4.74  12   \n D      4.92 0.640 Inf      3.81      6.35   2   \n A     14.50 1.099 Inf     12.50     16.82    3  \n B     15.33 1.130 Inf     13.27     17.72    3  \n F     16.67 1.179 Inf     14.51     19.14    3  \n\nConfidence level used: 0.95 \nIntervals are back-transformed from the log scale \nP value adjustment: tukey method for comparing a family of 6 estimates \nTests are performed on the log scale \nsignificance level used: alpha = 0.05 \nNOTE: If two or more means share the same grouping symbol,\n      then we cannot show them to be different.\n      But we also did not show them to be the same. \n\n\nOutro conjunto de dados two-way anova - ANOVA fatorial\n\nlibrary(gsheet)\nli &lt;- gsheet2tbl(\"https://docs.google.com/spreadsheets/d/1bq2N19DcZdtax2fQW9OHSGMR0X2__Z9T/edit#gid=2023059672\")\n\nhead(li)\n\n# A tibble: 6 × 8\n  treat         dose   rep  n_sp dis_sp n_seeds inf_seeds severity\n  &lt;chr&gt;        &lt;dbl&gt; &lt;dbl&gt; &lt;dbl&gt;  &lt;dbl&gt;   &lt;dbl&gt;     &lt;dbl&gt;    &lt;dbl&gt;\n1 Ionic liquid   0.5     1   103     13      25        10   0.126 \n2 Ionic liquid   0.5     2   125     31      25        12   0.248 \n3 Ionic liquid   0.5     3   210     80      25        12   0.381 \n4 Ionic liquid   0.5     4    97     28      25        10   0.289 \n5 Ionic liquid   0.5     5   180     75      25        11   0.417 \n6 Ionic liquid   2       2   116      9      25         6   0.0776\n\n\n\nlibrary(ggplot2)\nli |&gt;\n  ggplot(aes(factor(dose),severity, color = factor(dose)))+\n  geom_jitter(width = 0.1)+\n  facet_wrap(~treat)+\n  theme_bw()\n\n\n\n\n\n\n\n\n\nli |&gt;\n  ggplot(aes(treat ,severity, color = factor(dose)))+\n  geom_jitter(width = 0.1)\n\n\n\n\n\n\n\n\nModelo fatoral - Para DIC\n\nmf &lt;- lm(severity ~ treat*factor(dose),\n         data = li)\nmf\n\n\nCall:\nlm(formula = severity ~ treat * factor(dose), data = li)\n\nCoefficients:\n                    (Intercept)                treatTebuconazole  \n                         0.2921                          -0.2711  \n                  factor(dose)2  treatTebuconazole:factor(dose)2  \n                        -0.2420                           0.2412  \n\nanova(mf)\n\nAnalysis of Variance Table\n\nResponse: severity\n                   Df   Sum Sq  Mean Sq F value    Pr(&gt;F)    \ntreat               1 0.113232 0.113232  30.358 4.754e-05 ***\nfactor(dose)        1 0.073683 0.073683  19.755 0.0004077 ***\ntreat:factor(dose)  1 0.072739 0.072739  19.502 0.0004326 ***\nResiduals          16 0.059678 0.003730                      \n---\nSignif. codes:  0 '***' 0.001 '**' 0.01 '*' 0.05 '.' 0.1 ' ' 1\n\n\n\nlibrary(DHARMa)\nplot(simulateResiduals(mf))\n\n\n\n\n\n\n\n\n\nlibrary(performance)\ncheck_normality(mf)\n\nWarning: Non-normality of residuals detected (p = 0.011).\n\ncheck_homogeneity(mf)\n\nWarning: Variances differ between groups (Bartlett Test, p = 0.001).\n\n\nO cld, do pacote multcomp, coloca as letras.\n\nmf_medias &lt;- emmeans(mf, ~ treat | dose)\nmf_medias\n\ndose = 0.5:\n treat        emmean     SE df lower.CL upper.CL\n Ionic liquid 0.2921 0.0273 16  0.23420   0.3500\n Tebuconazole 0.0210 0.0273 16 -0.03690   0.0789\n\ndose = 2.0:\n treat        emmean     SE df lower.CL upper.CL\n Ionic liquid 0.0501 0.0273 16 -0.00781   0.1080\n Tebuconazole 0.0202 0.0273 16 -0.03768   0.0781\n\nConfidence level used: 0.95 \n\n\n\nlibrary(multcomp)\nmf_medias &lt;- emmeans(mf, ~ dose | treat)\ncld(mf_medias)\n\ntreat = Ionic liquid:\n dose emmean     SE df lower.CL upper.CL .group\n  2.0 0.0501 0.0273 16 -0.00781   0.1080  1    \n  0.5 0.2921 0.0273 16  0.23420   0.3500   2   \n\ntreat = Tebuconazole:\n dose emmean     SE df lower.CL upper.CL .group\n  2.0 0.0202 0.0273 16 -0.03768   0.0781  1    \n  0.5 0.0210 0.0273 16 -0.03690   0.0789  1    \n\nConfidence level used: 0.95 \nsignificance level used: alpha = 0.05 \nNOTE: If two or more means share the same grouping symbol,\n      then we cannot show them to be different.\n      But we also did not show them to be the same."
  },
  {
    "objectID": "aula_07.html#one-way-anova",
    "href": "aula_07.html#one-way-anova",
    "title": "Análise Estatística: Estatística inferencial - Parte 2",
    "section": "",
    "text": "A One-Way ANOVA (Análise de Variância de um Fator) é um teste estatístico utilizado para determinar se existem diferenças significativas entre as médias de três ou mais grupos independentes. A “one-way” refere-se ao fato de que há apenas uma variável independente (fator) sendo testada. Este teste é usado quando se quer comparar as médias de diferentes grupos para verificar se pelo menos um grupo difere significativamente dos outros.\nDesta vez iniciaremos garantindo que todos os gráficos tenham uma aparência unica ao longo do documento, para isso, configuraremos o tema para theme_bw() usando a função theme_set().\n\nlibrary(tidyverse)\n\n── Attaching core tidyverse packages ──────────────────────── tidyverse 2.0.0 ──\n✔ dplyr     1.1.4     ✔ readr     2.1.5\n✔ forcats   1.0.0     ✔ stringr   1.5.1\n✔ ggplot2   3.5.1     ✔ tibble    3.2.1\n✔ lubridate 1.9.3     ✔ tidyr     1.3.1\n✔ purrr     1.0.2     \n── Conflicts ────────────────────────────────────────── tidyverse_conflicts() ──\n✖ dplyr::filter() masks stats::filter()\n✖ dplyr::lag()    masks stats::lag()\nℹ Use the conflicted package (&lt;http://conflicted.r-lib.org/&gt;) to force all conflicts to become errors\n\ntheme_set(theme_bw())\n\nPara este tópico utilizamos o conjunto de dados InsectSprays para nossa análise. Este conjunto de dados contém informações sobre a contagem de insetos após a aplicação de diferentes sprays.\n\ninseticida &lt;- InsectSprays\nhead(inseticida)\n\n  count spray\n1    10     A\n2     7     A\n3    20     A\n4    14     A\n5    14     A\n6    12     A\n\n\nAntes de prosseguir com a análise, é útil entender a distribuição das observações entre os diferentes tipos de spray. Para isso, utilizamos a função count() do pacote tidyverse, que conta o número de ocorrências de cada categoria na variável spray.\n\nlibrary(tidyverse)\ninseticida |&gt; \n  count(spray)\n\n  spray  n\n1     A 12\n2     B 12\n3     C 12\n4     D 12\n5     E 12\n6     F 12\n\n\nA função count() é usada para contar as ocorrências de valores únicos em uma coluna. No caso acima, estamos contando quantas vezes cada tipo de spray aparece no conjunto de dados InsectSprays.\nPara ter uma visão geral da contagem por tipo de spray, usamos o boxplot (gráfico de caixa) e jitter para a dispersão.\n\nlibrary(ggplot2)\ninseticida |&gt;\n  ggplot(aes(x = spray, y = count))+\n  geom_boxplot()+\n  geom_jitter()+\n  theme_bw()\n\n\n\n\n\n\n\n\nO boxplot dá indícios de que as médias C, D e E diferem das demais. Entretanto, o plot da variatiância dos dados é bem grande e com presença de outliers.\n\nm1 &lt;- lm(count ~ spray,\n         data = inseticida)\nsummary(m1)\n\n\nCall:\nlm(formula = count ~ spray, data = inseticida)\n\nResiduals:\n   Min     1Q Median     3Q    Max \n-8.333 -1.958 -0.500  1.667  9.333 \n\nCoefficients:\n            Estimate Std. Error t value Pr(&gt;|t|)    \n(Intercept)  14.5000     1.1322  12.807  &lt; 2e-16 ***\nsprayB        0.8333     1.6011   0.520    0.604    \nsprayC      -12.4167     1.6011  -7.755 7.27e-11 ***\nsprayD       -9.5833     1.6011  -5.985 9.82e-08 ***\nsprayE      -11.0000     1.6011  -6.870 2.75e-09 ***\nsprayF        2.1667     1.6011   1.353    0.181    \n---\nSignif. codes:  0 '***' 0.001 '**' 0.01 '*' 0.05 '.' 0.1 ' ' 1\n\nResidual standard error: 3.922 on 66 degrees of freedom\nMultiple R-squared:  0.7244,    Adjusted R-squared:  0.7036 \nF-statistic:  34.7 on 5 and 66 DF,  p-value: &lt; 2.2e-16\n\nanova(m1)\n\nAnalysis of Variance Table\n\nResponse: count\n          Df Sum Sq Mean Sq F value    Pr(&gt;F)    \nspray      5 2668.8  533.77  34.702 &lt; 2.2e-16 ***\nResiduals 66 1015.2   15.38                      \n---\nSignif. codes:  0 '***' 0.001 '**' 0.01 '*' 0.05 '.' 0.1 ' ' 1\n\n\nSegundo a one-way ANOVA, o p-valor associado ao teste F foi &lt; 0.05, indicando que há uma diferença estatisticamente significativa entre pelo menos um par de grupos de spray.\n\n\nPara garantir que o modelo ANOVA seja válido, verificamos os resíduos do modelo para normalidade e homocedasticidade. Inicialmente a normalidade dos resíduos e a homocedasticidade foram verificadas usando um histograma e um gráfico QQ, respectivamente.\n\nm1$residuals\n\n          1           2           3           4           5           6 \n-4.50000000 -7.50000000  5.50000000 -0.50000000 -0.50000000 -2.50000000 \n          7           8           9          10          11          12 \n-4.50000000  8.50000000  2.50000000  5.50000000 -0.50000000 -1.50000000 \n         13          14          15          16          17          18 \n-4.33333333  1.66666667  5.66666667 -4.33333333  0.66666667 -1.33333333 \n         19          20          21          22          23          24 \n 1.66666667  1.66666667  3.66666667  5.66666667 -8.33333333 -2.33333333 \n         25          26          27          28          29          30 \n-2.08333333 -1.08333333  4.91666667 -0.08333333  0.91666667 -1.08333333 \n         31          32          33          34          35          36 \n-0.08333333 -1.08333333  0.91666667 -2.08333333 -1.08333333  1.91666667 \n         37          38          39          40          41          42 \n-1.91666667  0.08333333  7.08333333  1.08333333 -0.91666667 -1.91666667 \n         43          44          45          46          47          48 \n 0.08333333  0.08333333  0.08333333  0.08333333 -2.91666667 -0.91666667 \n         49          50          51          52          53          54 \n-0.50000000  1.50000000 -0.50000000  1.50000000 -0.50000000  2.50000000 \n         55          56          57          58          59          60 \n-2.50000000 -2.50000000 -0.50000000 -1.50000000  2.50000000  0.50000000 \n         61          62          63          64          65          66 \n-5.66666667 -7.66666667 -1.66666667  5.33333333 -1.66666667 -0.66666667 \n         67          68          69          70          71          72 \n-3.66666667 -6.66666667  9.33333333  9.33333333  7.33333333 -3.66666667 \n\nhist(m1$residuals)\n\n\n\n\n\n\n\nqqnorm(m1$residuals)\nqqline(m1$residuals)\n\n\n\n\n\n\n\n\nSegundo obvervado no histograma, os residuos aparentemente seguem uma distribuição normal. Olhando o gráfico QQ os pontos extremos se distanciam em muito a linha central, o que indica não haver homocedesticidade.\nEntretanto, para sabermos definitivamente, de uma forma não subjetiva, se os dados atendem aos preceitos estátisticos, foram feitos o teste de Shapiro-Wilk, para verificar a normalidade e Bartlett para testarmos a homogeneidade de variância.\n\nshapiro.test(m1$residuals)\n\n\n    Shapiro-Wilk normality test\n\ndata:  m1$residuals\nW = 0.96006, p-value = 0.02226\n\nbartlett.test(count ~ spray,\n              data = inseticida)\n\n\n    Bartlett test of homogeneity of variances\n\ndata:  count by spray\nBartlett's K-squared = 25.96, df = 5, p-value = 9.085e-05\n\n\nEm ambos os testes o p-valor foi &lt; 0.05, assim os dados não apresentam normalidade e homogeneidade de variância pelo teste de Shapiro-Wilk e Bartllet, respectivamente. Destre deste preceitos estatísticos, a falta de normalidade é mais “leve” do que a falta de homocedasticidade.\nOutras funções como check_normality() e check_heteroscedasticity() do pacote performance são outras opções poderosas de ferramentas para verificar os pressupostos de normalidade e homocedasticidade.\n\nlibrary(performance)\n\nWarning: pacote 'performance' foi compilado no R versão 4.4.1\n\ncheck_normality(m1)\n\nWarning: Non-normality of residuals detected (p = 0.022).\n\ncheck_heteroscedasticity(m1)\n\nWarning: Heteroscedasticity (non-constant error variance) detected (p &lt; .001).\n\n\nAs funções do pacote performance oferecem uma saída escrita e em cores que identificam se atendeu (verde) ou não (vermelho) ao teste em que os dados foram submetidos. Essas verificações são essenciais para garantir que as inferências estatísticas sejam válidas.\nNo caso do exemplo, como dito anteriormente, os dados não apresentaram normalidade e homogeneidade de variância.\nOutra opção é a utilização do pacote DHARMa (Residual Diagnostics for Hierarchical (Multi-Level / Mixed) Regression Models), ecificamente a função simulateResiduals(). Esta função é usada para gerar resíduos simulados a partir do modelo ajustado. Isso é feito para criar uma distribuição de referência que é usada para diagnosticar o modelo.\n\nlibrary(DHARMa)\n\nWarning: pacote 'DHARMa' foi compilado no R versão 4.4.1\n\n\nThis is DHARMa 0.4.6. For overview type '?DHARMa'. For recent changes, type news(package = 'DHARMa')\n\nplot(simulateResiduals(m1))\n\n\n\n\n\n\n\n\nO gráfico da esquerda, QQ Plot Residuals, tem por objetivo verificar a normalidade dos resíduos. Este gráfico compara os quantis dos resíduos observados com os quantis de uma distribuição normal teórica. Os pontos no gráfico representam os resíduos simulados, e a linha diagonal representa a distribuição normal teórica. Na imagem, os pontos estão próximos da linha diagonal, indicando que os resíduos são aproximadamente normais.\nEsta mesma função realiza o teste de Kolmogorov-Smirnov (KS), este teste é usado para testar a hipótese de que os resíduos seguem uma distribuição normal. Um p-valor de 0.380 indica que não rejeitamos a hipótese nula de normalidade, sugerindo que os resíduos são normalmente distribuídos.\nJá o gráfico da direita, um Boxplot de Resíduos vs. Valores Ajustados, tem por objetico verificar a homocedasticidade (igualdade das variâncias) dos resíduos. Este boxplot mostra a distribuição dos resíduos simulados para diferentes valores preditos pelo modelo (valores ajustados). Neste gráfico as caixas parecem ter tamanhos muito diferentes, indicando possível heterocedasticidade.\nO teste de Levene, que é usado para testar a hipótese de homogeneidade das variâncias, também é aplicado ao se utilizar a funçãosimulateResiduals() e significância do teste de Levene sugere que há heterocedasticidade, ou seja, a variância dos resíduos não é constante ao longo dos valores ajustados."
  },
  {
    "objectID": "aula_07.html#transformação-dos-dados",
    "href": "aula_07.html#transformação-dos-dados",
    "title": "Análise Estatística: Estatística inferencial - Parte 2",
    "section": "",
    "text": "Quando os dados não atendem aos pressupostos de normalidade e homocedasticidade, podemos aplicar uma transformação, como a raiz quadrada, Arco Seno, Logarítmica, Box Cox ou outros, para tentar normalizar os dados e estabilizar a variância.\n\n\nQuando temos dado de contagem geralmente se utiliza a raiz quadrada. Para isso transformamos a variável de contagem aplicando a raiz quadrada e visualizamos novamente os dados. Como no exempo:\n\ninseticida &lt;- inseticida |&gt;\n  mutate(count2 = sqrt(count))\ninseticida |&gt;\n  ggplot(aes(x = spray, y = count2))+\n  geom_boxplot()+\n  geom_jitter()+\n  theme_bw()\n\n\n\n\n\n\n\n\n\nm2 &lt;- lm(count2 ~ spray,\n         data = inseticida)\nsummary(m2)\n\n\nCall:\nlm(formula = count2 ~ spray, data = inseticida)\n\nResiduals:\n     Min       1Q   Median       3Q      Max \n-1.24486 -0.39970 -0.01902  0.42661  1.40089 \n\nCoefficients:\n            Estimate Std. Error t value Pr(&gt;|t|)    \n(Intercept)   3.7607     0.1814  20.733  &lt; 2e-16 ***\nsprayB        0.1160     0.2565   0.452    0.653    \nsprayC       -2.5158     0.2565  -9.807 1.64e-14 ***\nsprayD       -1.5963     0.2565  -6.223 3.80e-08 ***\nsprayE       -1.9512     0.2565  -7.606 1.34e-10 ***\nsprayF        0.2579     0.2565   1.006    0.318    \n---\nSignif. codes:  0 '***' 0.001 '**' 0.01 '*' 0.05 '.' 0.1 ' ' 1\n\nResidual standard error: 0.6283 on 66 degrees of freedom\nMultiple R-squared:  0.7724,    Adjusted R-squared:  0.7552 \nF-statistic:  44.8 on 5 and 66 DF,  p-value: &lt; 2.2e-16\n\nanova(m2)\n\nAnalysis of Variance Table\n\nResponse: count2\n          Df Sum Sq Mean Sq F value    Pr(&gt;F)    \nspray      5 88.438 17.6876  44.799 &lt; 2.2e-16 ***\nResiduals 66 26.058  0.3948                      \n---\nSignif. codes:  0 '***' 0.001 '**' 0.01 '*' 0.05 '.' 0.1 ' ' 1\n\nm2$residuals\n\n          1           2           3           4           5           6 \n-0.59840073 -1.11492708  0.71145756 -0.01902101 -0.01902101 -0.29657678 \n          7           8           9          10          11          12 \n-0.59840073  1.03515313  0.36242723  0.71145756 -0.01902101 -0.15512712 \n         13          14          15          16          17          18 \n-0.56000661  0.24647423  0.70594430 -0.56000661  0.12336860 -0.13497401 \n         19          20          21          22          23          24 \n 0.24647423  0.24647423  0.48226755  0.70594430 -1.23088009 -0.27108012 \n         25          26          27          28          29          30 \n-1.24485667 -0.24485667  1.40089464  0.16935689  0.48719414 -0.24485667 \n         31          32          33          34          35          36 \n 0.16935689 -0.24485667  0.48719414 -1.24485667 -0.24485667  0.75514333 \n         37          38          39          40          41          42 \n-0.43230306  0.07171411  1.29974775  0.28513587 -0.16435387 -0.43230306 \n         43          44          45          46          47          48 \n 0.07171411  0.07171411  0.07171411  0.07171411 -0.75014031 -0.16435387 \n         49          50          51          52          53          54 \n-0.07741021  0.42660696 -0.07741021  0.42660696 -0.07741021  0.64002872 \n         55          56          57          58          59          60 \n-0.80946102 -0.80946102 -0.07741021 -0.39524746  0.64002872  0.19053898 \n         61          62          63          64          65          66 \n-0.70199237 -1.01861716 -0.14563382  0.67179860 -0.14563382 -0.01861716 \n         67          68          69          70          71          72 \n-0.41306589 -0.85633950  1.08040235  1.08040235  0.88036232 -0.41306589 \n\nhist(m2$residuals)\n\n\n\n\n\n\n\nqqnorm(m2$residuals)\nqqline(m2$residuals)\n\n\n\n\n\n\n\n\n\nshapiro.test(m2$residuals)\n\n\n    Shapiro-Wilk normality test\n\ndata:  m2$residuals\nW = 0.98721, p-value = 0.6814\n\nbartlett.test(count2 ~ spray,\n              data = inseticida)\n\n\n    Bartlett test of homogeneity of variances\n\ndata:  count2 by spray\nBartlett's K-squared = 3.7525, df = 5, p-value = 0.5856\n\n\n\nlibrary(DHARMa)\nplot(simulateResiduals(m2))\n\n\n\n\n\n\n\nlibrary(performance)\ncheck_normality(m2)\n\nOK: residuals appear as normally distributed (p = 0.681).\n\ncheck_heteroscedasticity(m2)\n\nOK: Error variance appears to be homoscedastic (p = 0.854).\n\n\nAgora os dados atendem a normalidade e homocedasticidade.\nemmeans mostra o intervalo de confiança\n\nlibrary(emmeans)\n\nWarning: pacote 'emmeans' foi compilado no R versão 4.4.1\n\n\nWelcome to emmeans.\nCaution: You lose important information if you filter this package's results.\nSee '? untidy'\n\nm1_medias &lt;- emmeans(m1, ~ spray)\nplot(m1_medias)\n\n\n\n\n\n\n\n\n\nlibrary(multcomp)\n\nCarregando pacotes exigidos: mvtnorm\n\n\nCarregando pacotes exigidos: survival\n\n\nWarning: pacote 'survival' foi compilado no R versão 4.4.1\n\n\nCarregando pacotes exigidos: TH.data\n\n\nCarregando pacotes exigidos: MASS\n\n\nWarning: pacote 'MASS' foi compilado no R versão 4.4.1\n\n\n\nAnexando pacote: 'MASS'\n\n\nO seguinte objeto é mascarado por 'package:dplyr':\n\n    select\n\n\n\nAnexando pacote: 'TH.data'\n\n\nO seguinte objeto é mascarado por 'package:MASS':\n\n    geyser\n\ncld(m1_medias)\n\n spray emmean   SE df lower.CL upper.CL .group\n C       2.08 1.13 66   -0.177     4.34  1    \n E       3.50 1.13 66    1.240     5.76  1    \n D       4.92 1.13 66    2.656     7.18  1    \n A      14.50 1.13 66   12.240    16.76   2   \n B      15.33 1.13 66   13.073    17.59   2   \n F      16.67 1.13 66   14.406    18.93   2   \n\nConfidence level used: 0.95 \nP value adjustment: tukey method for comparing a family of 6 estimates \nsignificance level used: alpha = 0.05 \nNOTE: If two or more means share the same grouping symbol,\n      then we cannot show them to be different.\n      But we also did not show them to be the same. \n\n\n\nlibrary(emmeans)\nm2_medias &lt;- emmeans(m2, ~ spray)\nplot(m2_medias)\n\n\n\n\n\n\n\n\n\nlibrary(multcomp)\ncld(m2_medias)\n\n spray emmean    SE df lower.CL upper.CL .group\n C       1.24 0.181 66    0.883     1.61  1    \n E       1.81 0.181 66    1.447     2.17  12   \n D       2.16 0.181 66    1.802     2.53   2   \n A       3.76 0.181 66    3.399     4.12    3  \n B       3.88 0.181 66    3.514     4.24    3  \n F       4.02 0.181 66    3.656     4.38    3  \n\nConfidence level used: 0.95 \nP value adjustment: tukey method for comparing a family of 6 estimates \nsignificance level used: alpha = 0.05 \nNOTE: If two or more means share the same grouping symbol,\n      then we cannot show them to be different.\n      But we also did not show them to be the same. \n\n\n\npwpm(m2_medias)\n\n       A      B      C      D      E      F\nA [3.76] 0.9975 &lt;.0001 &lt;.0001 &lt;.0001 0.9145\nB -0.116 [3.88] &lt;.0001 &lt;.0001 &lt;.0001 0.9936\nC  2.516  2.632 [1.24] 0.0081 0.2513 &lt;.0001\nD  1.596  1.712 -0.919 [2.16] 0.7366 &lt;.0001\nE  1.951  2.067 -0.565  0.355 [1.81] &lt;.0001\nF -0.258 -0.142 -2.774 -1.854 -2.209 [4.02]\n\nRow and column labels: spray\nUpper triangle: P values   adjust = \"tukey\"\nDiagonal: [Estimates] (emmean) \nLower triangle: Comparisons (estimate)   earlier vs. later\n\npwpp(m2_medias)\n\n\n\n\n\n\n\n\n\npairs(m2_medias)\n\n contrast estimate    SE df t.ratio p.value\n A - B      -0.116 0.257 66  -0.452  0.9975\n A - C       2.516 0.257 66   9.807  &lt;.0001\n A - D       1.596 0.257 66   6.223  &lt;.0001\n A - E       1.951 0.257 66   7.606  &lt;.0001\n A - F      -0.258 0.257 66  -1.006  0.9145\n B - C       2.632 0.257 66  10.259  &lt;.0001\n B - D       1.712 0.257 66   6.675  &lt;.0001\n B - E       2.067 0.257 66   8.058  &lt;.0001\n B - F      -0.142 0.257 66  -0.554  0.9936\n C - D      -0.919 0.257 66  -3.584  0.0081\n C - E      -0.565 0.257 66  -2.201  0.2513\n C - F      -2.774 0.257 66 -10.813  &lt;.0001\n D - E       0.355 0.257 66   1.383  0.7366\n D - F      -1.854 0.257 66  -7.229  &lt;.0001\n E - F      -2.209 0.257 66  -8.612  &lt;.0001\n\nP value adjustment: tukey method for comparing a family of 6 estimates \n\n\npodemos aplicar de Box-Cox\n\nlibrary(MASS)\nb &lt;- boxcox(lm(inseticida$count + 0.1 ~ 1))\n\n\n\n\n\n\n\nlambda &lt;- b$x[which.max(b$y)]\nlambda\n\n[1] 0.4242424\n\n\n\ninseticida$count3 &lt;- (inseticida$count^lambda-1)/lambda\ninseticida$count3\n\n [1]  3.903635  3.024469  6.043993  4.864268  4.864268  4.407118  3.903635\n [8]  6.557185  5.484274  6.043993  4.864268  4.640760  4.161975  5.484274\n[15]  6.219699  4.161975  5.285168  4.864268  5.484274  5.484274  5.863153\n[22]  6.219699  3.024469  4.640760 -2.357143  0.000000  3.024469  0.805831\n[29]  1.399509  0.000000  0.805831  0.000000  1.399509 -2.357143  0.000000\n[36]  1.887150  1.399509  2.308577  4.407118  2.683787  1.887150  1.399509\n[43]  2.308577  2.308577  2.308577  2.308577  0.805831  1.887150  1.399509\n[50]  2.308577  1.399509  2.308577  1.399509  2.683787  0.000000  0.000000\n[57]  1.399509  0.805831  2.683787  1.887150  4.161975  3.629951  5.078760\n[64]  6.390651  5.078760  5.285168  4.640760  3.903635  7.033117  7.033117\n[71]  6.719601  4.640760\n\n\nSe lambda for igual a 0.5 é igual a raiz quadrada\n\nm5 &lt;- lm(count3 ~ spray,\n         data = inseticida)\nlibrary(DHARMa)\nplot(simulateResiduals(m5))\n\n\n\n\n\n\n\nlibrary(performance)\ncheck_normality(m5)\n\nOK: residuals appear as normally distributed (p = 0.772).\n\ncheck_heteroscedasticity(m5)\n\nOK: Error variance appears to be homoscedastic (p = 0.246).\n\n\nAlternativa, usando testes não paramétricos\n\nlibrary(agricolae)\n\nWarning: pacote 'agricolae' foi compilado no R versão 4.4.1\n\nprint('-=-=-=-=-=-=- DO PRÓPRIO R -=-=-=-=-=-=-')\n\n[1] \"-=-=-=-=-=-=- DO PRÓPRIO R -=-=-=-=-=-=-\"\n\nkruskal.test(count ~ spray,\n             data = inseticida)\n\n\n    Kruskal-Wallis rank sum test\n\ndata:  count by spray\nKruskal-Wallis chi-squared = 54.691, df = 5, p-value = 1.511e-10\n\nprint('-=-=-=-=-=-=- DO PACOTE AGRICOLAE -=-=-=-=-=-=-')\n\n[1] \"-=-=-=-=-=-=- DO PACOTE AGRICOLAE -=-=-=-=-=-=-\"\n\nm3 &lt;- kruskal(inseticida$count,\n        inseticida$spray,\n        group = TRUE)\nm3\n\n$statistics\n     Chisq Df      p.chisq  t.value      MSD\n  54.69134  5 1.510845e-10 1.996564 8.462804\n\n$parameters\n            test p.ajusted           name.t ntr alpha\n  Kruskal-Wallis      none inseticida$spray   6  0.05\n\n$means\n  inseticida.count     rank      std  r Min Max   Q25  Q50   Q75\nA        14.500000 52.16667 4.719399 12   7  23 11.50 14.0 17.75\nB        15.333333 54.83333 4.271115 12   7  21 12.50 16.5 17.50\nC         2.083333 11.45833 1.975225 12   0   7  1.00  1.5  3.00\nD         4.916667 25.58333 2.503028 12   2  12  3.75  5.0  5.00\nE         3.500000 19.33333 1.732051 12   1   6  2.75  3.0  5.00\nF        16.666667 55.62500 6.213378 12   9  26 12.50 15.0 22.50\n\n$comparison\nNULL\n\n$groups\n  inseticida$count groups\nF         55.62500      a\nB         54.83333      a\nA         52.16667      a\nD         25.58333      b\nE         19.33333     bc\nC         11.45833      c\n\nattr(,\"class\")\n[1] \"group\"\n\n\ngeneralizado é mais bonito, mais moderno, mais aceito.\nAlternativa usando GLMs\n\nm4 &lt;- glm(count ~spray,\n          family = gaussian,\n          data = inseticida)\nsummary(m4)\n\n\nCall:\nglm(formula = count ~ spray, family = gaussian, data = inseticida)\n\nCoefficients:\n            Estimate Std. Error t value Pr(&gt;|t|)    \n(Intercept)  14.5000     1.1322  12.807  &lt; 2e-16 ***\nsprayB        0.8333     1.6011   0.520    0.604    \nsprayC      -12.4167     1.6011  -7.755 7.27e-11 ***\nsprayD       -9.5833     1.6011  -5.985 9.82e-08 ***\nsprayE      -11.0000     1.6011  -6.870 2.75e-09 ***\nsprayF        2.1667     1.6011   1.353    0.181    \n---\nSignif. codes:  0 '***' 0.001 '**' 0.01 '*' 0.05 '.' 0.1 ' ' 1\n\n(Dispersion parameter for gaussian family taken to be 15.38131)\n\n    Null deviance: 3684.0  on 71  degrees of freedom\nResidual deviance: 1015.2  on 66  degrees of freedom\nAIC: 408.85\n\nNumber of Fisher Scoring iterations: 2\n\nanova(m4)\n\nAnalysis of Deviance Table\n\nModel: gaussian, link: identity\n\nResponse: count\n\nTerms added sequentially (first to last)\n\n      Df Deviance Resid. Df Resid. Dev      F    Pr(&gt;F)    \nNULL                     71     3684.0                     \nspray  5   2668.8        66     1015.2 34.702 &lt; 2.2e-16 ***\n---\nSignif. codes:  0 '***' 0.001 '**' 0.01 '*' 0.05 '.' 0.1 ' ' 1\n\nlibrary(car)\n\nCarregando pacotes exigidos: carData\n\n\n\nAnexando pacote: 'car'\n\n\nO seguinte objeto é mascarado por 'package:dplyr':\n\n    recode\n\n\nO seguinte objeto é mascarado por 'package:purrr':\n\n    some\n\nAnova(m4)\n\nAnalysis of Deviance Table (Type II tests)\n\nResponse: count\n      LR Chisq Df Pr(&gt;Chisq)    \nspray   173.51  5  &lt; 2.2e-16 ***\n---\nSignif. codes:  0 '***' 0.001 '**' 0.01 '*' 0.05 '.' 0.1 ' ' 1\n\n\nTem que olhar a familia da distribuição olhando os pressupostos.\n\nlibrary(DHARMa)\nm5 &lt;- glm(count ~spray,\n          family = poisson,\n          data = inseticida)\nsummary(m5)\n\n\nCall:\nglm(formula = count ~ spray, family = poisson, data = inseticida)\n\nCoefficients:\n            Estimate Std. Error z value Pr(&gt;|z|)    \n(Intercept)  2.67415    0.07581  35.274  &lt; 2e-16 ***\nsprayB       0.05588    0.10574   0.528    0.597    \nsprayC      -1.94018    0.21389  -9.071  &lt; 2e-16 ***\nsprayD      -1.08152    0.15065  -7.179 7.03e-13 ***\nsprayE      -1.42139    0.17192  -8.268  &lt; 2e-16 ***\nsprayF       0.13926    0.10367   1.343    0.179    \n---\nSignif. codes:  0 '***' 0.001 '**' 0.01 '*' 0.05 '.' 0.1 ' ' 1\n\n(Dispersion parameter for poisson family taken to be 1)\n\n    Null deviance: 409.041  on 71  degrees of freedom\nResidual deviance:  98.329  on 66  degrees of freedom\nAIC: 376.59\n\nNumber of Fisher Scoring iterations: 5\n\nAnova(m5)\n\nAnalysis of Deviance Table (Type II tests)\n\nResponse: count\n      LR Chisq Df Pr(&gt;Chisq)    \nspray   310.71  5  &lt; 2.2e-16 ***\n---\nSignif. codes:  0 '***' 0.001 '**' 0.01 '*' 0.05 '.' 0.1 ' ' 1\n\nplot(simulateResiduals(m5))\n\n\n\n\n\n\n\n\n\nm5_medias &lt;- emmeans(m5, ~ spray,\n                     type = 'response')\nlibrary(multcomp)\nlibrary(multcompView)\n\nWarning: pacote 'multcompView' foi compilado no R versão 4.4.1\n\ncld(m5_medias)\n\n spray  rate    SE  df asymp.LCL asymp.UCL .group\n C      2.08 0.417 Inf      1.41      3.08  1    \n E      3.50 0.540 Inf      2.59      4.74  12   \n D      4.92 0.640 Inf      3.81      6.35   2   \n A     14.50 1.099 Inf     12.50     16.82    3  \n B     15.33 1.130 Inf     13.27     17.72    3  \n F     16.67 1.179 Inf     14.51     19.14    3  \n\nConfidence level used: 0.95 \nIntervals are back-transformed from the log scale \nP value adjustment: tukey method for comparing a family of 6 estimates \nTests are performed on the log scale \nsignificance level used: alpha = 0.05 \nNOTE: If two or more means share the same grouping symbol,\n      then we cannot show them to be different.\n      But we also did not show them to be the same. \n\n\nOutro conjunto de dados two-way anova - ANOVA fatorial\n\nlibrary(gsheet)\nli &lt;- gsheet2tbl(\"https://docs.google.com/spreadsheets/d/1bq2N19DcZdtax2fQW9OHSGMR0X2__Z9T/edit#gid=2023059672\")\n\nhead(li)\n\n# A tibble: 6 × 8\n  treat         dose   rep  n_sp dis_sp n_seeds inf_seeds severity\n  &lt;chr&gt;        &lt;dbl&gt; &lt;dbl&gt; &lt;dbl&gt;  &lt;dbl&gt;   &lt;dbl&gt;     &lt;dbl&gt;    &lt;dbl&gt;\n1 Ionic liquid   0.5     1   103     13      25        10   0.126 \n2 Ionic liquid   0.5     2   125     31      25        12   0.248 \n3 Ionic liquid   0.5     3   210     80      25        12   0.381 \n4 Ionic liquid   0.5     4    97     28      25        10   0.289 \n5 Ionic liquid   0.5     5   180     75      25        11   0.417 \n6 Ionic liquid   2       2   116      9      25         6   0.0776\n\n\n\nlibrary(ggplot2)\nli |&gt;\n  ggplot(aes(factor(dose),severity, color = factor(dose)))+\n  geom_jitter(width = 0.1)+\n  facet_wrap(~treat)+\n  theme_bw()\n\n\n\n\n\n\n\n\n\nli |&gt;\n  ggplot(aes(treat ,severity, color = factor(dose)))+\n  geom_jitter(width = 0.1)\n\n\n\n\n\n\n\n\nModelo fatoral - Para DIC\n\nmf &lt;- lm(severity ~ treat*factor(dose),\n         data = li)\nmf\n\n\nCall:\nlm(formula = severity ~ treat * factor(dose), data = li)\n\nCoefficients:\n                    (Intercept)                treatTebuconazole  \n                         0.2921                          -0.2711  \n                  factor(dose)2  treatTebuconazole:factor(dose)2  \n                        -0.2420                           0.2412  \n\nanova(mf)\n\nAnalysis of Variance Table\n\nResponse: severity\n                   Df   Sum Sq  Mean Sq F value    Pr(&gt;F)    \ntreat               1 0.113232 0.113232  30.358 4.754e-05 ***\nfactor(dose)        1 0.073683 0.073683  19.755 0.0004077 ***\ntreat:factor(dose)  1 0.072739 0.072739  19.502 0.0004326 ***\nResiduals          16 0.059678 0.003730                      \n---\nSignif. codes:  0 '***' 0.001 '**' 0.01 '*' 0.05 '.' 0.1 ' ' 1\n\n\n\nlibrary(DHARMa)\nplot(simulateResiduals(mf))\n\n\n\n\n\n\n\n\n\nlibrary(performance)\ncheck_normality(mf)\n\nWarning: Non-normality of residuals detected (p = 0.011).\n\ncheck_homogeneity(mf)\n\nWarning: Variances differ between groups (Bartlett Test, p = 0.001).\n\n\nO cld, do pacote multcomp, coloca as letras.\n\nmf_medias &lt;- emmeans(mf, ~ treat | dose)\nmf_medias\n\ndose = 0.5:\n treat        emmean     SE df lower.CL upper.CL\n Ionic liquid 0.2921 0.0273 16  0.23420   0.3500\n Tebuconazole 0.0210 0.0273 16 -0.03690   0.0789\n\ndose = 2.0:\n treat        emmean     SE df lower.CL upper.CL\n Ionic liquid 0.0501 0.0273 16 -0.00781   0.1080\n Tebuconazole 0.0202 0.0273 16 -0.03768   0.0781\n\nConfidence level used: 0.95 \n\n\n\nlibrary(multcomp)\nmf_medias &lt;- emmeans(mf, ~ dose | treat)\ncld(mf_medias)\n\ntreat = Ionic liquid:\n dose emmean     SE df lower.CL upper.CL .group\n  2.0 0.0501 0.0273 16 -0.00781   0.1080  1    \n  0.5 0.2921 0.0273 16  0.23420   0.3500   2   \n\ntreat = Tebuconazole:\n dose emmean     SE df lower.CL upper.CL .group\n  2.0 0.0202 0.0273 16 -0.03768   0.0781  1    \n  0.5 0.0210 0.0273 16 -0.03690   0.0789  1    \n\nConfidence level used: 0.95 \nsignificance level used: alpha = 0.05 \nNOTE: If two or more means share the same grouping symbol,\n      then we cannot show them to be different.\n      But we also did not show them to be the same."
  },
  {
    "objectID": "aula_09.html",
    "href": "aula_09.html",
    "title": "Aula 09",
    "section": "",
    "text": "Modelo misto, um fator fixo e um aleatório.\n\nlibrary(tidyverse)\n\n── Attaching core tidyverse packages ──────────────────────── tidyverse 2.0.0 ──\n✔ dplyr     1.1.4     ✔ readr     2.1.5\n✔ forcats   1.0.0     ✔ stringr   1.5.1\n✔ ggplot2   3.5.1     ✔ tibble    3.2.1\n✔ lubridate 1.9.3     ✔ tidyr     1.3.1\n✔ purrr     1.0.2     \n── Conflicts ────────────────────────────────────────── tidyverse_conflicts() ──\n✖ dplyr::filter() masks stats::filter()\n✖ dplyr::lag()    masks stats::lag()\nℹ Use the conflicted package (&lt;http://conflicted.r-lib.org/&gt;) to force all conflicts to become errors\n\ntheme_set(theme_bw())\n\nChamando os dados\n\nlibrary(gsheet)\nmilho &lt;- gsheet2tbl(\"https://docs.google.com/spreadsheets/d/1bq2N19DcZdtax2fQW9OHSGMR0X2__Z9T/edit#gid=1345524759\")\n\nPlotando gráfico\n\nindx &lt;- milho |&gt; \n  ggplot(aes(method, index ))+\n  geom_jitter(width = 0.05, color = \"gray70\")+\n  facet_wrap(~ hybrid)+ #Sem o facet_wrap fica somente por tratamento.\n  stat_summary(fun.data = \"mean_cl_boot\", size =0.5, color = \"black\", alpha = 0.5)\nindx\n\n\n\n\n\n\n\n\n\n\n\nlibrary(lme4)\n\nCarregando pacotes exigidos: Matrix\n\n\n\nAnexando pacote: 'Matrix'\n\n\nOs seguintes objetos são mascarados por 'package:tidyr':\n\n    expand, pack, unpack\n\nlibrary(car)\n\nCarregando pacotes exigidos: carData\n\n\n\nAnexando pacote: 'car'\n\n\nO seguinte objeto é mascarado por 'package:dplyr':\n\n    recode\n\n\nO seguinte objeto é mascarado por 'package:purrr':\n\n    some\n\nmilho &lt;- milho |&gt; \n  mutate(block = as.factor(block))\n#lmer é o modelo linear do lme4\nmix2 &lt;- lmer(index ~ hybrid*method + block+ (1|block/hybrid), data = milho)\n\nWarning in checkConv(attr(opt, \"derivs\"), opt$par, ctrl = control$checkConv, :\nunable to evaluate scaled gradient\n\n\nWarning in checkConv(attr(opt, \"derivs\"), opt$par, ctrl = control$checkConv, :\nModel failed to converge: degenerate Hessian with 1 negative eigenvalues\n\nAnova(mix2)\n\nAnalysis of Deviance Table (Type II Wald chisquare tests)\n\nResponse: index\n                Chisq Df Pr(&gt;Chisq)   \nhybrid        15.5971  5   0.008094 **\nmethod         4.6963  1   0.030228 * \nblock          0.2157  3   0.975023   \nhybrid:method 15.8060  5   0.007420 **\n---\nSignif. codes:  0 '***' 0.001 '**' 0.01 '*' 0.05 '.' 0.1 ' ' 1\n\n\nHouve interação significativa entre hibridos e metodos.\n\nlibrary(performance)\n\nWarning: pacote 'performance' foi compilado no R versão 4.4.1\n\ncheck_normality(mix2)\n\nOK: residuals appear as normally distributed (p = 0.635).\n\ncheck_heteroscedasticity(mix2)\n\nWarning: Heteroscedasticity (non-constant error variance) detected (p = 0.009).\n\n\n\nlibrary(DHARMa)\n\nWarning: pacote 'DHARMa' foi compilado no R versão 4.4.1\n\n\nThis is DHARMa 0.4.6. For overview type '?DHARMa'. For recent changes, type news(package = 'DHARMa')\n\nplot(simulateResiduals(mix2))\n\n\n\n\n\n\n\n\nTransformação - Raiz quadrada\n\nmilho &lt;- milho |&gt; \n  mutate(block = as.factor(block))\n#lmer é o modelo linear do lme4\nmix3 &lt;- lmer(sqrt(index) ~ hybrid*method + block+ (1|block/hybrid), data = milho)\n\nWarning in checkConv(attr(opt, \"derivs\"), opt$par, ctrl = control$checkConv, :\nunable to evaluate scaled gradient\n\n\nWarning in checkConv(attr(opt, \"derivs\"), opt$par, ctrl = control$checkConv, :\nModel failed to converge: degenerate Hessian with 1 negative eigenvalues\n\nAnova(mix2)\n\nAnalysis of Deviance Table (Type II Wald chisquare tests)\n\nResponse: index\n                Chisq Df Pr(&gt;Chisq)   \nhybrid        15.5971  5   0.008094 **\nmethod         4.6963  1   0.030228 * \nblock          0.2157  3   0.975023   \nhybrid:method 15.8060  5   0.007420 **\n---\nSignif. codes:  0 '***' 0.001 '**' 0.01 '*' 0.05 '.' 0.1 ' ' 1\n\n\n\nlibrary(performance)\ncheck_normality(mix3)\n\nOK: residuals appear as normally distributed (p = 0.440).\n\ncheck_heteroscedasticity(mix3)\n\nOK: Error variance appears to be homoscedastic (p = 0.971).\n\n\n\nlibrary(DHARMa)\nplot(simulateResiduals(mix3))\n\n\n\n\n\n\n\n\n\nqqnorm(residuals(mix3))\nqqline(residuals(mix3))\n\n\n\n\n\n\n\nhist(residuals(mix3))\n\n\n\n\n\n\n\n\nCalcular as médias\n\nlibrary(emmeans)\n\nWarning: pacote 'emmeans' foi compilado no R versão 4.4.1\n\n\nWelcome to emmeans.\nCaution: You lose important information if you filter this package's results.\nSee '? untidy'\n\nprint(\"HIBRIDO X METODO\")\n\n[1] \"HIBRIDO X METODO\"\n\nmedias_milho1 &lt;- emmeans(mix3, ~ hybrid|method, type = \"response\")\nmedias_milho1\n\nmethod = pin:\n hybrid   response   SE   df lower.CL upper.CL\n 30F53 HX     25.0 12.1 6084     6.84     54.4\n 30F53 YH     24.5 12.0 6084     6.61     53.7\n 30K64        20.3 10.9 6084     4.51     47.4\n 30S31H       37.1 14.8 6084    13.79     71.8\n 30S31YH      31.7 13.7 6084    10.57     64.2\n BG7049H      19.4 10.7 6084     4.10     46.0\n\nmethod = silk:\n hybrid   response   SE   df lower.CL upper.CL\n 30F53 HX     24.4 12.0 6084     6.56     53.6\n 30F53 YH     26.0 12.4 6084     7.42     56.0\n 30K64        21.3 11.2 6084     5.00     48.9\n 30S31H       26.3 12.5 6084     7.57     56.4\n 30S31YH      26.4 12.5 6084     7.62     56.5\n BG7049H      19.1 10.6 6084     3.96     45.6\n\nResults are averaged over the levels of: block \nDegrees-of-freedom method: kenward-roger \nConfidence level used: 0.95 \nIntervals are back-transformed from the sqrt scale \n\nprint(\"METODO X HIBRIDO\")\n\n[1] \"METODO X HIBRIDO\"\n\nmedias_milho2 &lt;- emmeans(mix3, ~ method|hybrid, type = \"response\")\nmedias_milho2\n\nhybrid = 30F53 HX:\n method response   SE   df lower.CL upper.CL\n pin        25.0 12.1 6084     6.84     54.4\n silk       24.4 12.0 6084     6.56     53.6\n\nhybrid = 30F53 YH:\n method response   SE   df lower.CL upper.CL\n pin        24.5 12.0 6084     6.61     53.7\n silk       26.0 12.4 6084     7.42     56.0\n\nhybrid = 30K64:\n method response   SE   df lower.CL upper.CL\n pin        20.3 10.9 6084     4.51     47.4\n silk       21.3 11.2 6084     5.00     48.9\n\nhybrid = 30S31H:\n method response   SE   df lower.CL upper.CL\n pin        37.1 14.8 6084    13.79     71.8\n silk       26.3 12.5 6084     7.57     56.4\n\nhybrid = 30S31YH:\n method response   SE   df lower.CL upper.CL\n pin        31.7 13.7 6084    10.57     64.2\n silk       26.4 12.5 6084     7.62     56.5\n\nhybrid = BG7049H:\n method response   SE   df lower.CL upper.CL\n pin        19.4 10.7 6084     4.10     46.0\n silk       19.1 10.6 6084     3.96     45.6\n\nResults are averaged over the levels of: block \nDegrees-of-freedom method: kenward-roger \nConfidence level used: 0.95 \nIntervals are back-transformed from the sqrt scale \n\n\n\nlibrary(multcomp)\n\nCarregando pacotes exigidos: mvtnorm\n\n\nCarregando pacotes exigidos: survival\n\n\nWarning: pacote 'survival' foi compilado no R versão 4.4.1\n\n\nCarregando pacotes exigidos: TH.data\n\n\nCarregando pacotes exigidos: MASS\n\n\nWarning: pacote 'MASS' foi compilado no R versão 4.4.1\n\n\n\nAnexando pacote: 'MASS'\n\n\nO seguinte objeto é mascarado por 'package:dplyr':\n\n    select\n\n\n\nAnexando pacote: 'TH.data'\n\n\nO seguinte objeto é mascarado por 'package:MASS':\n\n    geyser\n\ncld(medias_milho1, Letters = LETTERS)\n\nmethod = pin:\n hybrid   response   SE   df lower.CL upper.CL .group\n BG7049H      19.4 10.7 6084     4.10     46.0  A    \n 30K64        20.3 10.9 6084     4.51     47.4  A    \n 30F53 YH     24.5 12.0 6084     6.61     53.7  AB   \n 30F53 HX     25.0 12.1 6084     6.84     54.4  AB   \n 30S31YH      31.7 13.7 6084    10.57     64.2  AB   \n 30S31H       37.1 14.8 6084    13.79     71.8   B   \n\nmethod = silk:\n hybrid   response   SE   df lower.CL upper.CL .group\n BG7049H      19.1 10.6 6084     3.96     45.6  A    \n 30K64        21.3 11.2 6084     5.00     48.9  A    \n 30F53 HX     24.4 12.0 6084     6.56     53.6  A    \n 30F53 YH     26.0 12.4 6084     7.42     56.0  A    \n 30S31H       26.3 12.5 6084     7.57     56.4  A    \n 30S31YH      26.4 12.5 6084     7.62     56.5  A    \n\nResults are averaged over the levels of: block \nDegrees-of-freedom method: kenward-roger \nConfidence level used: 0.95 \nIntervals are back-transformed from the sqrt scale \nNote: contrasts are still on the sqrt scale \nP value adjustment: tukey method for comparing a family of 6 estimates \nsignificance level used: alpha = 0.05 \nNOTE: If two or more means share the same grouping symbol,\n      then we cannot show them to be different.\n      But we also did not show them to be the same. \n\ncld(medias_milho2, Letters = letters)\n\nhybrid = 30F53 HX:\n method response   SE   df lower.CL upper.CL .group\n silk       24.4 12.0 6084     6.56     53.6  a    \n pin        25.0 12.1 6084     6.84     54.4  a    \n\nhybrid = 30F53 YH:\n method response   SE   df lower.CL upper.CL .group\n pin        24.5 12.0 6084     6.61     53.7  a    \n silk       26.0 12.4 6084     7.42     56.0  a    \n\nhybrid = 30K64:\n method response   SE   df lower.CL upper.CL .group\n pin        20.3 10.9 6084     4.51     47.4  a    \n silk       21.3 11.2 6084     5.00     48.9  a    \n\nhybrid = 30S31H:\n method response   SE   df lower.CL upper.CL .group\n silk       26.3 12.5 6084     7.57     56.4  a    \n pin        37.1 14.8 6084    13.79     71.8   b   \n\nhybrid = 30S31YH:\n method response   SE   df lower.CL upper.CL .group\n silk       26.4 12.5 6084     7.62     56.5  a    \n pin        31.7 13.7 6084    10.57     64.2  a    \n\nhybrid = BG7049H:\n method response   SE   df lower.CL upper.CL .group\n silk       19.1 10.6 6084     3.96     45.6  a    \n pin        19.4 10.7 6084     4.10     46.0  a    \n\nResults are averaged over the levels of: block \nDegrees-of-freedom method: kenward-roger \nConfidence level used: 0.95 \nIntervals are back-transformed from the sqrt scale \nNote: contrasts are still on the sqrt scale \nsignificance level used: alpha = 0.05 \nNOTE: If two or more means share the same grouping symbol,\n      then we cannot show them to be different.\n      But we also did not show them to be the same. \n\n\nAgora para produtividade\n\nmix4 &lt;- lmer(sqrt(yield) ~ hybrid*method + block+ (1|block/hybrid), data = milho)\n\nWarning in checkConv(attr(opt, \"derivs\"), opt$par, ctrl = control$checkConv, : Model is nearly unidentifiable: large eigenvalue ratio\n - Rescale variables?\n\nAnova(mix4)\n\nAnalysis of Deviance Table (Type II Wald chisquare tests)\n\nResponse: sqrt(yield)\n                Chisq Df Pr(&gt;Chisq)    \nhybrid        25.5591  5  0.0001086 ***\nmethod         0.0520  1  0.8196750    \nblock          2.3606  3  0.5010021    \nhybrid:method 24.4985  5  0.0001741 ***\n---\nSignif. codes:  0 '***' 0.001 '**' 0.01 '*' 0.05 '.' 0.1 ' ' 1\n\nlibrary(performance)\ncheck_normality(mix4)\n\nOK: residuals appear as normally distributed (p = 0.214).\n\ncheck_heteroscedasticity(mix4)\n\nOK: Error variance appears to be homoscedastic (p = 0.686).\n\n\n\nplot(simulateResiduals(mix4))\n\n\n\n\n\n\n\n\n\nprint(\"HIBRIDO X METODO\")\n\n[1] \"HIBRIDO X METODO\"\n\nmedias_milho3 &lt;- emmeans(mix4, ~ hybrid|method, type = \"response\")\nmedias_milho3\n\nmethod = pin:\n hybrid   response  SE   df lower.CL upper.CL\n 30F53 HX    11130 872 26.1     9410    12995\n 30F53 YH     9314 798 26.1     7746    11027\n 30K64       11666 893 26.1     9903    13574\n 30S31H       8081 743 26.1     6626     9681\n 30S31YH      7829 732 26.1     6398     9405\n BG7049H     11914 903 26.1    10131    13841\n\nmethod = silk:\n hybrid   response  SE   df lower.CL upper.CL\n 30F53 HX     9932 824 26.1     8311    11698\n 30F53 YH     9079 788 26.1     7532    10770\n 30K64       10331 840 26.1     8676    12131\n 30S31H       9135 790 26.1     7583    10832\n 30S31YH      8257 751 26.1     6785     9873\n BG7049H     12822 936 26.1    10970    14818\n\nResults are averaged over the levels of: block \nDegrees-of-freedom method: kenward-roger \nConfidence level used: 0.95 \nIntervals are back-transformed from the sqrt scale \n\nprint(\"METODO X HIBRIDO\")\n\n[1] \"METODO X HIBRIDO\"\n\nmedias_milho4 &lt;- emmeans(mix4, ~ method|hybrid, type = \"response\")\nmedias_milho4\n\nhybrid = 30F53 HX:\n method response  SE   df lower.CL upper.CL\n pin       11130 872 26.1     9410    12995\n silk       9932 824 26.1     8311    11698\n\nhybrid = 30F53 YH:\n method response  SE   df lower.CL upper.CL\n pin        9314 798 26.1     7746    11027\n silk       9079 788 26.1     7532    10770\n\nhybrid = 30K64:\n method response  SE   df lower.CL upper.CL\n pin       11666 893 26.1     9903    13574\n silk      10331 840 26.1     8676    12131\n\nhybrid = 30S31H:\n method response  SE   df lower.CL upper.CL\n pin        8081 743 26.1     6626     9681\n silk       9135 790 26.1     7583    10832\n\nhybrid = 30S31YH:\n method response  SE   df lower.CL upper.CL\n pin        7829 732 26.1     6398     9405\n silk       8257 751 26.1     6785     9873\n\nhybrid = BG7049H:\n method response  SE   df lower.CL upper.CL\n pin       11914 903 26.1    10131    13841\n silk      12822 936 26.1    10970    14818\n\nResults are averaged over the levels of: block \nDegrees-of-freedom method: kenward-roger \nConfidence level used: 0.95 \nIntervals are back-transformed from the sqrt scale \n\n\n\ncld(medias_milho3, Letters = LETTERS)\n\nmethod = pin:\n hybrid   response  SE   df lower.CL upper.CL .group\n 30S31YH      7829 732 26.1     6398     9405  A    \n 30S31H       8081 743 26.1     6626     9681  AB   \n 30F53 YH     9314 798 26.1     7746    11027  ABC  \n 30F53 HX    11130 872 26.1     9410    12995   BC  \n 30K64       11666 893 26.1     9903    13574    C  \n BG7049H     11914 903 26.1    10131    13841    C  \n\nmethod = silk:\n hybrid   response  SE   df lower.CL upper.CL .group\n 30S31YH      8257 751 26.1     6785     9873  A    \n 30F53 YH     9079 788 26.1     7532    10770  A    \n 30S31H       9135 790 26.1     7583    10832  A    \n 30F53 HX     9932 824 26.1     8311    11698  AB   \n 30K64       10331 840 26.1     8676    12131  AB   \n BG7049H     12822 936 26.1    10970    14818   B   \n\nResults are averaged over the levels of: block \nDegrees-of-freedom method: kenward-roger \nConfidence level used: 0.95 \nIntervals are back-transformed from the sqrt scale \nNote: contrasts are still on the sqrt scale \nP value adjustment: tukey method for comparing a family of 6 estimates \nsignificance level used: alpha = 0.05 \nNOTE: If two or more means share the same grouping symbol,\n      then we cannot show them to be different.\n      But we also did not show them to be the same. \n\ncld(medias_milho4, Letters = letters)\n\nhybrid = 30F53 HX:\n method response  SE   df lower.CL upper.CL .group\n silk       9932 824 26.1     8311    11698  a    \n pin       11130 872 26.1     9410    12995   b   \n\nhybrid = 30F53 YH:\n method response  SE   df lower.CL upper.CL .group\n silk       9079 788 26.1     7532    10770  a    \n pin        9314 798 26.1     7746    11027  a    \n\nhybrid = 30K64:\n method response  SE   df lower.CL upper.CL .group\n silk      10331 840 26.1     8676    12131  a    \n pin       11666 893 26.1     9903    13574   b   \n\nhybrid = 30S31H:\n method response  SE   df lower.CL upper.CL .group\n pin        8081 743 26.1     6626     9681  a    \n silk       9135 790 26.1     7583    10832   b   \n\nhybrid = 30S31YH:\n method response  SE   df lower.CL upper.CL .group\n pin        7829 732 26.1     6398     9405  a    \n silk       8257 751 26.1     6785     9873  a    \n\nhybrid = BG7049H:\n method response  SE   df lower.CL upper.CL .group\n pin       11914 903 26.1    10131    13841  a    \n silk      12822 936 26.1    10970    14818  a    \n\nResults are averaged over the levels of: block \nDegrees-of-freedom method: kenward-roger \nConfidence level used: 0.95 \nIntervals are back-transformed from the sqrt scale \nNote: contrasts are still on the sqrt scale \nsignificance level used: alpha = 0.05 \nNOTE: If two or more means share the same grouping symbol,\n      then we cannot show them to be different.\n      But we also did not show them to be the same. \n\n\nNOVO CONJUNTO DE DADOS\n\nestande &lt;- gsheet2tbl(\"https://docs.google.com/spreadsheets/d/1bq2N19DcZdtax2fQW9OHSGMR0X2__Z9T/edit#gid=401662555\")\n\n\nnplan &lt;- estande |&gt; \n  ggplot(aes(exp, nplants ))+\n  geom_jitter(width = 0.05, color = \"gray70\")+\n  facet_wrap(~ trat)+ #Sem o facet_wrap fica somente por tratamento.\n  stat_summary(fun.data = \"mean_cl_boot\", size =0.5, color = \"black\", alpha = 0.5)\nnplan\n\n\n\n\n\n\n\n\n\nnplan &lt;- estande |&gt; \n  ggplot(aes(trat, nplants ))+\n  geom_jitter(width = 0.05, color = \"gray70\")+\n  facet_wrap(~ exp)+ #Sem o facet_wrap fica somente por tratamento.\n  stat_summary(fun.data = \"mean_cl_boot\", size =0.5, color = \"black\", alpha = 0.5)+\n  geom_smooth(method = \"lm\", se = F, color = \"black\")\nnplan\n\n`geom_smooth()` using formula = 'y ~ x'\n\n\n\n\n\n\n\n\n\n\nnplan &lt;- estande |&gt; \n  ggplot(aes(trat, nplants ))+\n  geom_jitter(width = 0.05, color = \"gray70\")+\n  facet_wrap(~ exp)+ #Sem o facet_wrap fica somente por tratamento.\n  stat_summary(fun.data = \"mean_cl_boot\", size =0.5, color = \"black\", alpha = 0.5)+\n  geom_smooth(method = \"lm\", se = F, color = \"black\")\nnplan\n\n`geom_smooth()` using formula = 'y ~ x'\n\n\n\n\n\n\n\n\n\nA cada acrescimo tem a queda de aproximadamene, 24 plantas (trat - 0.24)\n\nexp1 &lt;- estande |&gt; \n  filter(exp ==1)\n\nexp1 |&gt; \n  ggplot(aes(trat, nplants))+\n  geom_point()+\n  geom_smooth(se = F, method = \"lm\")\n\n`geom_smooth()` using formula = 'y ~ x'\n\n\n\n\n\n\n\n\nlm1 &lt;- lm(nplants ~ trat,\n          data = exp1)\nsummary(lm1)\n\n\nCall:\nlm(formula = nplants ~ trat, data = exp1)\n\nResiduals:\n    Min      1Q  Median      3Q     Max \n-25.500  -6.532   1.758   8.573  27.226 \n\nCoefficients:\n            Estimate Std. Error t value Pr(&gt;|t|)    \n(Intercept)  52.5000     4.2044  12.487 1.84e-11 ***\ntrat         -0.2419     0.1859  -1.301    0.207    \n---\nSignif. codes:  0 '***' 0.001 '**' 0.01 '*' 0.05 '.' 0.1 ' ' 1\n\nResidual standard error: 15 on 22 degrees of freedom\nMultiple R-squared:  0.07148,   Adjusted R-squared:  0.02928 \nF-statistic: 1.694 on 1 and 22 DF,  p-value: 0.2066\n\n\n\nexp2 &lt;- estande |&gt; \n  filter(exp ==2)\n\nexp2 |&gt; \n  ggplot(aes(trat, nplants))+\n  geom_point()+\n  geom_smooth(se = F, method = \"lm\")\n\n`geom_smooth()` using formula = 'y ~ x'\n\n\n\n\n\n\n\n\nlm2 &lt;- lm(nplants ~ trat,\n          data = exp2)\nsummary(lm2)\n\n\nCall:\nlm(formula = nplants ~ trat, data = exp2)\n\nResiduals:\n     Min       1Q   Median       3Q      Max \n-25.7816  -7.7150   0.5653   8.1929  19.2184 \n\nCoefficients:\n            Estimate Std. Error t value Pr(&gt;|t|)    \n(Intercept)  60.9857     3.6304  16.798 4.93e-14 ***\ntrat         -0.7007     0.1605  -4.365 0.000247 ***\n---\nSignif. codes:  0 '***' 0.001 '**' 0.01 '*' 0.05 '.' 0.1 ' ' 1\n\nResidual standard error: 12.95 on 22 degrees of freedom\nMultiple R-squared:  0.4641,    Adjusted R-squared:  0.4398 \nF-statistic: 19.05 on 1 and 22 DF,  p-value: 0.0002473\n\nhist(residuals(lm2))\n\n\n\n\n\n\n\n\n59% da variabilidade de y é explicado por x.\nAdjusted R-squared:  0.5907\nO R² diz o quanto da variabilidade é explicada pelo modelo. Quanto da da variabilidade de y é explicado por x.\n\nexp3 &lt;- estande |&gt; \n  filter(exp ==3)\n\nexp3 |&gt; \n  ggplot(aes(trat, nplants))+\n  geom_point()+\n  geom_smooth(se = F, method = \"lm\")\n\n`geom_smooth()` using formula = 'y ~ x'\n\n\n\n\n\n\n\n\nlm3 &lt;- lm(nplants ~ trat,\n          data = exp3)\nsummary(lm3)\n\n\nCall:\nlm(formula = nplants ~ trat, data = exp3)\n\nResiduals:\n     Min       1Q   Median       3Q      Max \n-26.5887  -3.9597   0.7177   5.5806  19.8952 \n\nCoefficients:\n            Estimate Std. Error t value Pr(&gt;|t|)    \n(Intercept)  95.7500     2.9529  32.425  &lt; 2e-16 ***\ntrat         -0.7634     0.1306  -5.847 6.97e-06 ***\n---\nSignif. codes:  0 '***' 0.001 '**' 0.01 '*' 0.05 '.' 0.1 ' ' 1\n\nResidual standard error: 10.53 on 22 degrees of freedom\nMultiple R-squared:  0.6085,    Adjusted R-squared:  0.5907 \nF-statistic: 34.19 on 1 and 22 DF,  p-value: 6.968e-06\n\nhist(residuals(lm3))\n\n\n\n\n\n\n\n\nusando glm\n\nglm1 &lt;- glm(nplants ~ trat,\n            family = \"gaussian\",\n            data = exp1)\nglm1\n\n\nCall:  glm(formula = nplants ~ trat, family = \"gaussian\", data = exp1)\n\nCoefficients:\n(Intercept)         trat  \n    52.5000      -0.2419  \n\nDegrees of Freedom: 23 Total (i.e. Null);  22 Residual\nNull Deviance:      5330 \nResidual Deviance: 4949     AIC: 202\n\nsummary(glm1)\n\n\nCall:\nglm(formula = nplants ~ trat, family = \"gaussian\", data = exp1)\n\nCoefficients:\n            Estimate Std. Error t value Pr(&gt;|t|)    \n(Intercept)  52.5000     4.2044  12.487 1.84e-11 ***\ntrat         -0.2419     0.1859  -1.301    0.207    \n---\nSignif. codes:  0 '***' 0.001 '**' 0.01 '*' 0.05 '.' 0.1 ' ' 1\n\n(Dispersion parameter for gaussian family taken to be 224.9751)\n\n    Null deviance: 5330.5  on 23  degrees of freedom\nResidual deviance: 4949.5  on 22  degrees of freedom\nAIC: 202\n\nNumber of Fisher Scoring iterations: 2\n\nAIC(glm1)\n\n[1] 202.0045\n\n\n\nprint(\"-=-=-=- GAUSSIAN -=-=-=-\")\n\n[1] \"-=-=-=- GAUSSIAN -=-=-=-\"\n\nglm2 &lt;- glm(nplants ~ trat,\n            family = \"gaussian\",\n            data = exp2)\nglm2\n\n\nCall:  glm(formula = nplants ~ trat, family = \"gaussian\", data = exp2)\n\nCoefficients:\n(Intercept)         trat  \n    60.9857      -0.7007  \n\nDegrees of Freedom: 23 Total (i.e. Null);  22 Residual\nNull Deviance:      6887 \nResidual Deviance: 3690     AIC: 195\n\nsummary(glm2)\n\n\nCall:\nglm(formula = nplants ~ trat, family = \"gaussian\", data = exp2)\n\nCoefficients:\n            Estimate Std. Error t value Pr(&gt;|t|)    \n(Intercept)  60.9857     3.6304  16.798 4.93e-14 ***\ntrat         -0.7007     0.1605  -4.365 0.000247 ***\n---\nSignif. codes:  0 '***' 0.001 '**' 0.01 '*' 0.05 '.' 0.1 ' ' 1\n\n(Dispersion parameter for gaussian family taken to be 167.7464)\n\n    Null deviance: 6886.6  on 23  degrees of freedom\nResidual deviance: 3690.4  on 22  degrees of freedom\nAIC: 194.96\n\nNumber of Fisher Scoring iterations: 2\n\nAIC(glm2)\n\n[1] 194.9597\n\nprint(\"-=-=-=- POISSON -=-=-=-\")\n\n[1] \"-=-=-=- POISSON -=-=-=-\"\n\nglm2b &lt;- glm(nplants ~ trat,\n            family = \"poisson\",\n            data = exp2)\nglm2b\n\n\nCall:  glm(formula = nplants ~ trat, family = \"poisson\", data = exp2)\n\nCoefficients:\n(Intercept)         trat  \n    4.13419     -0.01627  \n\nDegrees of Freedom: 23 Total (i.e. Null);  22 Residual\nNull Deviance:      139.8 \nResidual Deviance: 69.58    AIC: 210.2\n\nsummary(glm2b)\n\n\nCall:\nglm(formula = nplants ~ trat, family = \"poisson\", data = exp2)\n\nCoefficients:\n             Estimate Std. Error z value Pr(&gt;|z|)    \n(Intercept)  4.134189   0.037583 110.003  &lt; 2e-16 ***\ntrat        -0.016270   0.002059  -7.901 2.76e-15 ***\n---\nSignif. codes:  0 '***' 0.001 '**' 0.01 '*' 0.05 '.' 0.1 ' ' 1\n\n(Dispersion parameter for poisson family taken to be 1)\n\n    Null deviance: 139.783  on 23  degrees of freedom\nResidual deviance:  69.578  on 22  degrees of freedom\nAIC: 210.24\n\nNumber of Fisher Scoring iterations: 4\n\nAIC(glm2b)\n\n[1] 210.2353\n\n\n\nprint(\"-=-=-=- GAUSSIAN -=-=-=-\")\n\n[1] \"-=-=-=- GAUSSIAN -=-=-=-\"\n\nglm3 &lt;- glm(nplants ~ trat,\n            family = \"gaussian\",\n            data = exp3)\nglm3\n\n\nCall:  glm(formula = nplants ~ trat, family = \"gaussian\", data = exp3)\n\nCoefficients:\n(Intercept)         trat  \n    95.7500      -0.7634  \n\nDegrees of Freedom: 23 Total (i.e. Null);  22 Residual\nNull Deviance:      6236 \nResidual Deviance: 2442     AIC: 185\n\nsummary(glm3)\n\n\nCall:\nglm(formula = nplants ~ trat, family = \"gaussian\", data = exp3)\n\nCoefficients:\n            Estimate Std. Error t value Pr(&gt;|t|)    \n(Intercept)  95.7500     2.9529  32.425  &lt; 2e-16 ***\ntrat         -0.7634     0.1306  -5.847 6.97e-06 ***\n---\nSignif. codes:  0 '***' 0.001 '**' 0.01 '*' 0.05 '.' 0.1 ' ' 1\n\n(Dispersion parameter for gaussian family taken to be 110.9787)\n\n    Null deviance: 6235.8  on 23  degrees of freedom\nResidual deviance: 2441.5  on 22  degrees of freedom\nAIC: 185.04\n\nNumber of Fisher Scoring iterations: 2\n\nAIC(glm3)\n\n[1] 185.0449\n\nprint(\"-=-=-=- POISSON -=-=-=-\")\n\n[1] \"-=-=-=- POISSON -=-=-=-\"\n\nglm3b &lt;- glm(nplants ~ trat,\n            family = \"poisson\",\n            data = exp3)\nglm3b\n\n\nCall:  glm(formula = nplants ~ trat, family = \"poisson\", data = exp3)\n\nCoefficients:\n(Intercept)         trat  \n   4.571590    -0.009965  \n\nDegrees of Freedom: 23 Total (i.e. Null);  22 Residual\nNull Deviance:      77.91 \nResidual Deviance: 29.95    AIC: 183.9\n\nsummary(glm3b)\n\n\nCall:\nglm(formula = nplants ~ trat, family = \"poisson\", data = exp3)\n\nCoefficients:\n             Estimate Std. Error z value Pr(&gt;|z|)    \n(Intercept)  4.571590   0.029539 154.762  &lt; 2e-16 ***\ntrat        -0.009965   0.001488  -6.697 2.13e-11 ***\n---\nSignif. codes:  0 '***' 0.001 '**' 0.01 '*' 0.05 '.' 0.1 ' ' 1\n\n(Dispersion parameter for poisson family taken to be 1)\n\n    Null deviance: 77.906  on 23  degrees of freedom\nResidual deviance: 29.952  on 22  degrees of freedom\nAIC: 183.93\n\nNumber of Fisher Scoring iterations: 4\n\nAIC(glm3b)\n\n[1] 183.9324\n\n\nMODELO MISTOS -&gt; quando tem efeito aleatório o ideal é ter mais de 6 ou 7 níveis de experimentos diferentes. Aqui temos locais aleatórios diferentes.\nEfeito alétório dos tratamentos no experimento -&gt; (trat|exp).\nModelo mais robusto que da mais informações, em bloco, como é aleatório pode ser feito também. O efeito é baseado em uma amostra maior, por isso é mais robusto.\n\nprint(\"-=-=-=- GAUSSIAN -=-=-=-\")\n\n[1] \"-=-=-=- GAUSSIAN -=-=-=-\"\n\nglmer3 &lt;- glmer(nplants ~ trat + (trat|exp),\n            family = \"gaussian\",\n            data = estande)\n\nWarning in glmer(nplants ~ trat + (trat | exp), family = \"gaussian\", data =\nestande): calling glmer() with family=gaussian (identity link) as a shortcut to\nlmer() is deprecated; please call lmer() directly\n\n\nWarning in checkConv(attr(opt, \"derivs\"), opt$par, ctrl = control$checkConv, :\nModel failed to converge with max|grad| = 0.00274249 (tol = 0.002, component 1)\n\nglmer3\n\nLinear mixed model fit by REML ['lmerMod']\nFormula: nplants ~ trat + (trat | exp)\n   Data: estande\nREML criterion at convergence: 580.8402\nRandom effects:\n Groups   Name        Std.Dev. Corr \n exp      (Intercept) 22.5983       \n          trat         0.2349  -0.82\n Residual             12.9581       \nNumber of obs: 72, groups:  exp, 3\nFixed Effects:\n(Intercept)         trat  \n    69.7452      -0.5687  \noptimizer (nloptwrap) convergence code: 0 (OK) ; 0 optimizer warnings; 1 lme4 warnings \n\nsummary(glmer3)\n\nLinear mixed model fit by REML ['lmerMod']\nFormula: nplants ~ trat + (trat | exp)\n   Data: estande\n\nREML criterion at convergence: 580.8\n\nScaled residuals: \n    Min      1Q  Median      3Q     Max \n-2.0988 -0.6091  0.1722  0.6360  1.9963 \n\nRandom effects:\n Groups   Name        Variance  Std.Dev. Corr \n exp      (Intercept) 510.68405 22.5983       \n          trat          0.05516  0.2349  -0.82\n Residual             167.91303 12.9581       \nNumber of obs: 72, groups:  exp, 3\n\nFixed effects:\n            Estimate Std. Error t value\n(Intercept)  69.7452    13.2146   5.278\ntrat         -0.5687     0.1643  -3.462\n\nCorrelation of Fixed Effects:\n     (Intr)\ntrat -0.731\noptimizer (nloptwrap) convergence code: 0 (OK)\nModel failed to converge with max|grad| = 0.00274249 (tol = 0.002, component 1)\n\nAIC(glmer3)\n\n[1] 592.8402\n\nprint(\"-=-=-=- POISSON -=-=-=-\")\n\n[1] \"-=-=-=- POISSON -=-=-=-\"\n\nglmer3b &lt;- glmer(nplants ~ trat + (trat|exp),\n            family = \"poisson\",\n            data = estande)\nglmer3b\n\nGeneralized linear mixed model fit by maximum likelihood (Laplace\n  Approximation) [glmerMod]\n Family: poisson  ( log )\nFormula: nplants ~ trat + (trat | exp)\n   Data: estande\n      AIC       BIC    logLik  deviance  df.resid \n 660.7282  672.1115 -325.3641  650.7282        67 \nRandom effects:\n Groups Name        Std.Dev. Corr \n exp    (Intercept) 0.253478      \n        trat        0.004003 -0.17\nNumber of obs: 72, groups:  exp, 3\nFixed Effects:\n(Intercept)         trat  \n    4.22340     -0.01043  \n\nsummary(glmer3b)\n\nGeneralized linear mixed model fit by maximum likelihood (Laplace\n  Approximation) [glmerMod]\n Family: poisson  ( log )\nFormula: nplants ~ trat + (trat | exp)\n   Data: estande\n\n     AIC      BIC   logLik deviance df.resid \n   660.7    672.1   -325.4    650.7       67 \n\nScaled residuals: \n    Min      1Q  Median      3Q     Max \n-3.6247 -0.8083  0.1042  0.9601  3.6511 \n\nRandom effects:\n Groups Name        Variance  Std.Dev. Corr \n exp    (Intercept) 6.425e-02 0.253478      \n        trat        1.602e-05 0.004003 -0.17\nNumber of obs: 72, groups:  exp, 3\n\nFixed effects:\n             Estimate Std. Error z value Pr(&gt;|z|)    \n(Intercept)  4.223397   0.147793  28.577  &lt; 2e-16 ***\ntrat        -0.010434   0.002538  -4.111 3.93e-05 ***\n---\nSignif. codes:  0 '***' 0.001 '**' 0.01 '*' 0.05 '.' 0.1 ' ' 1\n\nCorrelation of Fixed Effects:\n     (Intr)\ntrat -0.192\n\nAIC(glmer3b)\n\n[1] 660.7282\n\n\nPacote do professor\n\nlibrary(remotes)\n\nWarning: pacote 'remotes' foi compilado no R versão 4.4.1\n\nremotes::install_github(\"emdelponte/r4pde\")\n\nSkipping install of 'r4pde' from a github remote, the SHA1 (42e6615b) has not changed since last install.\n  Use `force = TRUE` to force installation\n\n\n\nlibrary(lme4)\nglm3 &lt;- glmer(nplants ~ trat + (trat | exp), family = \"gaussian\",\n            data = estande)\n\nWarning in glmer(nplants ~ trat + (trat | exp), family = \"gaussian\", data =\nestande): calling glmer() with family=gaussian (identity link) as a shortcut to\nlmer() is deprecated; please call lmer() directly\n\n\nWarning in checkConv(attr(opt, \"derivs\"), opt$par, ctrl = control$checkConv, :\nModel failed to converge with max|grad| = 0.00274249 (tol = 0.002, component 1)\n\nsummary(glm3)\n\nLinear mixed model fit by REML ['lmerMod']\nFormula: nplants ~ trat + (trat | exp)\n   Data: estande\n\nREML criterion at convergence: 580.8\n\nScaled residuals: \n    Min      1Q  Median      3Q     Max \n-2.0988 -0.6091  0.1722  0.6360  1.9963 \n\nRandom effects:\n Groups   Name        Variance  Std.Dev. Corr \n exp      (Intercept) 510.68405 22.5983       \n          trat          0.05516  0.2349  -0.82\n Residual             167.91303 12.9581       \nNumber of obs: 72, groups:  exp, 3\n\nFixed effects:\n            Estimate Std. Error t value\n(Intercept)  69.7452    13.2146   5.278\ntrat         -0.5687     0.1643  -3.462\n\nCorrelation of Fixed Effects:\n     (Intr)\ntrat -0.731\noptimizer (nloptwrap) convergence code: 0 (OK)\nModel failed to converge with max|grad| = 0.00274249 (tol = 0.002, component 1)\n\nAIC(glm3)\n\n[1] 592.8402\n\nglmb3 &lt;- glmer(nplants ~ trat + (trat | exp), family = poisson(link = \"log\"), \n             data = estande)\nsummary(glmb3)\n\nGeneralized linear mixed model fit by maximum likelihood (Laplace\n  Approximation) [glmerMod]\n Family: poisson  ( log )\nFormula: nplants ~ trat + (trat | exp)\n   Data: estande\n\n     AIC      BIC   logLik deviance df.resid \n   660.7    672.1   -325.4    650.7       67 \n\nScaled residuals: \n    Min      1Q  Median      3Q     Max \n-3.6247 -0.8083  0.1042  0.9601  3.6511 \n\nRandom effects:\n Groups Name        Variance  Std.Dev. Corr \n exp    (Intercept) 6.425e-02 0.253478      \n        trat        1.602e-05 0.004003 -0.17\nNumber of obs: 72, groups:  exp, 3\n\nFixed effects:\n             Estimate Std. Error z value Pr(&gt;|z|)    \n(Intercept)  4.223397   0.147793  28.577  &lt; 2e-16 ***\ntrat        -0.010434   0.002538  -4.111 3.93e-05 ***\n---\nSignif. codes:  0 '***' 0.001 '**' 0.01 '*' 0.05 '.' 0.1 ' ' 1\n\nCorrelation of Fixed Effects:\n     (Intr)\ntrat -0.192\n\nAIC(glmb3)\n\n[1] 660.7282\n\n\n\nlibrary(r4pde)\n\nWarning: substituindo importação prévia 'car::recode' por 'dplyr::recode'\nquando carregando 'r4pde'\n\nwm &lt;- WhiteMoldSoybean\n\nwm |&gt; \n  ggplot(aes(inc, yld, group = factor(study)))+\n  geom_point()+\n  #facet_wrap(~ study)+\n  geom_smooth(method = \"lm\", se = F)\n\n`geom_smooth()` using formula = 'y ~ x'\n\n\n\n\n\n\n\n\n theme_minimal()\n\nList of 136\n $ line                            :List of 6\n  ..$ colour       : chr \"black\"\n  ..$ linewidth    : num 0.5\n  ..$ linetype     : num 1\n  ..$ lineend      : chr \"butt\"\n  ..$ arrow        : logi FALSE\n  ..$ inherit.blank: logi TRUE\n  ..- attr(*, \"class\")= chr [1:2] \"element_line\" \"element\"\n $ rect                            :List of 5\n  ..$ fill         : chr \"white\"\n  ..$ colour       : chr \"black\"\n  ..$ linewidth    : num 0.5\n  ..$ linetype     : num 1\n  ..$ inherit.blank: logi TRUE\n  ..- attr(*, \"class\")= chr [1:2] \"element_rect\" \"element\"\n $ text                            :List of 11\n  ..$ family       : chr \"\"\n  ..$ face         : chr \"plain\"\n  ..$ colour       : chr \"black\"\n  ..$ size         : num 11\n  ..$ hjust        : num 0.5\n  ..$ vjust        : num 0.5\n  ..$ angle        : num 0\n  ..$ lineheight   : num 0.9\n  ..$ margin       : 'margin' num [1:4] 0points 0points 0points 0points\n  .. ..- attr(*, \"unit\")= int 8\n  ..$ debug        : logi FALSE\n  ..$ inherit.blank: logi TRUE\n  ..- attr(*, \"class\")= chr [1:2] \"element_text\" \"element\"\n $ title                           : NULL\n $ aspect.ratio                    : NULL\n $ axis.title                      : NULL\n $ axis.title.x                    :List of 11\n  ..$ family       : NULL\n  ..$ face         : NULL\n  ..$ colour       : NULL\n  ..$ size         : NULL\n  ..$ hjust        : NULL\n  ..$ vjust        : num 1\n  ..$ angle        : NULL\n  ..$ lineheight   : NULL\n  ..$ margin       : 'margin' num [1:4] 2.75points 0points 0points 0points\n  .. ..- attr(*, \"unit\")= int 8\n  ..$ debug        : NULL\n  ..$ inherit.blank: logi TRUE\n  ..- attr(*, \"class\")= chr [1:2] \"element_text\" \"element\"\n $ axis.title.x.top                :List of 11\n  ..$ family       : NULL\n  ..$ face         : NULL\n  ..$ colour       : NULL\n  ..$ size         : NULL\n  ..$ hjust        : NULL\n  ..$ vjust        : num 0\n  ..$ angle        : NULL\n  ..$ lineheight   : NULL\n  ..$ margin       : 'margin' num [1:4] 0points 0points 2.75points 0points\n  .. ..- attr(*, \"unit\")= int 8\n  ..$ debug        : NULL\n  ..$ inherit.blank: logi TRUE\n  ..- attr(*, \"class\")= chr [1:2] \"element_text\" \"element\"\n $ axis.title.x.bottom             : NULL\n $ axis.title.y                    :List of 11\n  ..$ family       : NULL\n  ..$ face         : NULL\n  ..$ colour       : NULL\n  ..$ size         : NULL\n  ..$ hjust        : NULL\n  ..$ vjust        : num 1\n  ..$ angle        : num 90\n  ..$ lineheight   : NULL\n  ..$ margin       : 'margin' num [1:4] 0points 2.75points 0points 0points\n  .. ..- attr(*, \"unit\")= int 8\n  ..$ debug        : NULL\n  ..$ inherit.blank: logi TRUE\n  ..- attr(*, \"class\")= chr [1:2] \"element_text\" \"element\"\n $ axis.title.y.left               : NULL\n $ axis.title.y.right              :List of 11\n  ..$ family       : NULL\n  ..$ face         : NULL\n  ..$ colour       : NULL\n  ..$ size         : NULL\n  ..$ hjust        : NULL\n  ..$ vjust        : num 1\n  ..$ angle        : num -90\n  ..$ lineheight   : NULL\n  ..$ margin       : 'margin' num [1:4] 0points 0points 0points 2.75points\n  .. ..- attr(*, \"unit\")= int 8\n  ..$ debug        : NULL\n  ..$ inherit.blank: logi TRUE\n  ..- attr(*, \"class\")= chr [1:2] \"element_text\" \"element\"\n $ axis.text                       :List of 11\n  ..$ family       : NULL\n  ..$ face         : NULL\n  ..$ colour       : chr \"grey30\"\n  ..$ size         : 'rel' num 0.8\n  ..$ hjust        : NULL\n  ..$ vjust        : NULL\n  ..$ angle        : NULL\n  ..$ lineheight   : NULL\n  ..$ margin       : NULL\n  ..$ debug        : NULL\n  ..$ inherit.blank: logi TRUE\n  ..- attr(*, \"class\")= chr [1:2] \"element_text\" \"element\"\n $ axis.text.x                     :List of 11\n  ..$ family       : NULL\n  ..$ face         : NULL\n  ..$ colour       : NULL\n  ..$ size         : NULL\n  ..$ hjust        : NULL\n  ..$ vjust        : num 1\n  ..$ angle        : NULL\n  ..$ lineheight   : NULL\n  ..$ margin       : 'margin' num [1:4] 2.2points 0points 0points 0points\n  .. ..- attr(*, \"unit\")= int 8\n  ..$ debug        : NULL\n  ..$ inherit.blank: logi TRUE\n  ..- attr(*, \"class\")= chr [1:2] \"element_text\" \"element\"\n $ axis.text.x.top                 :List of 11\n  ..$ family       : NULL\n  ..$ face         : NULL\n  ..$ colour       : NULL\n  ..$ size         : NULL\n  ..$ hjust        : NULL\n  ..$ vjust        : num 0\n  ..$ angle        : NULL\n  ..$ lineheight   : NULL\n  ..$ margin       : 'margin' num [1:4] 0points 0points 2.2points 0points\n  .. ..- attr(*, \"unit\")= int 8\n  ..$ debug        : NULL\n  ..$ inherit.blank: logi TRUE\n  ..- attr(*, \"class\")= chr [1:2] \"element_text\" \"element\"\n $ axis.text.x.bottom              : NULL\n $ axis.text.y                     :List of 11\n  ..$ family       : NULL\n  ..$ face         : NULL\n  ..$ colour       : NULL\n  ..$ size         : NULL\n  ..$ hjust        : num 1\n  ..$ vjust        : NULL\n  ..$ angle        : NULL\n  ..$ lineheight   : NULL\n  ..$ margin       : 'margin' num [1:4] 0points 2.2points 0points 0points\n  .. ..- attr(*, \"unit\")= int 8\n  ..$ debug        : NULL\n  ..$ inherit.blank: logi TRUE\n  ..- attr(*, \"class\")= chr [1:2] \"element_text\" \"element\"\n $ axis.text.y.left                : NULL\n $ axis.text.y.right               :List of 11\n  ..$ family       : NULL\n  ..$ face         : NULL\n  ..$ colour       : NULL\n  ..$ size         : NULL\n  ..$ hjust        : num 0\n  ..$ vjust        : NULL\n  ..$ angle        : NULL\n  ..$ lineheight   : NULL\n  ..$ margin       : 'margin' num [1:4] 0points 0points 0points 2.2points\n  .. ..- attr(*, \"unit\")= int 8\n  ..$ debug        : NULL\n  ..$ inherit.blank: logi TRUE\n  ..- attr(*, \"class\")= chr [1:2] \"element_text\" \"element\"\n $ axis.text.theta                 : NULL\n $ axis.text.r                     :List of 11\n  ..$ family       : NULL\n  ..$ face         : NULL\n  ..$ colour       : NULL\n  ..$ size         : NULL\n  ..$ hjust        : num 0.5\n  ..$ vjust        : NULL\n  ..$ angle        : NULL\n  ..$ lineheight   : NULL\n  ..$ margin       : 'margin' num [1:4] 0points 2.2points 0points 2.2points\n  .. ..- attr(*, \"unit\")= int 8\n  ..$ debug        : NULL\n  ..$ inherit.blank: logi TRUE\n  ..- attr(*, \"class\")= chr [1:2] \"element_text\" \"element\"\n $ axis.ticks                      : list()\n  ..- attr(*, \"class\")= chr [1:2] \"element_blank\" \"element\"\n $ axis.ticks.x                    : NULL\n $ axis.ticks.x.top                : NULL\n $ axis.ticks.x.bottom             : NULL\n $ axis.ticks.y                    : NULL\n $ axis.ticks.y.left               : NULL\n $ axis.ticks.y.right              : NULL\n $ axis.ticks.theta                : NULL\n $ axis.ticks.r                    : NULL\n $ axis.minor.ticks.x.top          : NULL\n $ axis.minor.ticks.x.bottom       : NULL\n $ axis.minor.ticks.y.left         : NULL\n $ axis.minor.ticks.y.right        : NULL\n $ axis.minor.ticks.theta          : NULL\n $ axis.minor.ticks.r              : NULL\n $ axis.ticks.length               : 'simpleUnit' num 2.75points\n  ..- attr(*, \"unit\")= int 8\n $ axis.ticks.length.x             : NULL\n $ axis.ticks.length.x.top         : NULL\n $ axis.ticks.length.x.bottom      : NULL\n $ axis.ticks.length.y             : NULL\n $ axis.ticks.length.y.left        : NULL\n $ axis.ticks.length.y.right       : NULL\n $ axis.ticks.length.theta         : NULL\n $ axis.ticks.length.r             : NULL\n $ axis.minor.ticks.length         : 'rel' num 0.75\n $ axis.minor.ticks.length.x       : NULL\n $ axis.minor.ticks.length.x.top   : NULL\n $ axis.minor.ticks.length.x.bottom: NULL\n $ axis.minor.ticks.length.y       : NULL\n $ axis.minor.ticks.length.y.left  : NULL\n $ axis.minor.ticks.length.y.right : NULL\n $ axis.minor.ticks.length.theta   : NULL\n $ axis.minor.ticks.length.r       : NULL\n $ axis.line                       : list()\n  ..- attr(*, \"class\")= chr [1:2] \"element_blank\" \"element\"\n $ axis.line.x                     : NULL\n $ axis.line.x.top                 : NULL\n $ axis.line.x.bottom              : NULL\n $ axis.line.y                     : NULL\n $ axis.line.y.left                : NULL\n $ axis.line.y.right               : NULL\n $ axis.line.theta                 : NULL\n $ axis.line.r                     : NULL\n $ legend.background               : list()\n  ..- attr(*, \"class\")= chr [1:2] \"element_blank\" \"element\"\n $ legend.margin                   : 'margin' num [1:4] 5.5points 5.5points 5.5points 5.5points\n  ..- attr(*, \"unit\")= int 8\n $ legend.spacing                  : 'simpleUnit' num 11points\n  ..- attr(*, \"unit\")= int 8\n $ legend.spacing.x                : NULL\n $ legend.spacing.y                : NULL\n $ legend.key                      : list()\n  ..- attr(*, \"class\")= chr [1:2] \"element_blank\" \"element\"\n $ legend.key.size                 : 'simpleUnit' num 1.2lines\n  ..- attr(*, \"unit\")= int 3\n $ legend.key.height               : NULL\n $ legend.key.width                : NULL\n $ legend.key.spacing              : 'simpleUnit' num 5.5points\n  ..- attr(*, \"unit\")= int 8\n $ legend.key.spacing.x            : NULL\n $ legend.key.spacing.y            : NULL\n $ legend.frame                    : NULL\n $ legend.ticks                    : NULL\n $ legend.ticks.length             : 'rel' num 0.2\n $ legend.axis.line                : NULL\n $ legend.text                     :List of 11\n  ..$ family       : NULL\n  ..$ face         : NULL\n  ..$ colour       : NULL\n  ..$ size         : 'rel' num 0.8\n  ..$ hjust        : NULL\n  ..$ vjust        : NULL\n  ..$ angle        : NULL\n  ..$ lineheight   : NULL\n  ..$ margin       : NULL\n  ..$ debug        : NULL\n  ..$ inherit.blank: logi TRUE\n  ..- attr(*, \"class\")= chr [1:2] \"element_text\" \"element\"\n $ legend.text.position            : NULL\n $ legend.title                    :List of 11\n  ..$ family       : NULL\n  ..$ face         : NULL\n  ..$ colour       : NULL\n  ..$ size         : NULL\n  ..$ hjust        : num 0\n  ..$ vjust        : NULL\n  ..$ angle        : NULL\n  ..$ lineheight   : NULL\n  ..$ margin       : NULL\n  ..$ debug        : NULL\n  ..$ inherit.blank: logi TRUE\n  ..- attr(*, \"class\")= chr [1:2] \"element_text\" \"element\"\n $ legend.title.position           : NULL\n $ legend.position                 : chr \"right\"\n $ legend.position.inside          : NULL\n $ legend.direction                : NULL\n $ legend.byrow                    : NULL\n $ legend.justification            : chr \"center\"\n $ legend.justification.top        : NULL\n $ legend.justification.bottom     : NULL\n $ legend.justification.left       : NULL\n $ legend.justification.right      : NULL\n $ legend.justification.inside     : NULL\n $ legend.location                 : NULL\n $ legend.box                      : NULL\n $ legend.box.just                 : NULL\n $ legend.box.margin               : 'margin' num [1:4] 0cm 0cm 0cm 0cm\n  ..- attr(*, \"unit\")= int 1\n $ legend.box.background           : list()\n  ..- attr(*, \"class\")= chr [1:2] \"element_blank\" \"element\"\n $ legend.box.spacing              : 'simpleUnit' num 11points\n  ..- attr(*, \"unit\")= int 8\n  [list output truncated]\n - attr(*, \"class\")= chr [1:2] \"theme\" \"gg\"\n - attr(*, \"complete\")= logi TRUE\n - attr(*, \"validate\")= logi TRUE\n\nmofo1 &lt;- lm(yld ~ inc,\n            data = wm)\n\nsummary(mofo1) #no slope, inc perde -9kg por percentual\n\n\nCall:\nlm(formula = yld ~ inc, data = wm)\n\nResiduals:\n     Min       1Q   Median       3Q      Max \n-1657.85  -594.50   -91.32   531.76  1693.15 \n\nCoefficients:\n            Estimate Std. Error t value Pr(&gt;|t|)    \n(Intercept) 3299.619     56.451  58.451  &lt; 2e-16 ***\ninc           -9.261      2.108  -4.393 1.45e-05 ***\n---\nSignif. codes:  0 '***' 0.001 '**' 0.01 '*' 0.05 '.' 0.1 ' ' 1\n\nResidual standard error: 745.8 on 380 degrees of freedom\nMultiple R-squared:  0.04833,   Adjusted R-squared:  0.04582 \nF-statistic:  19.3 on 1 and 380 DF,  p-value: 1.452e-05\n\n\nCom o tidy tem como fazer váras regressões\n\nlibrary(broom)\nmofo1 &lt;- wm |&gt; \n  group_by(study) |&gt; \n  do(tidy(lm(.$yld ~ .$inc), conf.int= TRUE))\nmofo1\n\n# A tibble: 70 × 8\n# Groups:   study [35]\n   study term        estimate std.error statistic  p.value conf.low conf.high\n   &lt;dbl&gt; &lt;chr&gt;          &lt;dbl&gt;     &lt;dbl&gt;     &lt;dbl&gt;    &lt;dbl&gt;    &lt;dbl&gt;     &lt;dbl&gt;\n 1     1 (Intercept)  3329.       86.8      38.3  4.60e-13   3138.    3520.  \n 2     1 .$inc         -14.2       2.08     -6.85 2.78e- 5    -18.8     -9.64\n 3     2 (Intercept)  2682.       48.6      55.2  8.55e-15   2575.    2789.  \n 4     2 .$inc          -6.93      1.49     -4.66 6.89e- 4    -10.2     -3.66\n 5     3 (Intercept)  4017.       61.6      65.2  1.37e-15   3882.    4153.  \n 6     3 .$inc         -18.6       1.71    -10.9  3.11e- 7    -22.4    -14.9 \n 7     4 (Intercept)  2814.      151.       18.6  1.15e- 9   2481.    3147.  \n 8     4 .$inc         -43.5      16.8      -2.58 2.56e- 2    -80.5     -6.38\n 9     5 (Intercept)  3317.      234.       14.2  2.07e- 8   2802.    3832.  \n10     5 .$inc         -21.2       5.69     -3.72 3.36e- 3    -33.7     -8.67\n# ℹ 60 more rows\n\n\n\nmofo2 &lt;- lm(yld ~ inc,\n            data = wm)\n\nsummary(mofo2) #no slope, inc perde -9kg por percentual\n\n\nCall:\nlm(formula = yld ~ inc, data = wm)\n\nResiduals:\n     Min       1Q   Median       3Q      Max \n-1657.85  -594.50   -91.32   531.76  1693.15 \n\nCoefficients:\n            Estimate Std. Error t value Pr(&gt;|t|)    \n(Intercept) 3299.619     56.451  58.451  &lt; 2e-16 ***\ninc           -9.261      2.108  -4.393 1.45e-05 ***\n---\nSignif. codes:  0 '***' 0.001 '**' 0.01 '*' 0.05 '.' 0.1 ' ' 1\n\nResidual standard error: 745.8 on 380 degrees of freedom\nMultiple R-squared:  0.04833,   Adjusted R-squared:  0.04582 \nF-statistic:  19.3 on 1 and 380 DF,  p-value: 1.452e-05\n\n\n\nmofo2 &lt;- wm |&gt; \n  group_by(study) |&gt; \n  do(tidy(lm(.$yld ~ .$inc), conf.int = TRUE))\nmofo2\n\n# A tibble: 70 × 8\n# Groups:   study [35]\n   study term        estimate std.error statistic  p.value conf.low conf.high\n   &lt;dbl&gt; &lt;chr&gt;          &lt;dbl&gt;     &lt;dbl&gt;     &lt;dbl&gt;    &lt;dbl&gt;    &lt;dbl&gt;     &lt;dbl&gt;\n 1     1 (Intercept)  3329.       86.8      38.3  4.60e-13   3138.    3520.  \n 2     1 .$inc         -14.2       2.08     -6.85 2.78e- 5    -18.8     -9.64\n 3     2 (Intercept)  2682.       48.6      55.2  8.55e-15   2575.    2789.  \n 4     2 .$inc          -6.93      1.49     -4.66 6.89e- 4    -10.2     -3.66\n 5     3 (Intercept)  4017.       61.6      65.2  1.37e-15   3882.    4153.  \n 6     3 .$inc         -18.6       1.71    -10.9  3.11e- 7    -22.4    -14.9 \n 7     4 (Intercept)  2814.      151.       18.6  1.15e- 9   2481.    3147.  \n 8     4 .$inc         -43.5      16.8      -2.58 2.56e- 2    -80.5     -6.38\n 9     5 (Intercept)  3317.      234.       14.2  2.07e- 8   2802.    3832.  \n10     5 .$inc         -21.2       5.69     -3.72 3.36e- 3    -33.7     -8.67\n# ℹ 60 more rows\n\n\n\nlibrary(lme4)\nmofo3 &lt;- lmer(yld ~inc +(inc|study), data = wm)\n\nWarning in checkConv(attr(opt, \"derivs\"), opt$par, ctrl = control$checkConv, :\nModel failed to converge with max|grad| = 0.00587194 (tol = 0.002, component 1)\n\n\n\ndf &lt;- mofo2 |&gt; filter(term == \".$inc\")\nmean(df$estimate)\n\n[1] -19.52932\n\np1 &lt;- mofo2 |&gt; \n  filter(term == \"(Intercept)\") |&gt; \n           ggplot(aes(x = estimate))+\n           geom_histogram(bins = 8, color = \"white\", fill = \"gray\")+\n           theme_r4pde()+\n           labs(x = \"Intercept\", y = \"frequency\")\np2 &lt;- mofo2 |&gt; \n  filter(term == \".$inc\") |&gt; \n           ggplot(aes(x = estimate))+\n           geom_histogram(bins = 8, color = \"white\", fill = \"gray\")+\n           theme_r4pde()+\n           labs(x = \"Slopes\", y = \"frequency\")\nlibrary(patchwork)\n\n\nAnexando pacote: 'patchwork'\n\n\nO seguinte objeto é mascarado por 'package:MASS':\n\n    area\n\np1+p2\n\n\n\n\n\n\n\n\n\np3 &lt;- mofo2 |&gt; \n  filter(term == \"(Intercept)\") |&gt; \n  ggplot(aes(x = estimate))+\n  geom_histogram(bins = 8, color = \"white\", fill = \"gray50\")+\n  theme_r4pde()+\n  labs(x = \"Intercept\", y = \"Frequency\")\n\ndf &lt;- mofo2 |&gt; filter(term == \".$inc\")\nmean(df$estimate)\n\n[1] -19.52932\n\np4 &lt;- df |&gt; \n  filter(term == \".$inc\") |&gt; \n  ggplot(aes(x = estimate))+\n  geom_histogram(bins = 8, color = \"white\", fill = \"gray50\")+\n  theme_r4pde()+\n  labs(x = \"Slope\", y = \"Frequency\")\n\n\nlibrary(patchwork)\np3 | p4"
  },
  {
    "objectID": "aula_09.html#parcela-subdividida",
    "href": "aula_09.html#parcela-subdividida",
    "title": "Aula 09",
    "section": "",
    "text": "Modelo misto, um fator fixo e um aleatório.\n\nlibrary(tidyverse)\n\n── Attaching core tidyverse packages ──────────────────────── tidyverse 2.0.0 ──\n✔ dplyr     1.1.4     ✔ readr     2.1.5\n✔ forcats   1.0.0     ✔ stringr   1.5.1\n✔ ggplot2   3.5.1     ✔ tibble    3.2.1\n✔ lubridate 1.9.3     ✔ tidyr     1.3.1\n✔ purrr     1.0.2     \n── Conflicts ────────────────────────────────────────── tidyverse_conflicts() ──\n✖ dplyr::filter() masks stats::filter()\n✖ dplyr::lag()    masks stats::lag()\nℹ Use the conflicted package (&lt;http://conflicted.r-lib.org/&gt;) to force all conflicts to become errors\n\ntheme_set(theme_bw())\n\nChamando os dados\n\nlibrary(gsheet)\nmilho &lt;- gsheet2tbl(\"https://docs.google.com/spreadsheets/d/1bq2N19DcZdtax2fQW9OHSGMR0X2__Z9T/edit#gid=1345524759\")\n\nPlotando gráfico\n\nindx &lt;- milho |&gt; \n  ggplot(aes(method, index ))+\n  geom_jitter(width = 0.05, color = \"gray70\")+\n  facet_wrap(~ hybrid)+ #Sem o facet_wrap fica somente por tratamento.\n  stat_summary(fun.data = \"mean_cl_boot\", size =0.5, color = \"black\", alpha = 0.5)\nindx\n\n\n\n\n\n\n\n\n\n\n\nlibrary(lme4)\n\nCarregando pacotes exigidos: Matrix\n\n\n\nAnexando pacote: 'Matrix'\n\n\nOs seguintes objetos são mascarados por 'package:tidyr':\n\n    expand, pack, unpack\n\nlibrary(car)\n\nCarregando pacotes exigidos: carData\n\n\n\nAnexando pacote: 'car'\n\n\nO seguinte objeto é mascarado por 'package:dplyr':\n\n    recode\n\n\nO seguinte objeto é mascarado por 'package:purrr':\n\n    some\n\nmilho &lt;- milho |&gt; \n  mutate(block = as.factor(block))\n#lmer é o modelo linear do lme4\nmix2 &lt;- lmer(index ~ hybrid*method + block+ (1|block/hybrid), data = milho)\n\nWarning in checkConv(attr(opt, \"derivs\"), opt$par, ctrl = control$checkConv, :\nunable to evaluate scaled gradient\n\n\nWarning in checkConv(attr(opt, \"derivs\"), opt$par, ctrl = control$checkConv, :\nModel failed to converge: degenerate Hessian with 1 negative eigenvalues\n\nAnova(mix2)\n\nAnalysis of Deviance Table (Type II Wald chisquare tests)\n\nResponse: index\n                Chisq Df Pr(&gt;Chisq)   \nhybrid        15.5971  5   0.008094 **\nmethod         4.6963  1   0.030228 * \nblock          0.2157  3   0.975023   \nhybrid:method 15.8060  5   0.007420 **\n---\nSignif. codes:  0 '***' 0.001 '**' 0.01 '*' 0.05 '.' 0.1 ' ' 1\n\n\nHouve interação significativa entre hibridos e metodos.\n\nlibrary(performance)\n\nWarning: pacote 'performance' foi compilado no R versão 4.4.1\n\ncheck_normality(mix2)\n\nOK: residuals appear as normally distributed (p = 0.635).\n\ncheck_heteroscedasticity(mix2)\n\nWarning: Heteroscedasticity (non-constant error variance) detected (p = 0.009).\n\n\n\nlibrary(DHARMa)\n\nWarning: pacote 'DHARMa' foi compilado no R versão 4.4.1\n\n\nThis is DHARMa 0.4.6. For overview type '?DHARMa'. For recent changes, type news(package = 'DHARMa')\n\nplot(simulateResiduals(mix2))\n\n\n\n\n\n\n\n\nTransformação - Raiz quadrada\n\nmilho &lt;- milho |&gt; \n  mutate(block = as.factor(block))\n#lmer é o modelo linear do lme4\nmix3 &lt;- lmer(sqrt(index) ~ hybrid*method + block+ (1|block/hybrid), data = milho)\n\nWarning in checkConv(attr(opt, \"derivs\"), opt$par, ctrl = control$checkConv, :\nunable to evaluate scaled gradient\n\n\nWarning in checkConv(attr(opt, \"derivs\"), opt$par, ctrl = control$checkConv, :\nModel failed to converge: degenerate Hessian with 1 negative eigenvalues\n\nAnova(mix2)\n\nAnalysis of Deviance Table (Type II Wald chisquare tests)\n\nResponse: index\n                Chisq Df Pr(&gt;Chisq)   \nhybrid        15.5971  5   0.008094 **\nmethod         4.6963  1   0.030228 * \nblock          0.2157  3   0.975023   \nhybrid:method 15.8060  5   0.007420 **\n---\nSignif. codes:  0 '***' 0.001 '**' 0.01 '*' 0.05 '.' 0.1 ' ' 1\n\n\n\nlibrary(performance)\ncheck_normality(mix3)\n\nOK: residuals appear as normally distributed (p = 0.440).\n\ncheck_heteroscedasticity(mix3)\n\nOK: Error variance appears to be homoscedastic (p = 0.971).\n\n\n\nlibrary(DHARMa)\nplot(simulateResiduals(mix3))\n\n\n\n\n\n\n\n\n\nqqnorm(residuals(mix3))\nqqline(residuals(mix3))\n\n\n\n\n\n\n\nhist(residuals(mix3))\n\n\n\n\n\n\n\n\nCalcular as médias\n\nlibrary(emmeans)\n\nWarning: pacote 'emmeans' foi compilado no R versão 4.4.1\n\n\nWelcome to emmeans.\nCaution: You lose important information if you filter this package's results.\nSee '? untidy'\n\nprint(\"HIBRIDO X METODO\")\n\n[1] \"HIBRIDO X METODO\"\n\nmedias_milho1 &lt;- emmeans(mix3, ~ hybrid|method, type = \"response\")\nmedias_milho1\n\nmethod = pin:\n hybrid   response   SE   df lower.CL upper.CL\n 30F53 HX     25.0 12.1 6084     6.84     54.4\n 30F53 YH     24.5 12.0 6084     6.61     53.7\n 30K64        20.3 10.9 6084     4.51     47.4\n 30S31H       37.1 14.8 6084    13.79     71.8\n 30S31YH      31.7 13.7 6084    10.57     64.2\n BG7049H      19.4 10.7 6084     4.10     46.0\n\nmethod = silk:\n hybrid   response   SE   df lower.CL upper.CL\n 30F53 HX     24.4 12.0 6084     6.56     53.6\n 30F53 YH     26.0 12.4 6084     7.42     56.0\n 30K64        21.3 11.2 6084     5.00     48.9\n 30S31H       26.3 12.5 6084     7.57     56.4\n 30S31YH      26.4 12.5 6084     7.62     56.5\n BG7049H      19.1 10.6 6084     3.96     45.6\n\nResults are averaged over the levels of: block \nDegrees-of-freedom method: kenward-roger \nConfidence level used: 0.95 \nIntervals are back-transformed from the sqrt scale \n\nprint(\"METODO X HIBRIDO\")\n\n[1] \"METODO X HIBRIDO\"\n\nmedias_milho2 &lt;- emmeans(mix3, ~ method|hybrid, type = \"response\")\nmedias_milho2\n\nhybrid = 30F53 HX:\n method response   SE   df lower.CL upper.CL\n pin        25.0 12.1 6084     6.84     54.4\n silk       24.4 12.0 6084     6.56     53.6\n\nhybrid = 30F53 YH:\n method response   SE   df lower.CL upper.CL\n pin        24.5 12.0 6084     6.61     53.7\n silk       26.0 12.4 6084     7.42     56.0\n\nhybrid = 30K64:\n method response   SE   df lower.CL upper.CL\n pin        20.3 10.9 6084     4.51     47.4\n silk       21.3 11.2 6084     5.00     48.9\n\nhybrid = 30S31H:\n method response   SE   df lower.CL upper.CL\n pin        37.1 14.8 6084    13.79     71.8\n silk       26.3 12.5 6084     7.57     56.4\n\nhybrid = 30S31YH:\n method response   SE   df lower.CL upper.CL\n pin        31.7 13.7 6084    10.57     64.2\n silk       26.4 12.5 6084     7.62     56.5\n\nhybrid = BG7049H:\n method response   SE   df lower.CL upper.CL\n pin        19.4 10.7 6084     4.10     46.0\n silk       19.1 10.6 6084     3.96     45.6\n\nResults are averaged over the levels of: block \nDegrees-of-freedom method: kenward-roger \nConfidence level used: 0.95 \nIntervals are back-transformed from the sqrt scale \n\n\n\nlibrary(multcomp)\n\nCarregando pacotes exigidos: mvtnorm\n\n\nCarregando pacotes exigidos: survival\n\n\nWarning: pacote 'survival' foi compilado no R versão 4.4.1\n\n\nCarregando pacotes exigidos: TH.data\n\n\nCarregando pacotes exigidos: MASS\n\n\nWarning: pacote 'MASS' foi compilado no R versão 4.4.1\n\n\n\nAnexando pacote: 'MASS'\n\n\nO seguinte objeto é mascarado por 'package:dplyr':\n\n    select\n\n\n\nAnexando pacote: 'TH.data'\n\n\nO seguinte objeto é mascarado por 'package:MASS':\n\n    geyser\n\ncld(medias_milho1, Letters = LETTERS)\n\nmethod = pin:\n hybrid   response   SE   df lower.CL upper.CL .group\n BG7049H      19.4 10.7 6084     4.10     46.0  A    \n 30K64        20.3 10.9 6084     4.51     47.4  A    \n 30F53 YH     24.5 12.0 6084     6.61     53.7  AB   \n 30F53 HX     25.0 12.1 6084     6.84     54.4  AB   \n 30S31YH      31.7 13.7 6084    10.57     64.2  AB   \n 30S31H       37.1 14.8 6084    13.79     71.8   B   \n\nmethod = silk:\n hybrid   response   SE   df lower.CL upper.CL .group\n BG7049H      19.1 10.6 6084     3.96     45.6  A    \n 30K64        21.3 11.2 6084     5.00     48.9  A    \n 30F53 HX     24.4 12.0 6084     6.56     53.6  A    \n 30F53 YH     26.0 12.4 6084     7.42     56.0  A    \n 30S31H       26.3 12.5 6084     7.57     56.4  A    \n 30S31YH      26.4 12.5 6084     7.62     56.5  A    \n\nResults are averaged over the levels of: block \nDegrees-of-freedom method: kenward-roger \nConfidence level used: 0.95 \nIntervals are back-transformed from the sqrt scale \nNote: contrasts are still on the sqrt scale \nP value adjustment: tukey method for comparing a family of 6 estimates \nsignificance level used: alpha = 0.05 \nNOTE: If two or more means share the same grouping symbol,\n      then we cannot show them to be different.\n      But we also did not show them to be the same. \n\ncld(medias_milho2, Letters = letters)\n\nhybrid = 30F53 HX:\n method response   SE   df lower.CL upper.CL .group\n silk       24.4 12.0 6084     6.56     53.6  a    \n pin        25.0 12.1 6084     6.84     54.4  a    \n\nhybrid = 30F53 YH:\n method response   SE   df lower.CL upper.CL .group\n pin        24.5 12.0 6084     6.61     53.7  a    \n silk       26.0 12.4 6084     7.42     56.0  a    \n\nhybrid = 30K64:\n method response   SE   df lower.CL upper.CL .group\n pin        20.3 10.9 6084     4.51     47.4  a    \n silk       21.3 11.2 6084     5.00     48.9  a    \n\nhybrid = 30S31H:\n method response   SE   df lower.CL upper.CL .group\n silk       26.3 12.5 6084     7.57     56.4  a    \n pin        37.1 14.8 6084    13.79     71.8   b   \n\nhybrid = 30S31YH:\n method response   SE   df lower.CL upper.CL .group\n silk       26.4 12.5 6084     7.62     56.5  a    \n pin        31.7 13.7 6084    10.57     64.2  a    \n\nhybrid = BG7049H:\n method response   SE   df lower.CL upper.CL .group\n silk       19.1 10.6 6084     3.96     45.6  a    \n pin        19.4 10.7 6084     4.10     46.0  a    \n\nResults are averaged over the levels of: block \nDegrees-of-freedom method: kenward-roger \nConfidence level used: 0.95 \nIntervals are back-transformed from the sqrt scale \nNote: contrasts are still on the sqrt scale \nsignificance level used: alpha = 0.05 \nNOTE: If two or more means share the same grouping symbol,\n      then we cannot show them to be different.\n      But we also did not show them to be the same. \n\n\nAgora para produtividade\n\nmix4 &lt;- lmer(sqrt(yield) ~ hybrid*method + block+ (1|block/hybrid), data = milho)\n\nWarning in checkConv(attr(opt, \"derivs\"), opt$par, ctrl = control$checkConv, : Model is nearly unidentifiable: large eigenvalue ratio\n - Rescale variables?\n\nAnova(mix4)\n\nAnalysis of Deviance Table (Type II Wald chisquare tests)\n\nResponse: sqrt(yield)\n                Chisq Df Pr(&gt;Chisq)    \nhybrid        25.5591  5  0.0001086 ***\nmethod         0.0520  1  0.8196750    \nblock          2.3606  3  0.5010021    \nhybrid:method 24.4985  5  0.0001741 ***\n---\nSignif. codes:  0 '***' 0.001 '**' 0.01 '*' 0.05 '.' 0.1 ' ' 1\n\nlibrary(performance)\ncheck_normality(mix4)\n\nOK: residuals appear as normally distributed (p = 0.214).\n\ncheck_heteroscedasticity(mix4)\n\nOK: Error variance appears to be homoscedastic (p = 0.686).\n\n\n\nplot(simulateResiduals(mix4))\n\n\n\n\n\n\n\n\n\nprint(\"HIBRIDO X METODO\")\n\n[1] \"HIBRIDO X METODO\"\n\nmedias_milho3 &lt;- emmeans(mix4, ~ hybrid|method, type = \"response\")\nmedias_milho3\n\nmethod = pin:\n hybrid   response  SE   df lower.CL upper.CL\n 30F53 HX    11130 872 26.1     9410    12995\n 30F53 YH     9314 798 26.1     7746    11027\n 30K64       11666 893 26.1     9903    13574\n 30S31H       8081 743 26.1     6626     9681\n 30S31YH      7829 732 26.1     6398     9405\n BG7049H     11914 903 26.1    10131    13841\n\nmethod = silk:\n hybrid   response  SE   df lower.CL upper.CL\n 30F53 HX     9932 824 26.1     8311    11698\n 30F53 YH     9079 788 26.1     7532    10770\n 30K64       10331 840 26.1     8676    12131\n 30S31H       9135 790 26.1     7583    10832\n 30S31YH      8257 751 26.1     6785     9873\n BG7049H     12822 936 26.1    10970    14818\n\nResults are averaged over the levels of: block \nDegrees-of-freedom method: kenward-roger \nConfidence level used: 0.95 \nIntervals are back-transformed from the sqrt scale \n\nprint(\"METODO X HIBRIDO\")\n\n[1] \"METODO X HIBRIDO\"\n\nmedias_milho4 &lt;- emmeans(mix4, ~ method|hybrid, type = \"response\")\nmedias_milho4\n\nhybrid = 30F53 HX:\n method response  SE   df lower.CL upper.CL\n pin       11130 872 26.1     9410    12995\n silk       9932 824 26.1     8311    11698\n\nhybrid = 30F53 YH:\n method response  SE   df lower.CL upper.CL\n pin        9314 798 26.1     7746    11027\n silk       9079 788 26.1     7532    10770\n\nhybrid = 30K64:\n method response  SE   df lower.CL upper.CL\n pin       11666 893 26.1     9903    13574\n silk      10331 840 26.1     8676    12131\n\nhybrid = 30S31H:\n method response  SE   df lower.CL upper.CL\n pin        8081 743 26.1     6626     9681\n silk       9135 790 26.1     7583    10832\n\nhybrid = 30S31YH:\n method response  SE   df lower.CL upper.CL\n pin        7829 732 26.1     6398     9405\n silk       8257 751 26.1     6785     9873\n\nhybrid = BG7049H:\n method response  SE   df lower.CL upper.CL\n pin       11914 903 26.1    10131    13841\n silk      12822 936 26.1    10970    14818\n\nResults are averaged over the levels of: block \nDegrees-of-freedom method: kenward-roger \nConfidence level used: 0.95 \nIntervals are back-transformed from the sqrt scale \n\n\n\ncld(medias_milho3, Letters = LETTERS)\n\nmethod = pin:\n hybrid   response  SE   df lower.CL upper.CL .group\n 30S31YH      7829 732 26.1     6398     9405  A    \n 30S31H       8081 743 26.1     6626     9681  AB   \n 30F53 YH     9314 798 26.1     7746    11027  ABC  \n 30F53 HX    11130 872 26.1     9410    12995   BC  \n 30K64       11666 893 26.1     9903    13574    C  \n BG7049H     11914 903 26.1    10131    13841    C  \n\nmethod = silk:\n hybrid   response  SE   df lower.CL upper.CL .group\n 30S31YH      8257 751 26.1     6785     9873  A    \n 30F53 YH     9079 788 26.1     7532    10770  A    \n 30S31H       9135 790 26.1     7583    10832  A    \n 30F53 HX     9932 824 26.1     8311    11698  AB   \n 30K64       10331 840 26.1     8676    12131  AB   \n BG7049H     12822 936 26.1    10970    14818   B   \n\nResults are averaged over the levels of: block \nDegrees-of-freedom method: kenward-roger \nConfidence level used: 0.95 \nIntervals are back-transformed from the sqrt scale \nNote: contrasts are still on the sqrt scale \nP value adjustment: tukey method for comparing a family of 6 estimates \nsignificance level used: alpha = 0.05 \nNOTE: If two or more means share the same grouping symbol,\n      then we cannot show them to be different.\n      But we also did not show them to be the same. \n\ncld(medias_milho4, Letters = letters)\n\nhybrid = 30F53 HX:\n method response  SE   df lower.CL upper.CL .group\n silk       9932 824 26.1     8311    11698  a    \n pin       11130 872 26.1     9410    12995   b   \n\nhybrid = 30F53 YH:\n method response  SE   df lower.CL upper.CL .group\n silk       9079 788 26.1     7532    10770  a    \n pin        9314 798 26.1     7746    11027  a    \n\nhybrid = 30K64:\n method response  SE   df lower.CL upper.CL .group\n silk      10331 840 26.1     8676    12131  a    \n pin       11666 893 26.1     9903    13574   b   \n\nhybrid = 30S31H:\n method response  SE   df lower.CL upper.CL .group\n pin        8081 743 26.1     6626     9681  a    \n silk       9135 790 26.1     7583    10832   b   \n\nhybrid = 30S31YH:\n method response  SE   df lower.CL upper.CL .group\n pin        7829 732 26.1     6398     9405  a    \n silk       8257 751 26.1     6785     9873  a    \n\nhybrid = BG7049H:\n method response  SE   df lower.CL upper.CL .group\n pin       11914 903 26.1    10131    13841  a    \n silk      12822 936 26.1    10970    14818  a    \n\nResults are averaged over the levels of: block \nDegrees-of-freedom method: kenward-roger \nConfidence level used: 0.95 \nIntervals are back-transformed from the sqrt scale \nNote: contrasts are still on the sqrt scale \nsignificance level used: alpha = 0.05 \nNOTE: If two or more means share the same grouping symbol,\n      then we cannot show them to be different.\n      But we also did not show them to be the same. \n\n\nNOVO CONJUNTO DE DADOS\n\nestande &lt;- gsheet2tbl(\"https://docs.google.com/spreadsheets/d/1bq2N19DcZdtax2fQW9OHSGMR0X2__Z9T/edit#gid=401662555\")\n\n\nnplan &lt;- estande |&gt; \n  ggplot(aes(exp, nplants ))+\n  geom_jitter(width = 0.05, color = \"gray70\")+\n  facet_wrap(~ trat)+ #Sem o facet_wrap fica somente por tratamento.\n  stat_summary(fun.data = \"mean_cl_boot\", size =0.5, color = \"black\", alpha = 0.5)\nnplan\n\n\n\n\n\n\n\n\n\nnplan &lt;- estande |&gt; \n  ggplot(aes(trat, nplants ))+\n  geom_jitter(width = 0.05, color = \"gray70\")+\n  facet_wrap(~ exp)+ #Sem o facet_wrap fica somente por tratamento.\n  stat_summary(fun.data = \"mean_cl_boot\", size =0.5, color = \"black\", alpha = 0.5)+\n  geom_smooth(method = \"lm\", se = F, color = \"black\")\nnplan\n\n`geom_smooth()` using formula = 'y ~ x'\n\n\n\n\n\n\n\n\n\n\nnplan &lt;- estande |&gt; \n  ggplot(aes(trat, nplants ))+\n  geom_jitter(width = 0.05, color = \"gray70\")+\n  facet_wrap(~ exp)+ #Sem o facet_wrap fica somente por tratamento.\n  stat_summary(fun.data = \"mean_cl_boot\", size =0.5, color = \"black\", alpha = 0.5)+\n  geom_smooth(method = \"lm\", se = F, color = \"black\")\nnplan\n\n`geom_smooth()` using formula = 'y ~ x'\n\n\n\n\n\n\n\n\n\nA cada acrescimo tem a queda de aproximadamene, 24 plantas (trat - 0.24)\n\nexp1 &lt;- estande |&gt; \n  filter(exp ==1)\n\nexp1 |&gt; \n  ggplot(aes(trat, nplants))+\n  geom_point()+\n  geom_smooth(se = F, method = \"lm\")\n\n`geom_smooth()` using formula = 'y ~ x'\n\n\n\n\n\n\n\n\nlm1 &lt;- lm(nplants ~ trat,\n          data = exp1)\nsummary(lm1)\n\n\nCall:\nlm(formula = nplants ~ trat, data = exp1)\n\nResiduals:\n    Min      1Q  Median      3Q     Max \n-25.500  -6.532   1.758   8.573  27.226 \n\nCoefficients:\n            Estimate Std. Error t value Pr(&gt;|t|)    \n(Intercept)  52.5000     4.2044  12.487 1.84e-11 ***\ntrat         -0.2419     0.1859  -1.301    0.207    \n---\nSignif. codes:  0 '***' 0.001 '**' 0.01 '*' 0.05 '.' 0.1 ' ' 1\n\nResidual standard error: 15 on 22 degrees of freedom\nMultiple R-squared:  0.07148,   Adjusted R-squared:  0.02928 \nF-statistic: 1.694 on 1 and 22 DF,  p-value: 0.2066\n\n\n\nexp2 &lt;- estande |&gt; \n  filter(exp ==2)\n\nexp2 |&gt; \n  ggplot(aes(trat, nplants))+\n  geom_point()+\n  geom_smooth(se = F, method = \"lm\")\n\n`geom_smooth()` using formula = 'y ~ x'\n\n\n\n\n\n\n\n\nlm2 &lt;- lm(nplants ~ trat,\n          data = exp2)\nsummary(lm2)\n\n\nCall:\nlm(formula = nplants ~ trat, data = exp2)\n\nResiduals:\n     Min       1Q   Median       3Q      Max \n-25.7816  -7.7150   0.5653   8.1929  19.2184 \n\nCoefficients:\n            Estimate Std. Error t value Pr(&gt;|t|)    \n(Intercept)  60.9857     3.6304  16.798 4.93e-14 ***\ntrat         -0.7007     0.1605  -4.365 0.000247 ***\n---\nSignif. codes:  0 '***' 0.001 '**' 0.01 '*' 0.05 '.' 0.1 ' ' 1\n\nResidual standard error: 12.95 on 22 degrees of freedom\nMultiple R-squared:  0.4641,    Adjusted R-squared:  0.4398 \nF-statistic: 19.05 on 1 and 22 DF,  p-value: 0.0002473\n\nhist(residuals(lm2))\n\n\n\n\n\n\n\n\n59% da variabilidade de y é explicado por x.\nAdjusted R-squared:  0.5907\nO R² diz o quanto da variabilidade é explicada pelo modelo. Quanto da da variabilidade de y é explicado por x.\n\nexp3 &lt;- estande |&gt; \n  filter(exp ==3)\n\nexp3 |&gt; \n  ggplot(aes(trat, nplants))+\n  geom_point()+\n  geom_smooth(se = F, method = \"lm\")\n\n`geom_smooth()` using formula = 'y ~ x'\n\n\n\n\n\n\n\n\nlm3 &lt;- lm(nplants ~ trat,\n          data = exp3)\nsummary(lm3)\n\n\nCall:\nlm(formula = nplants ~ trat, data = exp3)\n\nResiduals:\n     Min       1Q   Median       3Q      Max \n-26.5887  -3.9597   0.7177   5.5806  19.8952 \n\nCoefficients:\n            Estimate Std. Error t value Pr(&gt;|t|)    \n(Intercept)  95.7500     2.9529  32.425  &lt; 2e-16 ***\ntrat         -0.7634     0.1306  -5.847 6.97e-06 ***\n---\nSignif. codes:  0 '***' 0.001 '**' 0.01 '*' 0.05 '.' 0.1 ' ' 1\n\nResidual standard error: 10.53 on 22 degrees of freedom\nMultiple R-squared:  0.6085,    Adjusted R-squared:  0.5907 \nF-statistic: 34.19 on 1 and 22 DF,  p-value: 6.968e-06\n\nhist(residuals(lm3))\n\n\n\n\n\n\n\n\nusando glm\n\nglm1 &lt;- glm(nplants ~ trat,\n            family = \"gaussian\",\n            data = exp1)\nglm1\n\n\nCall:  glm(formula = nplants ~ trat, family = \"gaussian\", data = exp1)\n\nCoefficients:\n(Intercept)         trat  \n    52.5000      -0.2419  \n\nDegrees of Freedom: 23 Total (i.e. Null);  22 Residual\nNull Deviance:      5330 \nResidual Deviance: 4949     AIC: 202\n\nsummary(glm1)\n\n\nCall:\nglm(formula = nplants ~ trat, family = \"gaussian\", data = exp1)\n\nCoefficients:\n            Estimate Std. Error t value Pr(&gt;|t|)    \n(Intercept)  52.5000     4.2044  12.487 1.84e-11 ***\ntrat         -0.2419     0.1859  -1.301    0.207    \n---\nSignif. codes:  0 '***' 0.001 '**' 0.01 '*' 0.05 '.' 0.1 ' ' 1\n\n(Dispersion parameter for gaussian family taken to be 224.9751)\n\n    Null deviance: 5330.5  on 23  degrees of freedom\nResidual deviance: 4949.5  on 22  degrees of freedom\nAIC: 202\n\nNumber of Fisher Scoring iterations: 2\n\nAIC(glm1)\n\n[1] 202.0045\n\n\n\nprint(\"-=-=-=- GAUSSIAN -=-=-=-\")\n\n[1] \"-=-=-=- GAUSSIAN -=-=-=-\"\n\nglm2 &lt;- glm(nplants ~ trat,\n            family = \"gaussian\",\n            data = exp2)\nglm2\n\n\nCall:  glm(formula = nplants ~ trat, family = \"gaussian\", data = exp2)\n\nCoefficients:\n(Intercept)         trat  \n    60.9857      -0.7007  \n\nDegrees of Freedom: 23 Total (i.e. Null);  22 Residual\nNull Deviance:      6887 \nResidual Deviance: 3690     AIC: 195\n\nsummary(glm2)\n\n\nCall:\nglm(formula = nplants ~ trat, family = \"gaussian\", data = exp2)\n\nCoefficients:\n            Estimate Std. Error t value Pr(&gt;|t|)    \n(Intercept)  60.9857     3.6304  16.798 4.93e-14 ***\ntrat         -0.7007     0.1605  -4.365 0.000247 ***\n---\nSignif. codes:  0 '***' 0.001 '**' 0.01 '*' 0.05 '.' 0.1 ' ' 1\n\n(Dispersion parameter for gaussian family taken to be 167.7464)\n\n    Null deviance: 6886.6  on 23  degrees of freedom\nResidual deviance: 3690.4  on 22  degrees of freedom\nAIC: 194.96\n\nNumber of Fisher Scoring iterations: 2\n\nAIC(glm2)\n\n[1] 194.9597\n\nprint(\"-=-=-=- POISSON -=-=-=-\")\n\n[1] \"-=-=-=- POISSON -=-=-=-\"\n\nglm2b &lt;- glm(nplants ~ trat,\n            family = \"poisson\",\n            data = exp2)\nglm2b\n\n\nCall:  glm(formula = nplants ~ trat, family = \"poisson\", data = exp2)\n\nCoefficients:\n(Intercept)         trat  \n    4.13419     -0.01627  \n\nDegrees of Freedom: 23 Total (i.e. Null);  22 Residual\nNull Deviance:      139.8 \nResidual Deviance: 69.58    AIC: 210.2\n\nsummary(glm2b)\n\n\nCall:\nglm(formula = nplants ~ trat, family = \"poisson\", data = exp2)\n\nCoefficients:\n             Estimate Std. Error z value Pr(&gt;|z|)    \n(Intercept)  4.134189   0.037583 110.003  &lt; 2e-16 ***\ntrat        -0.016270   0.002059  -7.901 2.76e-15 ***\n---\nSignif. codes:  0 '***' 0.001 '**' 0.01 '*' 0.05 '.' 0.1 ' ' 1\n\n(Dispersion parameter for poisson family taken to be 1)\n\n    Null deviance: 139.783  on 23  degrees of freedom\nResidual deviance:  69.578  on 22  degrees of freedom\nAIC: 210.24\n\nNumber of Fisher Scoring iterations: 4\n\nAIC(glm2b)\n\n[1] 210.2353\n\n\n\nprint(\"-=-=-=- GAUSSIAN -=-=-=-\")\n\n[1] \"-=-=-=- GAUSSIAN -=-=-=-\"\n\nglm3 &lt;- glm(nplants ~ trat,\n            family = \"gaussian\",\n            data = exp3)\nglm3\n\n\nCall:  glm(formula = nplants ~ trat, family = \"gaussian\", data = exp3)\n\nCoefficients:\n(Intercept)         trat  \n    95.7500      -0.7634  \n\nDegrees of Freedom: 23 Total (i.e. Null);  22 Residual\nNull Deviance:      6236 \nResidual Deviance: 2442     AIC: 185\n\nsummary(glm3)\n\n\nCall:\nglm(formula = nplants ~ trat, family = \"gaussian\", data = exp3)\n\nCoefficients:\n            Estimate Std. Error t value Pr(&gt;|t|)    \n(Intercept)  95.7500     2.9529  32.425  &lt; 2e-16 ***\ntrat         -0.7634     0.1306  -5.847 6.97e-06 ***\n---\nSignif. codes:  0 '***' 0.001 '**' 0.01 '*' 0.05 '.' 0.1 ' ' 1\n\n(Dispersion parameter for gaussian family taken to be 110.9787)\n\n    Null deviance: 6235.8  on 23  degrees of freedom\nResidual deviance: 2441.5  on 22  degrees of freedom\nAIC: 185.04\n\nNumber of Fisher Scoring iterations: 2\n\nAIC(glm3)\n\n[1] 185.0449\n\nprint(\"-=-=-=- POISSON -=-=-=-\")\n\n[1] \"-=-=-=- POISSON -=-=-=-\"\n\nglm3b &lt;- glm(nplants ~ trat,\n            family = \"poisson\",\n            data = exp3)\nglm3b\n\n\nCall:  glm(formula = nplants ~ trat, family = \"poisson\", data = exp3)\n\nCoefficients:\n(Intercept)         trat  \n   4.571590    -0.009965  \n\nDegrees of Freedom: 23 Total (i.e. Null);  22 Residual\nNull Deviance:      77.91 \nResidual Deviance: 29.95    AIC: 183.9\n\nsummary(glm3b)\n\n\nCall:\nglm(formula = nplants ~ trat, family = \"poisson\", data = exp3)\n\nCoefficients:\n             Estimate Std. Error z value Pr(&gt;|z|)    \n(Intercept)  4.571590   0.029539 154.762  &lt; 2e-16 ***\ntrat        -0.009965   0.001488  -6.697 2.13e-11 ***\n---\nSignif. codes:  0 '***' 0.001 '**' 0.01 '*' 0.05 '.' 0.1 ' ' 1\n\n(Dispersion parameter for poisson family taken to be 1)\n\n    Null deviance: 77.906  on 23  degrees of freedom\nResidual deviance: 29.952  on 22  degrees of freedom\nAIC: 183.93\n\nNumber of Fisher Scoring iterations: 4\n\nAIC(glm3b)\n\n[1] 183.9324\n\n\nMODELO MISTOS -&gt; quando tem efeito aleatório o ideal é ter mais de 6 ou 7 níveis de experimentos diferentes. Aqui temos locais aleatórios diferentes.\nEfeito alétório dos tratamentos no experimento -&gt; (trat|exp).\nModelo mais robusto que da mais informações, em bloco, como é aleatório pode ser feito também. O efeito é baseado em uma amostra maior, por isso é mais robusto.\n\nprint(\"-=-=-=- GAUSSIAN -=-=-=-\")\n\n[1] \"-=-=-=- GAUSSIAN -=-=-=-\"\n\nglmer3 &lt;- glmer(nplants ~ trat + (trat|exp),\n            family = \"gaussian\",\n            data = estande)\n\nWarning in glmer(nplants ~ trat + (trat | exp), family = \"gaussian\", data =\nestande): calling glmer() with family=gaussian (identity link) as a shortcut to\nlmer() is deprecated; please call lmer() directly\n\n\nWarning in checkConv(attr(opt, \"derivs\"), opt$par, ctrl = control$checkConv, :\nModel failed to converge with max|grad| = 0.00274249 (tol = 0.002, component 1)\n\nglmer3\n\nLinear mixed model fit by REML ['lmerMod']\nFormula: nplants ~ trat + (trat | exp)\n   Data: estande\nREML criterion at convergence: 580.8402\nRandom effects:\n Groups   Name        Std.Dev. Corr \n exp      (Intercept) 22.5983       \n          trat         0.2349  -0.82\n Residual             12.9581       \nNumber of obs: 72, groups:  exp, 3\nFixed Effects:\n(Intercept)         trat  \n    69.7452      -0.5687  \noptimizer (nloptwrap) convergence code: 0 (OK) ; 0 optimizer warnings; 1 lme4 warnings \n\nsummary(glmer3)\n\nLinear mixed model fit by REML ['lmerMod']\nFormula: nplants ~ trat + (trat | exp)\n   Data: estande\n\nREML criterion at convergence: 580.8\n\nScaled residuals: \n    Min      1Q  Median      3Q     Max \n-2.0988 -0.6091  0.1722  0.6360  1.9963 \n\nRandom effects:\n Groups   Name        Variance  Std.Dev. Corr \n exp      (Intercept) 510.68405 22.5983       \n          trat          0.05516  0.2349  -0.82\n Residual             167.91303 12.9581       \nNumber of obs: 72, groups:  exp, 3\n\nFixed effects:\n            Estimate Std. Error t value\n(Intercept)  69.7452    13.2146   5.278\ntrat         -0.5687     0.1643  -3.462\n\nCorrelation of Fixed Effects:\n     (Intr)\ntrat -0.731\noptimizer (nloptwrap) convergence code: 0 (OK)\nModel failed to converge with max|grad| = 0.00274249 (tol = 0.002, component 1)\n\nAIC(glmer3)\n\n[1] 592.8402\n\nprint(\"-=-=-=- POISSON -=-=-=-\")\n\n[1] \"-=-=-=- POISSON -=-=-=-\"\n\nglmer3b &lt;- glmer(nplants ~ trat + (trat|exp),\n            family = \"poisson\",\n            data = estande)\nglmer3b\n\nGeneralized linear mixed model fit by maximum likelihood (Laplace\n  Approximation) [glmerMod]\n Family: poisson  ( log )\nFormula: nplants ~ trat + (trat | exp)\n   Data: estande\n      AIC       BIC    logLik  deviance  df.resid \n 660.7282  672.1115 -325.3641  650.7282        67 \nRandom effects:\n Groups Name        Std.Dev. Corr \n exp    (Intercept) 0.253478      \n        trat        0.004003 -0.17\nNumber of obs: 72, groups:  exp, 3\nFixed Effects:\n(Intercept)         trat  \n    4.22340     -0.01043  \n\nsummary(glmer3b)\n\nGeneralized linear mixed model fit by maximum likelihood (Laplace\n  Approximation) [glmerMod]\n Family: poisson  ( log )\nFormula: nplants ~ trat + (trat | exp)\n   Data: estande\n\n     AIC      BIC   logLik deviance df.resid \n   660.7    672.1   -325.4    650.7       67 \n\nScaled residuals: \n    Min      1Q  Median      3Q     Max \n-3.6247 -0.8083  0.1042  0.9601  3.6511 \n\nRandom effects:\n Groups Name        Variance  Std.Dev. Corr \n exp    (Intercept) 6.425e-02 0.253478      \n        trat        1.602e-05 0.004003 -0.17\nNumber of obs: 72, groups:  exp, 3\n\nFixed effects:\n             Estimate Std. Error z value Pr(&gt;|z|)    \n(Intercept)  4.223397   0.147793  28.577  &lt; 2e-16 ***\ntrat        -0.010434   0.002538  -4.111 3.93e-05 ***\n---\nSignif. codes:  0 '***' 0.001 '**' 0.01 '*' 0.05 '.' 0.1 ' ' 1\n\nCorrelation of Fixed Effects:\n     (Intr)\ntrat -0.192\n\nAIC(glmer3b)\n\n[1] 660.7282\n\n\nPacote do professor\n\nlibrary(remotes)\n\nWarning: pacote 'remotes' foi compilado no R versão 4.4.1\n\nremotes::install_github(\"emdelponte/r4pde\")\n\nSkipping install of 'r4pde' from a github remote, the SHA1 (42e6615b) has not changed since last install.\n  Use `force = TRUE` to force installation\n\n\n\nlibrary(lme4)\nglm3 &lt;- glmer(nplants ~ trat + (trat | exp), family = \"gaussian\",\n            data = estande)\n\nWarning in glmer(nplants ~ trat + (trat | exp), family = \"gaussian\", data =\nestande): calling glmer() with family=gaussian (identity link) as a shortcut to\nlmer() is deprecated; please call lmer() directly\n\n\nWarning in checkConv(attr(opt, \"derivs\"), opt$par, ctrl = control$checkConv, :\nModel failed to converge with max|grad| = 0.00274249 (tol = 0.002, component 1)\n\nsummary(glm3)\n\nLinear mixed model fit by REML ['lmerMod']\nFormula: nplants ~ trat + (trat | exp)\n   Data: estande\n\nREML criterion at convergence: 580.8\n\nScaled residuals: \n    Min      1Q  Median      3Q     Max \n-2.0988 -0.6091  0.1722  0.6360  1.9963 \n\nRandom effects:\n Groups   Name        Variance  Std.Dev. Corr \n exp      (Intercept) 510.68405 22.5983       \n          trat          0.05516  0.2349  -0.82\n Residual             167.91303 12.9581       \nNumber of obs: 72, groups:  exp, 3\n\nFixed effects:\n            Estimate Std. Error t value\n(Intercept)  69.7452    13.2146   5.278\ntrat         -0.5687     0.1643  -3.462\n\nCorrelation of Fixed Effects:\n     (Intr)\ntrat -0.731\noptimizer (nloptwrap) convergence code: 0 (OK)\nModel failed to converge with max|grad| = 0.00274249 (tol = 0.002, component 1)\n\nAIC(glm3)\n\n[1] 592.8402\n\nglmb3 &lt;- glmer(nplants ~ trat + (trat | exp), family = poisson(link = \"log\"), \n             data = estande)\nsummary(glmb3)\n\nGeneralized linear mixed model fit by maximum likelihood (Laplace\n  Approximation) [glmerMod]\n Family: poisson  ( log )\nFormula: nplants ~ trat + (trat | exp)\n   Data: estande\n\n     AIC      BIC   logLik deviance df.resid \n   660.7    672.1   -325.4    650.7       67 \n\nScaled residuals: \n    Min      1Q  Median      3Q     Max \n-3.6247 -0.8083  0.1042  0.9601  3.6511 \n\nRandom effects:\n Groups Name        Variance  Std.Dev. Corr \n exp    (Intercept) 6.425e-02 0.253478      \n        trat        1.602e-05 0.004003 -0.17\nNumber of obs: 72, groups:  exp, 3\n\nFixed effects:\n             Estimate Std. Error z value Pr(&gt;|z|)    \n(Intercept)  4.223397   0.147793  28.577  &lt; 2e-16 ***\ntrat        -0.010434   0.002538  -4.111 3.93e-05 ***\n---\nSignif. codes:  0 '***' 0.001 '**' 0.01 '*' 0.05 '.' 0.1 ' ' 1\n\nCorrelation of Fixed Effects:\n     (Intr)\ntrat -0.192\n\nAIC(glmb3)\n\n[1] 660.7282\n\n\n\nlibrary(r4pde)\n\nWarning: substituindo importação prévia 'car::recode' por 'dplyr::recode'\nquando carregando 'r4pde'\n\nwm &lt;- WhiteMoldSoybean\n\nwm |&gt; \n  ggplot(aes(inc, yld, group = factor(study)))+\n  geom_point()+\n  #facet_wrap(~ study)+\n  geom_smooth(method = \"lm\", se = F)\n\n`geom_smooth()` using formula = 'y ~ x'\n\n\n\n\n\n\n\n\n theme_minimal()\n\nList of 136\n $ line                            :List of 6\n  ..$ colour       : chr \"black\"\n  ..$ linewidth    : num 0.5\n  ..$ linetype     : num 1\n  ..$ lineend      : chr \"butt\"\n  ..$ arrow        : logi FALSE\n  ..$ inherit.blank: logi TRUE\n  ..- attr(*, \"class\")= chr [1:2] \"element_line\" \"element\"\n $ rect                            :List of 5\n  ..$ fill         : chr \"white\"\n  ..$ colour       : chr \"black\"\n  ..$ linewidth    : num 0.5\n  ..$ linetype     : num 1\n  ..$ inherit.blank: logi TRUE\n  ..- attr(*, \"class\")= chr [1:2] \"element_rect\" \"element\"\n $ text                            :List of 11\n  ..$ family       : chr \"\"\n  ..$ face         : chr \"plain\"\n  ..$ colour       : chr \"black\"\n  ..$ size         : num 11\n  ..$ hjust        : num 0.5\n  ..$ vjust        : num 0.5\n  ..$ angle        : num 0\n  ..$ lineheight   : num 0.9\n  ..$ margin       : 'margin' num [1:4] 0points 0points 0points 0points\n  .. ..- attr(*, \"unit\")= int 8\n  ..$ debug        : logi FALSE\n  ..$ inherit.blank: logi TRUE\n  ..- attr(*, \"class\")= chr [1:2] \"element_text\" \"element\"\n $ title                           : NULL\n $ aspect.ratio                    : NULL\n $ axis.title                      : NULL\n $ axis.title.x                    :List of 11\n  ..$ family       : NULL\n  ..$ face         : NULL\n  ..$ colour       : NULL\n  ..$ size         : NULL\n  ..$ hjust        : NULL\n  ..$ vjust        : num 1\n  ..$ angle        : NULL\n  ..$ lineheight   : NULL\n  ..$ margin       : 'margin' num [1:4] 2.75points 0points 0points 0points\n  .. ..- attr(*, \"unit\")= int 8\n  ..$ debug        : NULL\n  ..$ inherit.blank: logi TRUE\n  ..- attr(*, \"class\")= chr [1:2] \"element_text\" \"element\"\n $ axis.title.x.top                :List of 11\n  ..$ family       : NULL\n  ..$ face         : NULL\n  ..$ colour       : NULL\n  ..$ size         : NULL\n  ..$ hjust        : NULL\n  ..$ vjust        : num 0\n  ..$ angle        : NULL\n  ..$ lineheight   : NULL\n  ..$ margin       : 'margin' num [1:4] 0points 0points 2.75points 0points\n  .. ..- attr(*, \"unit\")= int 8\n  ..$ debug        : NULL\n  ..$ inherit.blank: logi TRUE\n  ..- attr(*, \"class\")= chr [1:2] \"element_text\" \"element\"\n $ axis.title.x.bottom             : NULL\n $ axis.title.y                    :List of 11\n  ..$ family       : NULL\n  ..$ face         : NULL\n  ..$ colour       : NULL\n  ..$ size         : NULL\n  ..$ hjust        : NULL\n  ..$ vjust        : num 1\n  ..$ angle        : num 90\n  ..$ lineheight   : NULL\n  ..$ margin       : 'margin' num [1:4] 0points 2.75points 0points 0points\n  .. ..- attr(*, \"unit\")= int 8\n  ..$ debug        : NULL\n  ..$ inherit.blank: logi TRUE\n  ..- attr(*, \"class\")= chr [1:2] \"element_text\" \"element\"\n $ axis.title.y.left               : NULL\n $ axis.title.y.right              :List of 11\n  ..$ family       : NULL\n  ..$ face         : NULL\n  ..$ colour       : NULL\n  ..$ size         : NULL\n  ..$ hjust        : NULL\n  ..$ vjust        : num 1\n  ..$ angle        : num -90\n  ..$ lineheight   : NULL\n  ..$ margin       : 'margin' num [1:4] 0points 0points 0points 2.75points\n  .. ..- attr(*, \"unit\")= int 8\n  ..$ debug        : NULL\n  ..$ inherit.blank: logi TRUE\n  ..- attr(*, \"class\")= chr [1:2] \"element_text\" \"element\"\n $ axis.text                       :List of 11\n  ..$ family       : NULL\n  ..$ face         : NULL\n  ..$ colour       : chr \"grey30\"\n  ..$ size         : 'rel' num 0.8\n  ..$ hjust        : NULL\n  ..$ vjust        : NULL\n  ..$ angle        : NULL\n  ..$ lineheight   : NULL\n  ..$ margin       : NULL\n  ..$ debug        : NULL\n  ..$ inherit.blank: logi TRUE\n  ..- attr(*, \"class\")= chr [1:2] \"element_text\" \"element\"\n $ axis.text.x                     :List of 11\n  ..$ family       : NULL\n  ..$ face         : NULL\n  ..$ colour       : NULL\n  ..$ size         : NULL\n  ..$ hjust        : NULL\n  ..$ vjust        : num 1\n  ..$ angle        : NULL\n  ..$ lineheight   : NULL\n  ..$ margin       : 'margin' num [1:4] 2.2points 0points 0points 0points\n  .. ..- attr(*, \"unit\")= int 8\n  ..$ debug        : NULL\n  ..$ inherit.blank: logi TRUE\n  ..- attr(*, \"class\")= chr [1:2] \"element_text\" \"element\"\n $ axis.text.x.top                 :List of 11\n  ..$ family       : NULL\n  ..$ face         : NULL\n  ..$ colour       : NULL\n  ..$ size         : NULL\n  ..$ hjust        : NULL\n  ..$ vjust        : num 0\n  ..$ angle        : NULL\n  ..$ lineheight   : NULL\n  ..$ margin       : 'margin' num [1:4] 0points 0points 2.2points 0points\n  .. ..- attr(*, \"unit\")= int 8\n  ..$ debug        : NULL\n  ..$ inherit.blank: logi TRUE\n  ..- attr(*, \"class\")= chr [1:2] \"element_text\" \"element\"\n $ axis.text.x.bottom              : NULL\n $ axis.text.y                     :List of 11\n  ..$ family       : NULL\n  ..$ face         : NULL\n  ..$ colour       : NULL\n  ..$ size         : NULL\n  ..$ hjust        : num 1\n  ..$ vjust        : NULL\n  ..$ angle        : NULL\n  ..$ lineheight   : NULL\n  ..$ margin       : 'margin' num [1:4] 0points 2.2points 0points 0points\n  .. ..- attr(*, \"unit\")= int 8\n  ..$ debug        : NULL\n  ..$ inherit.blank: logi TRUE\n  ..- attr(*, \"class\")= chr [1:2] \"element_text\" \"element\"\n $ axis.text.y.left                : NULL\n $ axis.text.y.right               :List of 11\n  ..$ family       : NULL\n  ..$ face         : NULL\n  ..$ colour       : NULL\n  ..$ size         : NULL\n  ..$ hjust        : num 0\n  ..$ vjust        : NULL\n  ..$ angle        : NULL\n  ..$ lineheight   : NULL\n  ..$ margin       : 'margin' num [1:4] 0points 0points 0points 2.2points\n  .. ..- attr(*, \"unit\")= int 8\n  ..$ debug        : NULL\n  ..$ inherit.blank: logi TRUE\n  ..- attr(*, \"class\")= chr [1:2] \"element_text\" \"element\"\n $ axis.text.theta                 : NULL\n $ axis.text.r                     :List of 11\n  ..$ family       : NULL\n  ..$ face         : NULL\n  ..$ colour       : NULL\n  ..$ size         : NULL\n  ..$ hjust        : num 0.5\n  ..$ vjust        : NULL\n  ..$ angle        : NULL\n  ..$ lineheight   : NULL\n  ..$ margin       : 'margin' num [1:4] 0points 2.2points 0points 2.2points\n  .. ..- attr(*, \"unit\")= int 8\n  ..$ debug        : NULL\n  ..$ inherit.blank: logi TRUE\n  ..- attr(*, \"class\")= chr [1:2] \"element_text\" \"element\"\n $ axis.ticks                      : list()\n  ..- attr(*, \"class\")= chr [1:2] \"element_blank\" \"element\"\n $ axis.ticks.x                    : NULL\n $ axis.ticks.x.top                : NULL\n $ axis.ticks.x.bottom             : NULL\n $ axis.ticks.y                    : NULL\n $ axis.ticks.y.left               : NULL\n $ axis.ticks.y.right              : NULL\n $ axis.ticks.theta                : NULL\n $ axis.ticks.r                    : NULL\n $ axis.minor.ticks.x.top          : NULL\n $ axis.minor.ticks.x.bottom       : NULL\n $ axis.minor.ticks.y.left         : NULL\n $ axis.minor.ticks.y.right        : NULL\n $ axis.minor.ticks.theta          : NULL\n $ axis.minor.ticks.r              : NULL\n $ axis.ticks.length               : 'simpleUnit' num 2.75points\n  ..- attr(*, \"unit\")= int 8\n $ axis.ticks.length.x             : NULL\n $ axis.ticks.length.x.top         : NULL\n $ axis.ticks.length.x.bottom      : NULL\n $ axis.ticks.length.y             : NULL\n $ axis.ticks.length.y.left        : NULL\n $ axis.ticks.length.y.right       : NULL\n $ axis.ticks.length.theta         : NULL\n $ axis.ticks.length.r             : NULL\n $ axis.minor.ticks.length         : 'rel' num 0.75\n $ axis.minor.ticks.length.x       : NULL\n $ axis.minor.ticks.length.x.top   : NULL\n $ axis.minor.ticks.length.x.bottom: NULL\n $ axis.minor.ticks.length.y       : NULL\n $ axis.minor.ticks.length.y.left  : NULL\n $ axis.minor.ticks.length.y.right : NULL\n $ axis.minor.ticks.length.theta   : NULL\n $ axis.minor.ticks.length.r       : NULL\n $ axis.line                       : list()\n  ..- attr(*, \"class\")= chr [1:2] \"element_blank\" \"element\"\n $ axis.line.x                     : NULL\n $ axis.line.x.top                 : NULL\n $ axis.line.x.bottom              : NULL\n $ axis.line.y                     : NULL\n $ axis.line.y.left                : NULL\n $ axis.line.y.right               : NULL\n $ axis.line.theta                 : NULL\n $ axis.line.r                     : NULL\n $ legend.background               : list()\n  ..- attr(*, \"class\")= chr [1:2] \"element_blank\" \"element\"\n $ legend.margin                   : 'margin' num [1:4] 5.5points 5.5points 5.5points 5.5points\n  ..- attr(*, \"unit\")= int 8\n $ legend.spacing                  : 'simpleUnit' num 11points\n  ..- attr(*, \"unit\")= int 8\n $ legend.spacing.x                : NULL\n $ legend.spacing.y                : NULL\n $ legend.key                      : list()\n  ..- attr(*, \"class\")= chr [1:2] \"element_blank\" \"element\"\n $ legend.key.size                 : 'simpleUnit' num 1.2lines\n  ..- attr(*, \"unit\")= int 3\n $ legend.key.height               : NULL\n $ legend.key.width                : NULL\n $ legend.key.spacing              : 'simpleUnit' num 5.5points\n  ..- attr(*, \"unit\")= int 8\n $ legend.key.spacing.x            : NULL\n $ legend.key.spacing.y            : NULL\n $ legend.frame                    : NULL\n $ legend.ticks                    : NULL\n $ legend.ticks.length             : 'rel' num 0.2\n $ legend.axis.line                : NULL\n $ legend.text                     :List of 11\n  ..$ family       : NULL\n  ..$ face         : NULL\n  ..$ colour       : NULL\n  ..$ size         : 'rel' num 0.8\n  ..$ hjust        : NULL\n  ..$ vjust        : NULL\n  ..$ angle        : NULL\n  ..$ lineheight   : NULL\n  ..$ margin       : NULL\n  ..$ debug        : NULL\n  ..$ inherit.blank: logi TRUE\n  ..- attr(*, \"class\")= chr [1:2] \"element_text\" \"element\"\n $ legend.text.position            : NULL\n $ legend.title                    :List of 11\n  ..$ family       : NULL\n  ..$ face         : NULL\n  ..$ colour       : NULL\n  ..$ size         : NULL\n  ..$ hjust        : num 0\n  ..$ vjust        : NULL\n  ..$ angle        : NULL\n  ..$ lineheight   : NULL\n  ..$ margin       : NULL\n  ..$ debug        : NULL\n  ..$ inherit.blank: logi TRUE\n  ..- attr(*, \"class\")= chr [1:2] \"element_text\" \"element\"\n $ legend.title.position           : NULL\n $ legend.position                 : chr \"right\"\n $ legend.position.inside          : NULL\n $ legend.direction                : NULL\n $ legend.byrow                    : NULL\n $ legend.justification            : chr \"center\"\n $ legend.justification.top        : NULL\n $ legend.justification.bottom     : NULL\n $ legend.justification.left       : NULL\n $ legend.justification.right      : NULL\n $ legend.justification.inside     : NULL\n $ legend.location                 : NULL\n $ legend.box                      : NULL\n $ legend.box.just                 : NULL\n $ legend.box.margin               : 'margin' num [1:4] 0cm 0cm 0cm 0cm\n  ..- attr(*, \"unit\")= int 1\n $ legend.box.background           : list()\n  ..- attr(*, \"class\")= chr [1:2] \"element_blank\" \"element\"\n $ legend.box.spacing              : 'simpleUnit' num 11points\n  ..- attr(*, \"unit\")= int 8\n  [list output truncated]\n - attr(*, \"class\")= chr [1:2] \"theme\" \"gg\"\n - attr(*, \"complete\")= logi TRUE\n - attr(*, \"validate\")= logi TRUE\n\nmofo1 &lt;- lm(yld ~ inc,\n            data = wm)\n\nsummary(mofo1) #no slope, inc perde -9kg por percentual\n\n\nCall:\nlm(formula = yld ~ inc, data = wm)\n\nResiduals:\n     Min       1Q   Median       3Q      Max \n-1657.85  -594.50   -91.32   531.76  1693.15 \n\nCoefficients:\n            Estimate Std. Error t value Pr(&gt;|t|)    \n(Intercept) 3299.619     56.451  58.451  &lt; 2e-16 ***\ninc           -9.261      2.108  -4.393 1.45e-05 ***\n---\nSignif. codes:  0 '***' 0.001 '**' 0.01 '*' 0.05 '.' 0.1 ' ' 1\n\nResidual standard error: 745.8 on 380 degrees of freedom\nMultiple R-squared:  0.04833,   Adjusted R-squared:  0.04582 \nF-statistic:  19.3 on 1 and 380 DF,  p-value: 1.452e-05\n\n\nCom o tidy tem como fazer váras regressões\n\nlibrary(broom)\nmofo1 &lt;- wm |&gt; \n  group_by(study) |&gt; \n  do(tidy(lm(.$yld ~ .$inc), conf.int= TRUE))\nmofo1\n\n# A tibble: 70 × 8\n# Groups:   study [35]\n   study term        estimate std.error statistic  p.value conf.low conf.high\n   &lt;dbl&gt; &lt;chr&gt;          &lt;dbl&gt;     &lt;dbl&gt;     &lt;dbl&gt;    &lt;dbl&gt;    &lt;dbl&gt;     &lt;dbl&gt;\n 1     1 (Intercept)  3329.       86.8      38.3  4.60e-13   3138.    3520.  \n 2     1 .$inc         -14.2       2.08     -6.85 2.78e- 5    -18.8     -9.64\n 3     2 (Intercept)  2682.       48.6      55.2  8.55e-15   2575.    2789.  \n 4     2 .$inc          -6.93      1.49     -4.66 6.89e- 4    -10.2     -3.66\n 5     3 (Intercept)  4017.       61.6      65.2  1.37e-15   3882.    4153.  \n 6     3 .$inc         -18.6       1.71    -10.9  3.11e- 7    -22.4    -14.9 \n 7     4 (Intercept)  2814.      151.       18.6  1.15e- 9   2481.    3147.  \n 8     4 .$inc         -43.5      16.8      -2.58 2.56e- 2    -80.5     -6.38\n 9     5 (Intercept)  3317.      234.       14.2  2.07e- 8   2802.    3832.  \n10     5 .$inc         -21.2       5.69     -3.72 3.36e- 3    -33.7     -8.67\n# ℹ 60 more rows\n\n\n\nmofo2 &lt;- lm(yld ~ inc,\n            data = wm)\n\nsummary(mofo2) #no slope, inc perde -9kg por percentual\n\n\nCall:\nlm(formula = yld ~ inc, data = wm)\n\nResiduals:\n     Min       1Q   Median       3Q      Max \n-1657.85  -594.50   -91.32   531.76  1693.15 \n\nCoefficients:\n            Estimate Std. Error t value Pr(&gt;|t|)    \n(Intercept) 3299.619     56.451  58.451  &lt; 2e-16 ***\ninc           -9.261      2.108  -4.393 1.45e-05 ***\n---\nSignif. codes:  0 '***' 0.001 '**' 0.01 '*' 0.05 '.' 0.1 ' ' 1\n\nResidual standard error: 745.8 on 380 degrees of freedom\nMultiple R-squared:  0.04833,   Adjusted R-squared:  0.04582 \nF-statistic:  19.3 on 1 and 380 DF,  p-value: 1.452e-05\n\n\n\nmofo2 &lt;- wm |&gt; \n  group_by(study) |&gt; \n  do(tidy(lm(.$yld ~ .$inc), conf.int = TRUE))\nmofo2\n\n# A tibble: 70 × 8\n# Groups:   study [35]\n   study term        estimate std.error statistic  p.value conf.low conf.high\n   &lt;dbl&gt; &lt;chr&gt;          &lt;dbl&gt;     &lt;dbl&gt;     &lt;dbl&gt;    &lt;dbl&gt;    &lt;dbl&gt;     &lt;dbl&gt;\n 1     1 (Intercept)  3329.       86.8      38.3  4.60e-13   3138.    3520.  \n 2     1 .$inc         -14.2       2.08     -6.85 2.78e- 5    -18.8     -9.64\n 3     2 (Intercept)  2682.       48.6      55.2  8.55e-15   2575.    2789.  \n 4     2 .$inc          -6.93      1.49     -4.66 6.89e- 4    -10.2     -3.66\n 5     3 (Intercept)  4017.       61.6      65.2  1.37e-15   3882.    4153.  \n 6     3 .$inc         -18.6       1.71    -10.9  3.11e- 7    -22.4    -14.9 \n 7     4 (Intercept)  2814.      151.       18.6  1.15e- 9   2481.    3147.  \n 8     4 .$inc         -43.5      16.8      -2.58 2.56e- 2    -80.5     -6.38\n 9     5 (Intercept)  3317.      234.       14.2  2.07e- 8   2802.    3832.  \n10     5 .$inc         -21.2       5.69     -3.72 3.36e- 3    -33.7     -8.67\n# ℹ 60 more rows\n\n\n\nlibrary(lme4)\nmofo3 &lt;- lmer(yld ~inc +(inc|study), data = wm)\n\nWarning in checkConv(attr(opt, \"derivs\"), opt$par, ctrl = control$checkConv, :\nModel failed to converge with max|grad| = 0.00587194 (tol = 0.002, component 1)\n\n\n\ndf &lt;- mofo2 |&gt; filter(term == \".$inc\")\nmean(df$estimate)\n\n[1] -19.52932\n\np1 &lt;- mofo2 |&gt; \n  filter(term == \"(Intercept)\") |&gt; \n           ggplot(aes(x = estimate))+\n           geom_histogram(bins = 8, color = \"white\", fill = \"gray\")+\n           theme_r4pde()+\n           labs(x = \"Intercept\", y = \"frequency\")\np2 &lt;- mofo2 |&gt; \n  filter(term == \".$inc\") |&gt; \n           ggplot(aes(x = estimate))+\n           geom_histogram(bins = 8, color = \"white\", fill = \"gray\")+\n           theme_r4pde()+\n           labs(x = \"Slopes\", y = \"frequency\")\nlibrary(patchwork)\n\n\nAnexando pacote: 'patchwork'\n\n\nO seguinte objeto é mascarado por 'package:MASS':\n\n    area\n\np1+p2\n\n\n\n\n\n\n\n\n\np3 &lt;- mofo2 |&gt; \n  filter(term == \"(Intercept)\") |&gt; \n  ggplot(aes(x = estimate))+\n  geom_histogram(bins = 8, color = \"white\", fill = \"gray50\")+\n  theme_r4pde()+\n  labs(x = \"Intercept\", y = \"Frequency\")\n\ndf &lt;- mofo2 |&gt; filter(term == \".$inc\")\nmean(df$estimate)\n\n[1] -19.52932\n\np4 &lt;- df |&gt; \n  filter(term == \".$inc\") |&gt; \n  ggplot(aes(x = estimate))+\n  geom_histogram(bins = 8, color = \"white\", fill = \"gray50\")+\n  theme_r4pde()+\n  labs(x = \"Slope\", y = \"Frequency\")\n\n\nlibrary(patchwork)\np3 | p4"
  },
  {
    "objectID": "aula_12.html",
    "href": "aula_12.html",
    "title": "Criação de mapas",
    "section": "",
    "text": "CRIAÇÃO DE MAPAS\n\nremotes::install_github(\"ropensci/rnaturalearthhires\")\n\nSkipping install of 'rnaturalearthhires' from a github remote, the SHA1 (dd1e210c) has not changed since last install.\n  Use `force = TRUE` to force installation\n\n\n\nlibrary(rnaturalearthhires)\nlibrary(rnaturalearth)\n\nWarning: pacote 'rnaturalearth' foi compilado no R versão 4.4.1\n\nworld &lt;- ne_countries()\n\nlibrary(tidyverse)\n\n── Attaching core tidyverse packages ──────────────────────── tidyverse 2.0.0 ──\n✔ dplyr     1.1.4     ✔ readr     2.1.5\n✔ forcats   1.0.0     ✔ stringr   1.5.1\n✔ ggplot2   3.5.1     ✔ tibble    3.2.1\n✔ lubridate 1.9.3     ✔ tidyr     1.3.1\n✔ purrr     1.0.2     \n── Conflicts ────────────────────────────────────────── tidyverse_conflicts() ──\n✖ dplyr::filter() masks stats::filter()\n✖ dplyr::lag()    masks stats::lag()\nℹ Use the conflicted package (&lt;http://conflicted.r-lib.org/&gt;) to force all conflicts to become errors\n\nBRA &lt;- ne_states(country = \"Brazil\",\n                 returnclass = \"sf\")\n\nggplot(BRA) +\n  geom_sf(fill = \"black\",\n          color = \"yellow\",\n          linewigth = 1)\n\nWarning in layer_sf(geom = GeomSf, data = data, mapping = mapping, stat = stat,\n: Ignoring unknown parameters: `linewigth`\n\n\n\n\n\n\n\n\n\n\nlibrary(r4pde)\n\nWarning: substituindo importação prévia 'car::recode' por 'dplyr::recode'\nquando carregando 'r4pde'\n\nlibrary(ggthemes)\n\nMG &lt;- BRA |&gt; \n  filter(name_en == \"Minas Gerais\")\n\nsbr &lt;- RustSoybean\n\nggplot(BRA)+\n  geom_sf(fill = \"white\",\n          color = \"black\",\n          linewidth = 0.1)+\n  geom_point(data = sbr, aes(longitude,latitude),\n             color = \"red\")#+\n\n\n\n\n\n\n\n  #theme_map() Retira o fundo\n\n\nlibrary(ggspatial)\n\nWarning: pacote 'ggspatial' foi compilado no R versão 4.4.1\n\nggplot(BRA)+\n  geom_sf(fill = \"white\",\n          color = \"black\",\n          linewidth = 0.1)+\n  geom_point(data = sbr, aes(longitude,latitude),\n             color = \"red\")+\n  #theme_map()#+ #Retira o fundo\n  annotation_north_arrow()# biblioteca ggspatial\n\n\n\n\n\n\n\n\n\nMG &lt;- BRA |&gt; \n  filter(name_en == \"Minas Gerais\")\n\nggplot(BRA)+\n  geom_sf(fill = \"white\",\n          color = \"black\")+\n  geom_sf(data = MG, fill = \"yellow\")+\n  geom_point(data = sbr, aes(longitude,latitude), color = \"red\")+\n  theme_map()\n\n\n\n\n\n\n\n\n\nlibrary(plotly)\n\nWarning: pacote 'plotly' foi compilado no R versão 4.4.1\n\n\n\nAnexando pacote: 'plotly'\n\n\nO seguinte objeto é mascarado por 'package:ggplot2':\n\n    last_plot\n\n\nO seguinte objeto é mascarado por 'package:stats':\n\n    filter\n\n\nO seguinte objeto é mascarado por 'package:graphics':\n\n    layout\n\nbra &lt;- ggplot(BRA)+\n  geom_sf(fill = \"white\",\n          color = \"black\")+\n  geom_point(data = sbr, aes(longitude,latitude),\n             color = \"red\")\n\nggplotly(bra)\n\n\n\n\n\n\nlibrary(leaflet)\n\nWarning: pacote 'leaflet' foi compilado no R versão 4.4.1\n\nleaflet() |&gt; \n  addTiles() |&gt; \n  setView(lng = -42.8825, lat = -20.7546, zoom = 15)\n\n\n\n\n\n\nlibrary(leaflet)\nleaflet() |&gt; \n  addProviderTiles(providers$Esri.NatGeoWorldMap) |&gt; \n  setView(lng = -42.8825, lat = -20.7546, zoom = 5)\n\n\n\n\n\n\nlibrary(leaflet)\nleaflet(sbr) |&gt; \n  addTiles() |&gt; \n  #setView(lng = -42.8825, lat = -20.7546, zoom = 5) |&gt; #zoom\n  addCircleMarkers(radius = 2)\n\nAssuming \"longitude\" and \"latitude\" are longitude and latitude, respectively\n\n\n\n\n\n\n\nlibrary(scatterpie)\n\nWarning: pacote 'scatterpie' foi compilado no R versão 4.4.1\n\nlibrary(ggrepel)\n\nWarning: pacote 'ggrepel' foi compilado no R versão 4.4.1\n\nlibrary(gsheet)\nmapa &lt;- gsheet2tbl(\"https://docs.google.com/spreadsheets/d/1pAIFKsdKxk_UQQXdYwIO-O5NOkYNhpclImJcLziYnk4/edit?usp=sharing\")\n\nBra_2 &lt;- ggplot(BRA) +\n  geom_sf(fill = \"gray70\", alpha = 0.5, color = \"white\") +\n  coord_sf()+\n  geom_scatterpie(aes(x = lon, y = lat, r = 0.6), alpha = 0.8, color = NA, data = mapa,\n                  cols = c(\"DFC\",\n                           \"MA\",\n                           \"FER\",\n                           \"ANTR\",\n                           \"OIDIO\"))+\n  geom_text_repel(data = mapa, aes(lon, lat, label = Local),\n                   size = 2, nudge_x = 0.2, nudge_y = 0.27, color = \"gray30\") +\n  ggthemes::scale_fill_calc()+\n  ggthemes::theme_map() +\n  labs(x = \"Longitude\", y = \"Latitude\", legend = \"\", fill = \"Doença\")+\n  theme(legend.position = \"bottom\", text = element_text(size = 8))\n\nBra_2"
  }
]